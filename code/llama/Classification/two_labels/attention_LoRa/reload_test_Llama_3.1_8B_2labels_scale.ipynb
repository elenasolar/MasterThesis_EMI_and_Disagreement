{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reload test for: LLama 3.1-8B (base version)**\n",
    "\n",
    "## **2 Labels only, Scale (Logits/Probability)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Note:**\n",
    "\n",
    "* This Notebook runs fine-tuning of a Llama model using the **base version** of Llama 3.1 (as apparently base versions are recommended for fine-tuning).\n",
    "* Also, it uses **`AutoModelForSequenceClassification`**. According to GPT:\n",
    "    * \"The AutoModelForSequenceClassification class in Hugging Face is specifically tailored for classification tasks. When using this model, the underlying LLaMA weights are fine-tuned with a small classifier layer on top (e.g., a linear layer with softmax for multiple classes).\n",
    "    Inputs to the model are tokenized text, and the model outputs probabilities for the predefined classes.\n",
    "The classifier does not \"understand\" instructions in the same way a generative LLM like GPT does. Instead, it learns from examples during fine-tuning, using the training data to associate input patterns with output labels.\"\n",
    "    * Instructions are nevertheless handed over by simply concatenating them: `System Prompt: 'Instruction'; Comment: 'the comment'; Reply: 'the reply'`\n",
    " \n",
    "See the other notebook for fine-tuning of the **instruction based model** using **`AutoModelForCausalLM`** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Llama**\n",
    "\n",
    "\n",
    "### Big Picture Overview of Parameter Efficient Fine Tuning Methods like LoRA and QLoRA Fine Tuning for Sequence Classification\n",
    "\n",
    "**The Essence of Fine-tuning**\n",
    "- LLMs are pre-trained on vast amounts of data for broad language understanding.\n",
    "- Fine-tuning is crucial for specializing in specific domains or tasks, involving adjustments with smaller, relevant datasets.\n",
    "\n",
    "**Model Fine-tuning with PEFT: Exploring LoRA and QLoRA**\n",
    "- Traditional fine-tuning is resource-intensive; PEFT (Parameter Efficient Fine-tuning) makes the process faster and less demanding.\n",
    "- Focus on two PEFT methods: LoRA and QLoRA.\n",
    "\n",
    "**The Power of PEFT**\n",
    "- PEFT modifies only a subset of the LLM's parameters, enhancing speed and reducing memory demands, making it suitable for less powerful devices.\n",
    "\n",
    "**LoRA: Efficiency through Adapters**\n",
    "- **Low-Rank Adaptation (LoRA):** Injects small trainable adapters into the pre-trained model.\n",
    "- **Equation:** For a weight matrix $W$, LoRA approximates $W = W_0 + BA$, where $W_0$ is the original weight matrix, and $BA$ represents the low-rank modification through trainable matrices $B$ and $A$.\n",
    "- Adapters learn task nuances while keeping the majority of the LLM unchanged, minimizing overhead.\n",
    "\n",
    "**QLoRA: Compression and Speed**\n",
    "- **Quantized LoRA (QLoRA):** Extends LoRA by quantizing the modelâ€™s weights, further reducing size and enhancing speed.\n",
    "- **Innovations in QLoRA:**\n",
    "  1. **4-bit Quantization:** Uses a 4-bit data type, NormalFloat (NF4), for optimal weight quantization, drastically reducing memory usage.\n",
    "  2. **Low-Rank Adapters:** Fine-tuned with 16-bit precision to effectively capture task-specific nuances.\n",
    "  3. **Double Quantization:** Reduces quantization constants from 32-bit to 8-bit, saving additional memory without accuracy loss.\n",
    "  4. **Paged Optimizers:** Manages memory efficiently during training, optimizing for large tasks.\n",
    "\n",
    "**Why PEFT Matters**\n",
    "- **Rapid Learning:** Speeds up model adaptation.\n",
    "- **Smaller Footprint:** Eases deployment with reduced model size.\n",
    "- **Edge-Friendly:** Fits better on devices with limited resources, enhancing accessibility.\n",
    "\n",
    "**Conclusion**\n",
    "- PEFT methods like LoRA and QLoRA revolutionize LLM fine-tuning by focusing on efficiency, facilitating faster adaptability, smaller models, and broader device compatibility.\n",
    "\n",
    "***\n",
    "\n",
    "### Fine-tuning for Sentiment Analysis Classification:\n",
    "\n",
    "\n",
    "#### 1. Text Generation with Sentiment Label as part of text\n",
    "- **Approach**: Train the model to generate text that naturally appends the sentiment label at the end.\n",
    "- **Input**: \"TSLA slashes model Y prices ======\"\n",
    "- **Output**: \"TSLA slashes model Y prices ====== Bearish\"\n",
    "- **Use Case**: This method is useful for applications requiring continuous text output that includes embedded sentiment analysis, such as interactive chatbots or automated content creation tools.\n",
    "\n",
    "\n",
    "#### 2. Sequence Classification Head\n",
    "- **Approach**: Add a sequence classification head (linear layer) on top of the LLaMa Model transformer. This setup is similar to GPT-2 and focuses on classifying the sentiment based on the last relevant token in the sequence.\n",
    "    - **Token Positioning**:\n",
    "        - **With pad_token_id**: The model identifies and ignores padding tokens, using the last non-padding token for classification.\n",
    "        - **Without pad_token_id**: It defaults to the last token in each sequence.\n",
    "        - **inputs_embeds**: If embeddings are directly passed (without input_ids), the model cannot identify padding tokens and takes the last embedding in each sequence as the input for classification.\n",
    "- **Input**: Specific sentences (e.g., \"TSLA slashes Model Y prices\").\n",
    "- **Output**: Direct sentiment classification (e.g., \"Bearish\").\n",
    "- **Training Objective**: Minimize cross-entropy loss between the predicted and the actual sentiment labels.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/en/model_doc/llama\n",
    "\n",
    "### Peft Configs\n",
    "* Bits and bytes config for quantization\n",
    "* Lora config for lora\n",
    "\n",
    "### Going to use Hugginface Transformers trainer class: Main componenents\n",
    "* Hugging face dataset (for train + eval)\n",
    "* Data collater\n",
    "* Compute Metrics\n",
    "* Class weights since we use custom trainer and also custom weighted loss..\n",
    "* trainingArgs: like # epochs, learning rate, weight decay etc..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.24.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.47.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.1\n",
      "    Uninstalling transformers-4.47.1:\n",
      "      Successfully uninstalled transformers-4.47.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "adapters 1.1.0 requires transformers~=4.47.1, but you have transformers 4.51.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed transformers-4.51.1\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.51.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from trl) (3.5.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.51.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.8.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (2.16.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2023.7.22)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in /opt/conda/lib/python3.11/site-packages (18.1.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.11/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: adapter-transformers in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: adapters in /opt/conda/lib/python3.11/site-packages (from adapter-transformers) (1.1.0)\n",
      "Collecting transformers~=4.47.1 (from adapters->adapter-transformers)\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from adapters->adapter-transformers) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (1.24.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.47.1->adapters->adapter-transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.47.1->adapters->adapter-transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.47.1->adapters->adapter-transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.47.1->adapters->adapter-transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.47.1->adapters->adapter-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.47.1->adapters->adapter-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.47.1->adapters->adapter-transformers) (2023.7.22)\n",
      "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.1\n",
      "    Uninstalling transformers-4.51.1:\n",
      "      Successfully uninstalled transformers-4.51.1\n",
      "Successfully installed transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U peft\n",
    "!pip install -U trl\n",
    "!pip install pyarrow==18.1.0\n",
    "!pip install evaluate\n",
    "!pip install --upgrade wandb\n",
    "!pip install adapter-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "import functools # ??\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                        AutoTokenizer,\n",
    "                        AutoModel,\n",
    "                        AutoConfig,\n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                            Trainer,\n",
    "                            DataCollatorWithPadding,\n",
    "                          pipeline, \n",
    "                          logging)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                            f1_score, balanced_accuracy_score)\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()\n",
    "#torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Authenticate for Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face access\n",
    "\n",
    "from huggingface_hub import login\n",
    "with open(\"../../../../login/hf_key.txt\", 'r') as f: \n",
    "    HF_TOKEN = str(f.read())\n",
    "    \n",
    "login(token = HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melena-solar\u001b[0m (\u001b[33melena-solar-university-of-konstanz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb\n",
    "\n",
    "with open(\"../../../../login/wandb.txt\", 'r') as f: \n",
    "    WB_TOKEN = str(f.read())\n",
    "\n",
    "wandb.login(key=WB_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't *been* honest in decades, so I'm c...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>agree</td>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42894 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't *been* honest in decades, so I'm c...   \n",
       "...         ...                                                ...   \n",
       "42889   neutral  Not trying to spark an argument but a legitima...   \n",
       "42890     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891     agree  >Why don't I see ads holding Republicans accou...   \n",
       "42892     agree  How about ... no? This is strange. Community o...   \n",
       "42893     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42890  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42891  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42892  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42893  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1  \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1  \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1  \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0  \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0  \n",
       "...            ...               ...               ...         ...     ...  \n",
       "42889      gyotff1        Republican  19/05/2021 12:36  1621427788       1  \n",
       "42890      gyp3u39         democrats  19/05/2021 13:56  1621432578       2  \n",
       "42891      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2  \n",
       "42892      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2  \n",
       "42893      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2  \n",
       "\n",
       "[42894 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../../../../data/labeled_data.csv\")\n",
    "data = data[[\"label\", \"body_parent\", \"body_child\", \"msg_id_parent\", \"msg_id_child\", \"subreddit\", \"datetime\", \"exact_time\"]].sort_values(by = \"exact_time\").reset_index(drop = True)\n",
    "\n",
    "# keep integer labels\n",
    "data['target'] = data['label']\n",
    "\n",
    "# for readability, recode labels\n",
    "int_to_label = {2: \"agree\", 1 : \"neutral\", 0 : \"disagree\"}\n",
    "data.replace({\"label\": int_to_label}, inplace = True)\n",
    "\n",
    "label_dict = {0 : 'no_disagreement', 1: 'disagree'}\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't *been* honest in decades, so I'm c...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>agree</td>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42894 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't *been* honest in decades, so I'm c...   \n",
       "...         ...                                                ...   \n",
       "42889   neutral  Not trying to spark an argument but a legitima...   \n",
       "42890     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891     agree  >Why don't I see ads holding Republicans accou...   \n",
       "42892     agree  How about ... no? This is strange. Community o...   \n",
       "42893     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42890  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42891  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42892  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42893  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1  \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1  \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1  \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0  \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0  \n",
       "...            ...               ...               ...         ...     ...  \n",
       "42889      gyotff1        Republican  19/05/2021 12:36  1621427788       1  \n",
       "42890      gyp3u39         democrats  19/05/2021 13:56  1621432578       2  \n",
       "42891      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2  \n",
       "42892      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2  \n",
       "42893      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2  \n",
       "\n",
       "[42894 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure order by time --> no leackage of info\n",
    "\n",
    "data = data.sort_values(by = \"exact_time\", ascending = True).reset_index(drop = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>1</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't *been* honest in decades, so I'm c...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>1</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>agree</td>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42894 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't *been* honest in decades, so I'm c...   \n",
       "...         ...                                                ...   \n",
       "42889   neutral  Not trying to spark an argument but a legitima...   \n",
       "42890     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891     agree  >Why don't I see ads holding Republicans accou...   \n",
       "42892     agree  How about ... no? This is strange. Community o...   \n",
       "42893     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42890  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42891  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42892  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42893  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \\\n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       0   \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       0   \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       0   \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       1   \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       1   \n",
       "...            ...               ...               ...         ...     ...   \n",
       "42889      gyotff1        Republican  19/05/2021 12:36  1621427788       0   \n",
       "42890      gyp3u39         democrats  19/05/2021 13:56  1621432578       0   \n",
       "42891      gyp5vzw         democrats  19/05/2021 14:11  1621433471       0   \n",
       "42892      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       0   \n",
       "42893      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       0   \n",
       "\n",
       "               label_2  \n",
       "0      no_disagreement  \n",
       "1      no_disagreement  \n",
       "2      no_disagreement  \n",
       "3             disagree  \n",
       "4             disagree  \n",
       "...                ...  \n",
       "42889  no_disagreement  \n",
       "42890  no_disagreement  \n",
       "42891  no_disagreement  \n",
       "42892  no_disagreement  \n",
       "42893  no_disagreement  \n",
       "\n",
       "[42894 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapt true labels\n",
    "labels_2 = []\n",
    "target_new = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    if row['label'] in ['neutral', 'agree']:\n",
    "        labels_2.append('no_disagreement')\n",
    "        target_new.append(0)\n",
    "    else:\n",
    "        labels_2.append('disagree')\n",
    "        target_new.append(1)\n",
    "        \n",
    "data['label_2'] = labels_2\n",
    "data['target'] = target_new\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mann hasn't *been* honest in decades, so I'm c...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42894 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "0      I live in rural Saskatchewan, Canada. We have ...   \n",
       "1      I live in rural Saskatchewan, Canada. We have ...   \n",
       "2      Convince her of what? That it's happening or t...   \n",
       "3      I think this prediction is about as valid as s...   \n",
       "4      Mann hasn't *been* honest in decades, so I'm c...   \n",
       "...                                                  ...   \n",
       "42889  Not trying to spark an argument but a legitima...   \n",
       "42890  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891  >Why don't I see ads holding Republicans accou...   \n",
       "42892  How about ... no? This is strange. Community o...   \n",
       "42893  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...  no_disagreement   \n",
       "1      One hundred year flood just means a one in one...  no_disagreement   \n",
       "2      That anthropocentric climate change is actuall...  no_disagreement   \n",
       "3      It's January. Literally no one said it would b...         disagree   \n",
       "4      There have been a dozen re-constructions of Ma...         disagree   \n",
       "...                                                  ...              ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42890  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42891  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42892  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42893  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "42889       0  \n",
       "42890       0  \n",
       "42891       0  \n",
       "42892       0  \n",
       "42893       0  \n",
       "\n",
       "[42894 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make text\n",
    "\n",
    "def create_training_data(data):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        #system_prompt = \"\"\"You are a classification Chatbot. Given a comment and a reply, you classify whether the reply disagrees with the comment, or not. You only reply with either \"disagree\" or \"no_disagreement\" and nothing else.\"\"\"\n",
    "        comment = row[\"body_parent\"]\n",
    "        reply = row[\"body_child\"]\n",
    "        label = row[\"label_2\"]\n",
    "        target = row[\"target\"]\n",
    "        result.append({'comment' : comment, 'reply': reply, 'label' : label, 'target' : target})\n",
    "    \n",
    "    return result\n",
    "\n",
    "# save data\n",
    "df = pd.DataFrame(create_training_data(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I live in rural Saskatchewan, Canada....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I live in rural Saskatchewan, Canada....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Convince her of what? That it's happe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: I think this prediction is about as v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mann hasn't *been* honest in decades, so I'm c...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Mann hasn't *been* honest in decades,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Not trying to spark an argument but a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Y'all saw Guilianis hail Mary right? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: &gt;Why don't I see ads holding Republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: How about ... no? This is strange. Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Can you recruit some white allies so ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42894 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "0      I live in rural Saskatchewan, Canada. We have ...   \n",
       "1      I live in rural Saskatchewan, Canada. We have ...   \n",
       "2      Convince her of what? That it's happening or t...   \n",
       "3      I think this prediction is about as valid as s...   \n",
       "4      Mann hasn't *been* honest in decades, so I'm c...   \n",
       "...                                                  ...   \n",
       "42889  Not trying to spark an argument but a legitima...   \n",
       "42890  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891  >Why don't I see ads holding Republicans accou...   \n",
       "42892  How about ... no? This is strange. Community o...   \n",
       "42893  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...  no_disagreement   \n",
       "1      One hundred year flood just means a one in one...  no_disagreement   \n",
       "2      That anthropocentric climate change is actuall...  no_disagreement   \n",
       "3      It's January. Literally no one said it would b...         disagree   \n",
       "4      There have been a dozen re-constructions of Ma...         disagree   \n",
       "...                                                  ...              ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42890  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42891  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42892  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42893  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target                                             prompt  \n",
       "0           0  Comment: I live in rural Saskatchewan, Canada....  \n",
       "1           0  Comment: I live in rural Saskatchewan, Canada....  \n",
       "2           0  Comment: Convince her of what? That it's happe...  \n",
       "3           1  Comment: I think this prediction is about as v...  \n",
       "4           1  Comment: Mann hasn't *been* honest in decades,...  \n",
       "...       ...                                                ...  \n",
       "42889       0  Comment: Not trying to spark an argument but a...  \n",
       "42890       0  Comment: Y'all saw Guilianis hail Mary right? ...  \n",
       "42891       0  Comment: >Why don't I see ads holding Republic...  \n",
       "42892       0  Comment: How about ... no? This is strange. Co...  \n",
       "42893       0  Comment: Can you recruit some white allies so ...  \n",
       "\n",
       "[42894 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompt'] = None\n",
    "\n",
    "def make_prompt(row):\n",
    "\n",
    "    prompt = \"Comment: \" + row[\"comment\"] + \"; Reply: \" + row[\"reply\"]\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "df['prompt'] = df.apply(lambda row: make_prompt(row), axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Make train/val/test split by time order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame\n",
    "train_size = 0.8\n",
    "eval_size = 0.1\n",
    "\n",
    "# Determine splitting indexes (ordered by time)\n",
    "train_end = int(train_size * len(df))\n",
    "eval_end = train_end + int(eval_size * len(df))\n",
    "\n",
    "# Split the data\n",
    "X_train = df[:train_end]\n",
    "X_eval = df[train_end:eval_end]\n",
    "X_test = df[eval_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from Pandas DataFrame to Hugging Face Dataset\n",
    "* Also let's shuffle the training set.\n",
    "* We put the components train,val,test into a DatasetDict so we can access them later with HF trainer.\n",
    "* Later we will add a tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['comment', 'reply', 'target', 'prompt'],\n",
       "    num_rows: 4290\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset = Dataset.from_pandas(X_train.drop('label', axis = 1))\n",
    "X_eval_dataset = Dataset.from_pandas(X_eval.drop('label', axis = 1))\n",
    "X_test_dataset = Dataset.from_pandas(X_test.drop('label', axis = 1))\n",
    "\n",
    "X_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle training data --> apparently this helps with performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset_shuffle = X_train_dataset.shuffle(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 34315\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4289\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train' : X_train_dataset_shuffle,\n",
    "    'val' : X_eval_dataset,\n",
    "    'test' : X_test_dataset\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.59933\n",
       "1    0.40067\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.target.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights\n",
    "\n",
    "* Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
    "* Convert to pytorch tensor since we will need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4007, 0.5993])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert the weights\n",
    "class_weights = (1/X_train.target.value_counts(normalize = True).sort_index()).to_list()\n",
    "\n",
    "# make a tensor\n",
    "class_weights = torch.tensor(class_weights)\n",
    "\n",
    "# make them sum to one\n",
    "class_weights = class_weights/class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Load the Model**\n",
    "\n",
    "Apparently, meta recommends the base version of the model for finetuning [source](https://www.youtube.com/watch?v=YJNbgusTSF0)\n",
    "\n",
    "* load model with 4bit quantization (as specified in bits and bytes) and prepare model for peft training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02939e6754448dca69824fbd0462190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.1-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      4\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      5\u001b[0m     load_in_4bit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# enable 4 bit quantization\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     bnb_4bit_quant_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# information theoretically optimal dtype for normally distributed weights\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     bnb_4bit_use_double_quant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# quantize quantized weights\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     bnb_4bit_compute_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16 \u001b[38;5;66;03m# optimized fp format for ML\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#config =  model_config, # Ensure this matches the number of labels you used during training\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:4264\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4254\u001b[0m         load_contexts\u001b[38;5;241m.\u001b[39mappend(tp_device)\n\u001b[1;32m   4256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(load_contexts):\n\u001b[1;32m   4257\u001b[0m         (\n\u001b[1;32m   4258\u001b[0m             model,\n\u001b[1;32m   4259\u001b[0m             missing_keys,\n\u001b[1;32m   4260\u001b[0m             unexpected_keys,\n\u001b[1;32m   4261\u001b[0m             mismatched_keys,\n\u001b[1;32m   4262\u001b[0m             offload_index,\n\u001b[1;32m   4263\u001b[0m             error_msgs,\n\u001b[0;32m-> 4264\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4266\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4271\u001b[0m \u001b[43m            \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4272\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4275\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4276\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4282\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4284\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4285\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:4777\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4773\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4774\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4775\u001b[0m                 )\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4777\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4778\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4779\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4780\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4781\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4783\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4784\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4791\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4793\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4795\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:942\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    939\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B\" \n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4 bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    #config =  model_config, # Ensure this matches the number of labels you used during training\n",
    "    quantization_config = quantization_config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reimport\n",
    "\n",
    "1. base mode\n",
    "2. then fin etuned adapters\n",
    "3. merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m adapter_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_Llama_3.1_8B_saved_model_2labels_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the LoRA adapter on top of it\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel\u001b[49m, adapter_path)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_Llama_3.1_8B_saved_model_2labels_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_prefix_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "adapter_path = \"final_Llama_3.1_8B_saved_model_2labels_scale\"\n",
    "\n",
    "# Load the LoRA adapter on top of it\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"final_Llama_3.1_8B_saved_model_2labels_scale\", add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  \n",
    "model.config.use_cache = False \n",
    "model.config.pretraining_pt = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac9bf251fcd4fb5886be4c59ee0a3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34315 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea88fba101a04f10bf138f5435a1cfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aac3b2ead8347acb58f630e90c1222e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "col_to_delete = ['comment', 'reply', 'prompt']\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['prompt'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 34315\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4289\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38604</th>\n",
       "      <td>It's so nice having a FLOTUS who's facial expr...</td>\n",
       "      <td>Melanoma's squinty cat face always looked to m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: It's so nice having a FLOTUS who's fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38605</th>\n",
       "      <td>Because Mitch McConnell indicated he's voting ...</td>\n",
       "      <td>I think it's worth it because the more we air ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Because Mitch McConnell indicated he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38606</th>\n",
       "      <td>How about some stimulus checks and a decent st...</td>\n",
       "      <td>You get this was an executive action, not legi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: How about some stimulus checks and a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38607</th>\n",
       "      <td>Satire feels appropriate. I'd like one dose of...</td>\n",
       "      <td>Are you saying they didn't know or understand ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Satire feels appropriate. I'd like on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38608</th>\n",
       "      <td>I actually didn't want to upload these particu...</td>\n",
       "      <td>To be fair they are just reporting what Brexit...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I actually didn't want to upload thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Not trying to spark an argument but a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Y'all saw Guilianis hail Mary right? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: &gt;Why don't I see ads holding Republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: How about ... no? This is strange. Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Can you recruit some white allies so ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "38604  It's so nice having a FLOTUS who's facial expr...   \n",
       "38605  Because Mitch McConnell indicated he's voting ...   \n",
       "38606  How about some stimulus checks and a decent st...   \n",
       "38607  Satire feels appropriate. I'd like one dose of...   \n",
       "38608  I actually didn't want to upload these particu...   \n",
       "...                                                  ...   \n",
       "42889  Not trying to spark an argument but a legitima...   \n",
       "42890  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891  >Why don't I see ads holding Republicans accou...   \n",
       "42892  How about ... no? This is strange. Community o...   \n",
       "42893  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "38604  Melanoma's squinty cat face always looked to m...  no_disagreement   \n",
       "38605  I think it's worth it because the more we air ...         disagree   \n",
       "38606  You get this was an executive action, not legi...         disagree   \n",
       "38607  Are you saying they didn't know or understand ...         disagree   \n",
       "38608  To be fair they are just reporting what Brexit...  no_disagreement   \n",
       "...                                                  ...              ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42890  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42891  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42892  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42893  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target                                             prompt  \n",
       "38604       0  Comment: It's so nice having a FLOTUS who's fa...  \n",
       "38605       1  Comment: Because Mitch McConnell indicated he'...  \n",
       "38606       1  Comment: How about some stimulus checks and a ...  \n",
       "38607       1  Comment: Satire feels appropriate. I'd like on...  \n",
       "38608       0  Comment: I actually didn't want to upload thes...  \n",
       "...       ...                                                ...  \n",
       "42889       0  Comment: Not trying to spark an argument but a...  \n",
       "42890       0  Comment: Y'all saw Guilianis hail Mary right? ...  \n",
       "42891       0  Comment: >Why don't I see ads holding Republic...  \n",
       "42892       0  Comment: How about ... no? This is strange. Co...  \n",
       "42893       0  Comment: Can you recruit some white allies so ...  \n",
       "\n",
       "[4290 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:39<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9878, 0.0123],\n",
      "        [0.6069, 0.3931],\n",
      "        [0.3408, 0.6592],\n",
      "        ...,\n",
      "        [0.9341, 0.0657],\n",
      "        [0.9878, 0.0120],\n",
      "        [0.9521, 0.0478]], device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_31465/1269005370.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions_label_ft'] = predicted_labels.cpu().numpy()\n",
      "/tmp/ipykernel_31465/1269005370.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions_score_ft'] = certainty_scores.cpu().numpy()\n",
      "/tmp/ipykernel_31465/1269005370.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions_ft'] = df_test['predictions_label_ft'].apply(lambda l:label_dict[l])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "      <th>predictions_label_ft</th>\n",
       "      <th>predictions_score_ft</th>\n",
       "      <th>predictions_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38604</th>\n",
       "      <td>It's so nice having a FLOTUS who's facial expr...</td>\n",
       "      <td>Melanoma's squinty cat face always looked to m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: It's so nice having a FLOTUS who's fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987793</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38605</th>\n",
       "      <td>Because Mitch McConnell indicated he's voting ...</td>\n",
       "      <td>I think it's worth it because the more we air ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Because Mitch McConnell indicated he'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38606</th>\n",
       "      <td>How about some stimulus checks and a decent st...</td>\n",
       "      <td>You get this was an executive action, not legi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: How about some stimulus checks and a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38607</th>\n",
       "      <td>Satire feels appropriate. I'd like one dose of...</td>\n",
       "      <td>Are you saying they didn't know or understand ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Satire feels appropriate. I'd like on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505859</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38608</th>\n",
       "      <td>I actually didn't want to upload these particu...</td>\n",
       "      <td>To be fair they are just reporting what Brexit...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I actually didn't want to upload thes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607422</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Not trying to spark an argument but a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807129</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Y'all saw Guilianis hail Mary right? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: &gt;Why don't I see ads holding Republic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934082</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: How about ... no? This is strange. Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987793</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Can you recruit some white allies so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952148</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "38604  It's so nice having a FLOTUS who's facial expr...   \n",
       "38605  Because Mitch McConnell indicated he's voting ...   \n",
       "38606  How about some stimulus checks and a decent st...   \n",
       "38607  Satire feels appropriate. I'd like one dose of...   \n",
       "38608  I actually didn't want to upload these particu...   \n",
       "...                                                  ...   \n",
       "42889  Not trying to spark an argument but a legitima...   \n",
       "42890  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891  >Why don't I see ads holding Republicans accou...   \n",
       "42892  How about ... no? This is strange. Community o...   \n",
       "42893  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "38604  Melanoma's squinty cat face always looked to m...  no_disagreement   \n",
       "38605  I think it's worth it because the more we air ...         disagree   \n",
       "38606  You get this was an executive action, not legi...         disagree   \n",
       "38607  Are you saying they didn't know or understand ...         disagree   \n",
       "38608  To be fair they are just reporting what Brexit...  no_disagreement   \n",
       "...                                                  ...              ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42890  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42891  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42892  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42893  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target                                             prompt  \\\n",
       "38604       0  Comment: It's so nice having a FLOTUS who's fa...   \n",
       "38605       1  Comment: Because Mitch McConnell indicated he'...   \n",
       "38606       1  Comment: How about some stimulus checks and a ...   \n",
       "38607       1  Comment: Satire feels appropriate. I'd like on...   \n",
       "38608       0  Comment: I actually didn't want to upload thes...   \n",
       "...       ...                                                ...   \n",
       "42889       0  Comment: Not trying to spark an argument but a...   \n",
       "42890       0  Comment: Y'all saw Guilianis hail Mary right? ...   \n",
       "42891       0  Comment: >Why don't I see ads holding Republic...   \n",
       "42892       0  Comment: How about ... no? This is strange. Co...   \n",
       "42893       0  Comment: Can you recruit some white allies so ...   \n",
       "\n",
       "       predictions_label_ft  predictions_score_ft   predictions_ft  \n",
       "38604                     0              0.987793  no_disagreement  \n",
       "38605                     0              0.606934  no_disagreement  \n",
       "38606                     1              0.659180         disagree  \n",
       "38607                     0              0.505859  no_disagreement  \n",
       "38608                     0              0.607422  no_disagreement  \n",
       "...                     ...                   ...              ...  \n",
       "42889                     1              0.807129         disagree  \n",
       "42890                     0              0.979492  no_disagreement  \n",
       "42891                     0              0.934082  no_disagreement  \n",
       "42892                     0              0.987793  no_disagreement  \n",
       "42893                     0              0.952148  no_disagreement  \n",
       "\n",
       "[4290 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(model,df_test):\n",
    "    \n",
    "    model.eval()\n",
    "    # Convert summaries to a list\n",
    "    sentences = df_test.prompt.tolist()\n",
    "    \n",
    "    # Define the batch size\n",
    "    batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "    \n",
    "    # Initialize an empty list to store the model outputs\n",
    "    all_outputs = []\n",
    "    \n",
    "    # Process the sentences in batches\n",
    "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "      # Get the batch of sentences\n",
    "      batch_sentences = sentences[i:i + batch_size]\n",
    "    \n",
    "      # Tokenize the batch\n",
    "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "    \n",
    "      # Perform inference and store the logits\n",
    "      with torch.no_grad():\n",
    "          outputs = model(**inputs)\n",
    "          all_outputs.append(outputs['logits'])\n",
    "          \n",
    "          \n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    probabilities = F.softmax(final_outputs, dim=1)\n",
    "    print(probabilities) \n",
    "    predicted_labels = probabilities.argmax(dim=1)  \n",
    "    certainty_scores = probabilities.max(dim=1).values \n",
    "    \n",
    "    df_test['predictions_label_ft'] = predicted_labels.cpu().numpy()\n",
    "    df_test['predictions_score_ft'] = certainty_scores.cpu().numpy()\n",
    "    df_test['predictions_ft'] = df_test['predictions_label_ft'].apply(lambda l:label_dict[l])\n",
    "    return df_test \n",
    "  \n",
    "\n",
    "\n",
    "make_predictions(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.to_csv(\"output/Llama_3.1_8B_ft_X_test_2labels_scale.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "      <th>predictions_label_initial</th>\n",
       "      <th>predictions_score_initial</th>\n",
       "      <th>predictions_initial</th>\n",
       "      <th>predictions_label_ft</th>\n",
       "      <th>predictions_score_ft</th>\n",
       "      <th>predictions_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>It's so nice having a FLOTUS who's facial expr...</td>\n",
       "      <td>Melanoma's squinty cat face always looked to m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960898</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983496</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>Because Mitch McConnell indicated he's voting ...</td>\n",
       "      <td>I think it's worth it because the more we air ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942642</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507598</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>How about some stimulus checks and a decent st...</td>\n",
       "      <td>You get this was an executive action, not legi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960131</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785662</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>Satire feels appropriate. I'd like one dose of...</td>\n",
       "      <td>Are you saying they didn't know or understand ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967641</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769629</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>I actually didn't want to upload these particu...</td>\n",
       "      <td>To be fair they are just reporting what Brexit...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828229</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824243</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692977</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989079</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951116</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984794</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993187</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>You are a classification Chatbot. Given a comm...</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>System Prompt: You are a classification Chatbo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946284</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification Chatbot. Given a comm...   \n",
       "1     You are a classification Chatbot. Given a comm...   \n",
       "2     You are a classification Chatbot. Given a comm...   \n",
       "3     You are a classification Chatbot. Given a comm...   \n",
       "4     You are a classification Chatbot. Given a comm...   \n",
       "...                                                 ...   \n",
       "4285  You are a classification Chatbot. Given a comm...   \n",
       "4286  You are a classification Chatbot. Given a comm...   \n",
       "4287  You are a classification Chatbot. Given a comm...   \n",
       "4288  You are a classification Chatbot. Given a comm...   \n",
       "4289  You are a classification Chatbot. Given a comm...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     It's so nice having a FLOTUS who's facial expr...   \n",
       "1     Because Mitch McConnell indicated he's voting ...   \n",
       "2     How about some stimulus checks and a decent st...   \n",
       "3     Satire feels appropriate. I'd like one dose of...   \n",
       "4     I actually didn't want to upload these particu...   \n",
       "...                                                 ...   \n",
       "4285  Not trying to spark an argument but a legitima...   \n",
       "4286  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "4287  >Why don't I see ads holding Republicans accou...   \n",
       "4288  How about ... no? This is strange. Community o...   \n",
       "4289  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                  reply            label  \\\n",
       "0     Melanoma's squinty cat face always looked to m...  no_disagreement   \n",
       "1     I think it's worth it because the more we air ...         disagree   \n",
       "2     You get this was an executive action, not legi...         disagree   \n",
       "3     Are you saying they didn't know or understand ...         disagree   \n",
       "4     To be fair they are just reporting what Brexit...  no_disagreement   \n",
       "...                                                 ...              ...   \n",
       "4285  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "4286  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "4287  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "4288  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "4289  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "      target                                             prompt  \\\n",
       "0          0  System Prompt: You are a classification Chatbo...   \n",
       "1          1  System Prompt: You are a classification Chatbo...   \n",
       "2          1  System Prompt: You are a classification Chatbo...   \n",
       "3          1  System Prompt: You are a classification Chatbo...   \n",
       "4          0  System Prompt: You are a classification Chatbo...   \n",
       "...      ...                                                ...   \n",
       "4285       0  System Prompt: You are a classification Chatbo...   \n",
       "4286       0  System Prompt: You are a classification Chatbo...   \n",
       "4287       0  System Prompt: You are a classification Chatbo...   \n",
       "4288       0  System Prompt: You are a classification Chatbo...   \n",
       "4289       0  System Prompt: You are a classification Chatbo...   \n",
       "\n",
       "      predictions_label_initial  predictions_score_initial  \\\n",
       "0                             0                   0.960898   \n",
       "1                             0                   0.942642   \n",
       "2                             0                   0.960131   \n",
       "3                             0                   0.967641   \n",
       "4                             1                   0.828229   \n",
       "...                         ...                        ...   \n",
       "4285                          1                   0.951807   \n",
       "4286                          0                   0.617278   \n",
       "4287                          0                   0.951116   \n",
       "4288                          0                   0.984794   \n",
       "4289                          0                   0.785714   \n",
       "\n",
       "     predictions_initial  predictions_label_ft  predictions_score_ft  \\\n",
       "0        no_disagreement                     0              0.983496   \n",
       "1        no_disagreement                     0              0.507598   \n",
       "2        no_disagreement                     1              0.785662   \n",
       "3        no_disagreement                     1              0.769629   \n",
       "4               disagree                     0              0.824243   \n",
       "...                  ...                   ...                   ...   \n",
       "4285            disagree                     1              0.692977   \n",
       "4286     no_disagreement                     0              0.989079   \n",
       "4287     no_disagreement                     0              0.887011   \n",
       "4288     no_disagreement                     0              0.993187   \n",
       "4289     no_disagreement                     0              0.946284   \n",
       "\n",
       "       predictions_ft  \n",
       "0     no_disagreement  \n",
       "1     no_disagreement  \n",
       "2            disagree  \n",
       "3            disagree  \n",
       "4     no_disagreement  \n",
       "...               ...  \n",
       "4285         disagree  \n",
       "4286  no_disagreement  \n",
       "4287  no_disagreement  \n",
       "4288  no_disagreement  \n",
       "4289  no_disagreement  \n",
       "\n",
       "[4290 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test = pd.read_csv(\"output/Llama_3.1_8B_ft_X_test_2labels_scale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test, pred_col):\n",
    "  y_test = df_test.label\n",
    "  y_pred = df_test[pred_col]\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1227  397]\n",
      " [ 410 2256]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       disagree       0.75      0.76      0.75      1624\n",
      "no_disagreement       0.85      0.85      0.85      2666\n",
      "\n",
      "       accuracy                           0.81      4290\n",
      "      macro avg       0.80      0.80      0.80      4290\n",
      "   weighted avg       0.81      0.81      0.81      4290\n",
      "\n",
      "Balanced Accuracy Score: 0.8008767124047022\n",
      "Accuracy Score: 0.8118881118881119\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_test, 'predictions_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"meta-llama/Llama-3.1-8B\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128001,\n",
      "  \"pretraining_pt\": 1,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 8.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare the model config\n",
    "print(model.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6076443,
     "sourceId": 9893468,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68812,
     "sourceId": 108555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
