{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LLama 3.1-8B (base version)**\n",
    "\n",
    "Code was adapted based on an example from [Link to Source](https://github.com/adidror005/youtube-videos/blob/main/old_videos/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "## **2 Labels only, Scale (Logits/Probability)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Llama**\n",
    "\n",
    "\n",
    "### Big Picture Overview of Parameter Efficient Fine Tuning Methods like LoRA and QLoRA Fine Tuning for Sequence Classification\n",
    "\n",
    "**The Essence of Fine-tuning**\n",
    "- LLMs are pre-trained on vast amounts of data for broad language understanding.\n",
    "- Fine-tuning is crucial for specializing in specific domains or tasks, involving adjustments with smaller, relevant datasets.\n",
    "\n",
    "**Model Fine-tuning with PEFT: Exploring LoRA and QLoRA**\n",
    "- Traditional fine-tuning is resource-intensive; PEFT (Parameter Efficient Fine-tuning) makes the process faster and less demanding.\n",
    "- Focus on two PEFT methods: LoRA and QLoRA.\n",
    "\n",
    "**The Power of PEFT**\n",
    "- PEFT modifies only a subset of the LLM's parameters, enhancing speed and reducing memory demands, making it suitable for less powerful devices.\n",
    "\n",
    "**LoRA: Efficiency through Adapters**\n",
    "- **Low-Rank Adaptation (LoRA):** Injects small trainable adapters into the pre-trained model.\n",
    "- **Equation:** For a weight matrix $W$, LoRA approximates $W = W_0 + BA$, where $W_0$ is the original weight matrix, and $BA$ represents the low-rank modification through trainable matrices $B$ and $A$.\n",
    "- Adapters learn task nuances while keeping the majority of the LLM unchanged, minimizing overhead.\n",
    "\n",
    "**QLoRA: Compression and Speed**\n",
    "- **Quantized LoRA (QLoRA):** Extends LoRA by quantizing the model’s weights, further reducing size and enhancing speed.\n",
    "- **Innovations in QLoRA:**\n",
    "  1. **4-bit Quantization:** Uses a 4-bit data type, NormalFloat (NF4), for optimal weight quantization, drastically reducing memory usage.\n",
    "  2. **Low-Rank Adapters:** Fine-tuned with 16-bit precision to effectively capture task-specific nuances.\n",
    "  3. **Double Quantization:** Reduces quantization constants from 32-bit to 8-bit, saving additional memory without accuracy loss.\n",
    "  4. **Paged Optimizers:** Manages memory efficiently during training, optimizing for large tasks.\n",
    "\n",
    "**Why PEFT Matters**\n",
    "- **Rapid Learning:** Speeds up model adaptation.\n",
    "- **Smaller Footprint:** Eases deployment with reduced model size.\n",
    "- **Edge-Friendly:** Fits better on devices with limited resources, enhancing accessibility.\n",
    "\n",
    "**Conclusion**\n",
    "- PEFT methods like LoRA and QLoRA revolutionize LLM fine-tuning by focusing on efficiency, facilitating faster adaptability, smaller models, and broader device compatibility.\n",
    "\n",
    "***\n",
    "\n",
    "### Fine-tuning for Sentiment Analysis Classification:\n",
    "\n",
    "\n",
    "#### 1. Text Generation with Sentiment Label as part of text\n",
    "- **Approach**: Train the model to generate text that naturally appends the sentiment label at the end.\n",
    "- **Input**: \"TSLA slashes model Y prices ======\"\n",
    "- **Output**: \"TSLA slashes model Y prices ====== Bearish\"\n",
    "- **Use Case**: This method is useful for applications requiring continuous text output that includes embedded sentiment analysis, such as interactive chatbots or automated content creation tools.\n",
    "\n",
    "\n",
    "#### 2. Sequence Classification Head\n",
    "- **Approach**: Add a sequence classification head (linear layer) on top of the LLaMa Model transformer. This setup is similar to GPT-2 and focuses on classifying the sentiment based on the last relevant token in the sequence.\n",
    "    - **Token Positioning**:\n",
    "        - **With pad_token_id**: The model identifies and ignores padding tokens, using the last non-padding token for classification.\n",
    "        - **Without pad_token_id**: It defaults to the last token in each sequence.\n",
    "        - **inputs_embeds**: If embeddings are directly passed (without input_ids), the model cannot identify padding tokens and takes the last embedding in each sequence as the input for classification.\n",
    "- **Input**: Specific sentences (e.g., \"TSLA slashes Model Y prices\").\n",
    "- **Output**: Direct sentiment classification (e.g., \"Bearish\").\n",
    "- **Training Objective**: Minimize cross-entropy loss between the predicted and the actual sentiment labels.\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/en/model_doc/llama\n",
    "\n",
    "### Peft Configs\n",
    "* Bits and bytes config for quantization\n",
    "* Lora config for lora\n",
    "\n",
    "### Going to use Hugginface Transformers trainer class: Main componenents\n",
    "* Hugging face dataset (for train + eval)\n",
    "* Data collater\n",
    "* Compute Metrics\n",
    "* Class weights since we use custom trainer and also custom weighted loss..\n",
    "* trainingArgs: like # epochs, learning rate, weight decay etc..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.24.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Using cached bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.51.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.2\n",
      "    Uninstalling transformers-4.51.2:\n",
      "      Successfully uninstalled transformers-4.51.2\n",
      "Successfully installed transformers-4.51.3\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
      "Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n",
      "Collecting peft\n",
      "  Using cached peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.7.22)\n",
      "Using cached peft-0.15.1-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.1\n",
      "Collecting trl\n",
      "  Using cached trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from trl) (1.6.0)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting rich (from trl)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.1.1)\n",
      "Collecting requests>=2.32.2 (from datasets>=3.0.0->trl)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=3.0.0->trl)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets>=3.0.0->trl)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.8.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (2.16.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2023.7.22)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Using cached trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, mdurl, dill, multiprocess, markdown-it-py, rich, datasets, trl\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 13.0.0\n",
      "    Uninstalling pyarrow-13.0.0:\n",
      "      Successfully uninstalled pyarrow-13.0.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "Successfully installed datasets-3.5.0 dill-0.3.8 markdown-it-py-3.0.0 mdurl-0.1.2 multiprocess-0.70.16 pyarrow-19.0.1 requests-2.32.3 rich-14.0.0 tqdm-4.67.1 trl-0.16.1 xxhash-3.5.0\n",
      "Collecting pyarrow==18.1.0\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.24.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.25.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3->wandb)\n",
      "  Using cached pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Using cached wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached sentry_sdk-2.25.1-py2.py3-none-any.whl (339 kB)\n",
      "Using cached setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, setproctitle, sentry-sdk, pydantic-core, docker-pycreds, annotated-types, pydantic, wandb\n",
      "Successfully installed annotated-types-0.7.0 docker-pycreds-0.4.0 pydantic-2.11.3 pydantic-core-2.33.1 sentry-sdk-2.25.1 setproctitle-1.3.5 typing-inspection-0.4.0 wandb-0.19.9\n",
      "Collecting adapter-transformers\n",
      "  Using cached adapter_transformers-4.0.0-py3-none-any.whl\n",
      "Collecting adapters (from adapter-transformers)\n",
      "  Downloading adapters-1.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting transformers~=4.48.3 (from adapters->adapter-transformers)\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from adapters->adapter-transformers) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (1.24.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers~=4.48.3->adapters->adapter-transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters->adapter-transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters->adapter-transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.48.3->adapters->adapter-transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.48.3->adapters->adapter-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.48.3->adapters->adapter-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers~=4.48.3->adapters->adapter-transformers) (2023.7.22)\n",
      "Downloading adapters-1.1.1-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Installing collected packages: transformers, adapters, adapter-transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "Successfully installed adapter-transformers-4.0.0 adapters-1.1.1 transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U peft\n",
    "!pip install -U trl\n",
    "!pip install pyarrow==18.1.0\n",
    "!pip install evaluate\n",
    "!pip install --upgrade wandb\n",
    "!pip install adapter-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "import functools # ??\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                        AutoTokenizer,\n",
    "                        AutoModel,\n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                            Trainer,\n",
    "                            DataCollatorWithPadding,\n",
    "                          pipeline, \n",
    "                          logging)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                            f1_score, balanced_accuracy_score)\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, f1_score, roc_curve, auc, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face access\n",
    "\n",
    "from huggingface_hub import login\n",
    "with open(\"../../../../login/hf_key.txt\", 'r') as f: \n",
    "    HF_TOKEN = str(f.read())\n",
    "    \n",
    "login(token = HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melena-solar\u001b[0m (\u001b[33melena-solar-university-of-konstanz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb\n",
    "\n",
    "with open(\"../../../../login/wandb.txt\", 'r') as f: \n",
    "    WB_TOKEN = str(f.read())\n",
    "\n",
    "wandb.login(key=WB_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>agree</td>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't been honest in decades, so I'm cur...   \n",
       "...         ...                                                ...   \n",
       "42838   neutral  Not trying to spark an argument but a legitima...   \n",
       "42839     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840     agree  Why don't I see ads holding Republicans accoun...   \n",
       "42841     agree  How about ... no? This is strange. Community o...   \n",
       "42842     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42839  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42840  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42841  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42842  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1  \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1  \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1  \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0  \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0  \n",
       "...            ...               ...               ...         ...     ...  \n",
       "42838      gyotff1        Republican  19/05/2021 12:36  1621427788       1  \n",
       "42839      gyp3u39         democrats  19/05/2021 13:56  1621432578       2  \n",
       "42840      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2  \n",
       "42841      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2  \n",
       "42842      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2  \n",
       "\n",
       "[42843 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../../../../data/debagree_new_preprocessing_com_rep.csv\")\n",
    "data = data[[\"label\", \"body_parent\", \"body_child\", \"msg_id_parent\", \"msg_id_child\", \"subreddit\", \"datetime\", \"exact_time\"]].sort_values(by = \"exact_time\").reset_index(drop = True)\n",
    "\n",
    "# keep integer labels\n",
    "data['target'] = data['label']\n",
    "\n",
    "# for readability, recode labels\n",
    "int_to_label = {2: \"agree\", 1 : \"neutral\", 0 : \"disagree\"}\n",
    "data.replace({\"label\": int_to_label}, inplace = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "### **Text Length Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "      <th>parent_len</th>\n",
       "      <th>child_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>agree</td>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't been honest in decades, so I'm cur...   \n",
       "...         ...                                                ...   \n",
       "42838   neutral  Not trying to spark an argument but a legitima...   \n",
       "42839     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840     agree  Why don't I see ads holding Republicans accoun...   \n",
       "42841     agree  How about ... no? This is strange. Community o...   \n",
       "42842     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42839  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42840  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42841  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42842  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \\\n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1   \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1   \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1   \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0   \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0   \n",
       "...            ...               ...               ...         ...     ...   \n",
       "42838      gyotff1        Republican  19/05/2021 12:36  1621427788       1   \n",
       "42839      gyp3u39         democrats  19/05/2021 13:56  1621432578       2   \n",
       "42840      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2   \n",
       "42841      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2   \n",
       "42842      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2   \n",
       "\n",
       "       parent_len  child_len  \n",
       "0              17         21  \n",
       "1              17         58  \n",
       "2              12         51  \n",
       "3              18         12  \n",
       "4              13         21  \n",
       "...           ...        ...  \n",
       "42838          29         39  \n",
       "42839          83         26  \n",
       "42840          16         79  \n",
       "42841          17         39  \n",
       "42842          60         80  \n",
       "\n",
       "[42843 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['parent_len'] = data['body_parent'].apply(lambda x: len(x.split()))\n",
    "data['child_len'] = data['body_child'].apply(lambda x: len(x.split()))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Max:  99\n",
      "Child Max:  99\n"
     ]
    }
   ],
   "source": [
    "print(\"Parent Max: \", data['parent_len'].max())\n",
    "print(\"Child Max: \", data['child_len'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>1</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>1</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>agree</td>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>0</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't been honest in decades, so I'm cur...   \n",
       "...         ...                                                ...   \n",
       "42838   neutral  Not trying to spark an argument but a legitima...   \n",
       "42839     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840     agree  Why don't I see ads holding Republicans accoun...   \n",
       "42841     agree  How about ... no? This is strange. Community o...   \n",
       "42842     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42839  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42840  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42841  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42842  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \\\n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       0   \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       0   \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       0   \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       1   \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       1   \n",
       "...            ...               ...               ...         ...     ...   \n",
       "42838      gyotff1        Republican  19/05/2021 12:36  1621427788       0   \n",
       "42839      gyp3u39         democrats  19/05/2021 13:56  1621432578       0   \n",
       "42840      gyp5vzw         democrats  19/05/2021 14:11  1621433471       0   \n",
       "42841      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       0   \n",
       "42842      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       0   \n",
       "\n",
       "               label_2  \n",
       "0      no_disagreement  \n",
       "1      no_disagreement  \n",
       "2      no_disagreement  \n",
       "3             disagree  \n",
       "4             disagree  \n",
       "...                ...  \n",
       "42838  no_disagreement  \n",
       "42839  no_disagreement  \n",
       "42840  no_disagreement  \n",
       "42841  no_disagreement  \n",
       "42842  no_disagreement  \n",
       "\n",
       "[42843 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapt true labels\n",
    "labels_2 = []\n",
    "target_new = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    if row['label'] in ['neutral', 'agree']:\n",
    "        labels_2.append('no_disagreement')\n",
    "        target_new.append(0)\n",
    "    else:\n",
    "        labels_2.append('disagree')\n",
    "        target_new.append(1)\n",
    "        \n",
    "data['label_2'] = labels_2\n",
    "data['target'] = target_new\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "0      I live in rural Saskatchewan, Canada. We have ...   \n",
       "1      I live in rural Saskatchewan, Canada. We have ...   \n",
       "2      Convince her of what? That it's happening or t...   \n",
       "3      I think this prediction is about as valid as s...   \n",
       "4      Mann hasn't been honest in decades, so I'm cur...   \n",
       "...                                                  ...   \n",
       "42838  Not trying to spark an argument but a legitima...   \n",
       "42839  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840  Why don't I see ads holding Republicans accoun...   \n",
       "42841  How about ... no? This is strange. Community o...   \n",
       "42842  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...  no_disagreement   \n",
       "1      One hundred year flood just means a one in one...  no_disagreement   \n",
       "2      That anthropocentric climate change is actuall...  no_disagreement   \n",
       "3      It's January. Literally no one said it would b...         disagree   \n",
       "4      There have been a dozen re-constructions of Ma...         disagree   \n",
       "...                                                  ...              ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42839  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42840  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42841  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42842  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "42838       0  \n",
       "42839       0  \n",
       "42840       0  \n",
       "42841       0  \n",
       "42842       0  \n",
       "\n",
       "[42843 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make text\n",
    "\n",
    "def create_training_data(data):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        #system_prompt = \"\"\"You are a classification Chatbot. Given a comment and a reply, you classify whether the reply disagrees with the comment, or not. You only reply with either \"disagree\" or \"no_disagreement\" and nothing else.\"\"\"\n",
    "        comment = row[\"body_parent\"]\n",
    "        reply = row[\"body_child\"]\n",
    "        label = row[\"label_2\"]\n",
    "        target = row[\"target\"]\n",
    "        result.append({'comment' : comment, 'reply': reply, 'label' : label, 'target' : target})\n",
    "    \n",
    "    return result\n",
    "\n",
    "# save data\n",
    "df = pd.DataFrame(create_training_data(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I live in rural Saskatchewan, Canada....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I live in rural Saskatchewan, Canada....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Convince her of what? That it's happe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: I think this prediction is about as v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Mann hasn't been honest in decades, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Not trying to spark an argument but a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Y'all saw Guilianis hail Mary right? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Why don't I see ads holding Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: How about ... no? This is strange. Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Can you recruit some white allies so ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "0      I live in rural Saskatchewan, Canada. We have ...   \n",
       "1      I live in rural Saskatchewan, Canada. We have ...   \n",
       "2      Convince her of what? That it's happening or t...   \n",
       "3      I think this prediction is about as valid as s...   \n",
       "4      Mann hasn't been honest in decades, so I'm cur...   \n",
       "...                                                  ...   \n",
       "42838  Not trying to spark an argument but a legitima...   \n",
       "42839  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840  Why don't I see ads holding Republicans accoun...   \n",
       "42841  How about ... no? This is strange. Community o...   \n",
       "42842  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...  no_disagreement   \n",
       "1      One hundred year flood just means a one in one...  no_disagreement   \n",
       "2      That anthropocentric climate change is actuall...  no_disagreement   \n",
       "3      It's January. Literally no one said it would b...         disagree   \n",
       "4      There have been a dozen re-constructions of Ma...         disagree   \n",
       "...                                                  ...              ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42839  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42840  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42841  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42842  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target                                             prompt  \n",
       "0           0  Comment: I live in rural Saskatchewan, Canada....  \n",
       "1           0  Comment: I live in rural Saskatchewan, Canada....  \n",
       "2           0  Comment: Convince her of what? That it's happe...  \n",
       "3           1  Comment: I think this prediction is about as v...  \n",
       "4           1  Comment: Mann hasn't been honest in decades, s...  \n",
       "...       ...                                                ...  \n",
       "42838       0  Comment: Not trying to spark an argument but a...  \n",
       "42839       0  Comment: Y'all saw Guilianis hail Mary right? ...  \n",
       "42840       0  Comment: Why don't I see ads holding Republica...  \n",
       "42841       0  Comment: How about ... no? This is strange. Co...  \n",
       "42842       0  Comment: Can you recruit some white allies so ...  \n",
       "\n",
       "[42843 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompt'] = None\n",
    "\n",
    "def make_prompt(row):\n",
    "\n",
    "    prompt = \"Comment: \" + row[\"comment\"] + \"; Reply: \" + row[\"reply\"]\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "df['prompt'] = df.apply(lambda row: make_prompt(row), axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Make train/val/test split by time order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame\n",
    "train_size = 0.8\n",
    "eval_size = 0.1\n",
    "\n",
    "# Determine splitting indexes (ordered by time)\n",
    "train_end = int(train_size * len(df))\n",
    "eval_end = train_end + int(eval_size * len(df))\n",
    "\n",
    "# Split the data\n",
    "X_train = df[:train_end]\n",
    "X_eval = df[train_end:eval_end]\n",
    "X_test = df[eval_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from Pandas DataFrame to Hugging Face Dataset\n",
    "* Also let's shuffle the training set.\n",
    "* We put the components train,val,test into a DatasetDict so we can access them later with HF trainer.\n",
    "* Later we will add a tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['comment', 'reply', 'target', 'prompt'],\n",
       "    num_rows: 4285\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset = Dataset.from_pandas(X_train.drop('label', axis = 1))\n",
    "X_eval_dataset = Dataset.from_pandas(X_eval.drop('label', axis = 1))\n",
    "X_test_dataset = Dataset.from_pandas(X_test.drop('label', axis = 1))\n",
    "\n",
    "X_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle training data --> apparently this helps with performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset_shuffle = X_train_dataset.shuffle(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 34274\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train' : X_train_dataset_shuffle,\n",
    "    'val' : X_eval_dataset,\n",
    "    'test' : X_test_dataset\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.599463\n",
       "1    0.400537\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.target.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights\n",
    "\n",
    "* Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
    "* Convert to pytorch tensor since we will need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4005, 0.5995])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert the weights\n",
    "class_weights = (1/X_train.target.value_counts(normalize = True).sort_index()).to_list()\n",
    "\n",
    "# make a tensor\n",
    "class_weights = torch.tensor(class_weights)\n",
    "\n",
    "# make them sum to one\n",
    "class_weights = class_weights/class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load the Model**\n",
    "\n",
    "Apparently, meta recommends the base version of the model for finetuning [source](https://www.youtube.com/watch?v=YJNbgusTSF0)\n",
    "\n",
    "* load model with 4bit quantization (as specified in bits and bytes) and prepare model for peft training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization for QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4 bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 16, # dimensions of low-rank matrices\n",
    "    lora_alpha = 8, # scaling factor (trade-off) for LoRA activations vs. pretrained weight activations\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'], # where to apply LoRA to\n",
    "    lora_dropout = 0.05, # drop out probability of LoRA layers, to prevent overfitting\n",
    "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
    "    task_type = 'SEQ_CLS'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model\n",
    "\n",
    "* AutoModelForSequenceClassification --> used for classifications\n",
    "* Num of labels is # of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d367bfb8c14612ada7e1ae7ca01971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = quantization_config,\n",
    "    num_labels = 2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to preprocess quantized model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for PEFT training\n",
    "\n",
    "`get_peft_model()` to prepare the model for training with PEFT method such as LoRA by wrapping the base model and PEFT configuration with `get_peft_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tokenizer**\n",
    "\n",
    "### Since LLAMA3 pre-training doesn't have EOS token\n",
    "* Set the pad_token_id to eos_token_id\n",
    "* Set pad token ot eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space = True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Update Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_pt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Apply model to get performance prior to training\n",
    "\n",
    "**Useless, as the model will output random logits $ßto$ it has not learned anything yet**\n",
    "\n",
    "* Use batch size 32 to vectorize and avoid memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Comment: luckily they won't retake the house. Has this piece of shit ever been on any other news channel other than FoxNews, OAN, and NewsMax? This man only speaks and care about his base, he doesn't give a shit about the rest of America.; Reply: I hope you're right but given that the GOP made gains in 2020, let's not be too overconfident 2022 won't have a red wave.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[100]['prompt'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/537 [00:03<04:21,  2.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(batch_sentences, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Move tensors to the device where the model is (e.g., GPU or CPU)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform inference and store the logits\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(batch_sentences, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Move tensors to the device where the model is (e.g., GPU or CPU)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform inference and store the logits\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Convert summaries to a list\n",
    "sentences = X_test.prompt.tolist()\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 8  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "# Initialize an empty list to store the model outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Process the sentences in batches\n",
    "for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "    # Get the batch of sentences\n",
    "    batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "    # Tokenize the batch\n",
    "    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "    # Perform inference and store the logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        all_outputs.append(outputs['logits'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate Outputs into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4675, -2.4747],\n",
       "        [ 2.0257,  0.0061],\n",
       "        [ 0.1863,  0.3972],\n",
       "        ...,\n",
       "        [ 4.6069, -1.0798],\n",
       "        [ 1.2376, -2.0870],\n",
       "        [ 2.0624, -0.1581]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs = torch.cat(all_outputs, dim=0)\n",
    "final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get **probabilities** with softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5018, 0.4982],\n",
      "        [0.8828, 0.1172],\n",
      "        [0.4475, 0.5525],\n",
      "        ...,\n",
      "        [0.9966, 0.0034],\n",
      "        [0.9653, 0.0347],\n",
      "        [0.9021, 0.0979]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "probabilities = F.softmax(final_outputs, dim=1)\n",
    "print(probabilities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = probabilities.argmax(dim=1)  # Get class labels\n",
    "certainty_scores = probabilities.max(dim=1).values  # Get max probability per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5018, 0.8828, 0.5525,  ..., 0.9966, 0.9653, 0.9021], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels\n",
    "certainty_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract predictions and turn to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882/1638758842.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['predictions_label_initial'] = predicted_labels.cpu().numpy()\n",
      "/tmp/ipykernel_882/1638758842.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['predictions_score_initial'] = certainty_scores.cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>prompt</th>\n",
       "      <th>predictions_label_initial</th>\n",
       "      <th>predictions_score_initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38604</th>\n",
       "      <td>It's so nice having a FLOTUS who's facial expr...</td>\n",
       "      <td>Melanoma's squinty cat face always looked to m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: It's so nice having a FLOTUS who's fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38605</th>\n",
       "      <td>Because Mitch McConnell indicated he's voting ...</td>\n",
       "      <td>I think it's worth it because the more we air ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Because Mitch McConnell indicated he'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38606</th>\n",
       "      <td>How about some stimulus checks and a decent st...</td>\n",
       "      <td>You get this was an executive action, not legi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: How about some stimulus checks and a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38607</th>\n",
       "      <td>Satire feels appropriate. I'd like one dose of...</td>\n",
       "      <td>Are you saying they didn't know or understand ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>Comment: Satire feels appropriate. I'd like on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38608</th>\n",
       "      <td>I actually didn't want to upload these particu...</td>\n",
       "      <td>To be fair they are just reporting what Brexit...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: I actually didn't want to upload thes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42889</th>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Not trying to spark an argument but a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42890</th>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Y'all saw Guilianis hail Mary right? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42891</th>\n",
       "      <td>&gt;Why don't I see ads holding Republicans accou...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: &gt;Why don't I see ads holding Republic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42892</th>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: How about ... no? This is strange. Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42893</th>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>0</td>\n",
       "      <td>Comment: Can you recruit some white allies so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "38604  It's so nice having a FLOTUS who's facial expr...   \n",
       "38605  Because Mitch McConnell indicated he's voting ...   \n",
       "38606  How about some stimulus checks and a decent st...   \n",
       "38607  Satire feels appropriate. I'd like one dose of...   \n",
       "38608  I actually didn't want to upload these particu...   \n",
       "...                                                  ...   \n",
       "42889  Not trying to spark an argument but a legitima...   \n",
       "42890  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42891  >Why don't I see ads holding Republicans accou...   \n",
       "42892  How about ... no? This is strange. Community o...   \n",
       "42893  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                                   reply            label  \\\n",
       "38604  Melanoma's squinty cat face always looked to m...  no_disagreement   \n",
       "38605  I think it's worth it because the more we air ...         disagree   \n",
       "38606  You get this was an executive action, not legi...         disagree   \n",
       "38607  Are you saying they didn't know or understand ...         disagree   \n",
       "38608  To be fair they are just reporting what Brexit...  no_disagreement   \n",
       "...                                                  ...              ...   \n",
       "42889  Keeping in mind that the Palestinians killed m...  no_disagreement   \n",
       "42890  Same I want these assholes in jail, full stop....  no_disagreement   \n",
       "42891  Yeah, I agree with the goal of this post but n...  no_disagreement   \n",
       "42892  I know, it feels strange too. We wouldn't hold...  no_disagreement   \n",
       "42893  Ooooo, now I like the taking the day request. ...  no_disagreement   \n",
       "\n",
       "       target                                             prompt  \\\n",
       "38604       0  Comment: It's so nice having a FLOTUS who's fa...   \n",
       "38605       1  Comment: Because Mitch McConnell indicated he'...   \n",
       "38606       1  Comment: How about some stimulus checks and a ...   \n",
       "38607       1  Comment: Satire feels appropriate. I'd like on...   \n",
       "38608       0  Comment: I actually didn't want to upload thes...   \n",
       "...       ...                                                ...   \n",
       "42889       0  Comment: Not trying to spark an argument but a...   \n",
       "42890       0  Comment: Y'all saw Guilianis hail Mary right? ...   \n",
       "42891       0  Comment: >Why don't I see ads holding Republic...   \n",
       "42892       0  Comment: How about ... no? This is strange. Co...   \n",
       "42893       0  Comment: Can you recruit some white allies so ...   \n",
       "\n",
       "       predictions_label_initial  predictions_score_initial  \n",
       "38604                          0                   0.501805  \n",
       "38605                          0                   0.882832  \n",
       "38606                          1                   0.552526  \n",
       "38607                          0                   0.909323  \n",
       "38608                          0                   0.911840  \n",
       "...                          ...                        ...  \n",
       "42889                          0                   0.905063  \n",
       "42890                          0                   0.973733  \n",
       "42891                          0                   0.996621  \n",
       "42892                          0                   0.965263  \n",
       "42893                          0                   0.902083  \n",
       "\n",
       "[4290 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['predictions_label_initial'] = predicted_labels.cpu().numpy()\n",
    "X_test['predictions_score_initial'] = certainty_scores.cpu().numpy()\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictions_label_initial'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictions_label_initial'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m label_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_disagreement\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisagree\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 3\u001b[0m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_initial\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions_label_initial\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m l:label_dict[l])\n\u001b[1;32m      4\u001b[0m X_test\u001b[38;5;66;03m#['predictions_initial']\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictions_label_initial'"
     ]
    }
   ],
   "source": [
    "label_dict = {0 : 'no_disagreement', 1: 'disagree'}\n",
    "\n",
    "X_test['predictions_initial']=X_test['predictions_label_initial'].apply(lambda l:label_dict[l])\n",
    "X_test#['predictions_initial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions_initial\n",
       "no_disagreement    3788\n",
       "disagree            502\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['predictions_initial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"output/v4_Llama_3.1_8B_initial_X_test_2labels_scale.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Three versions of initial performance**\n",
    "\n",
    "$\\to$ has not learned anything yet, so random!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "no_disagreement    2666\n",
       "disagree           1624\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions_initial\n",
       "no_disagreement    3053\n",
       "disagree           1237\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_old = pd.read_csv(\"output/OLD_Llama_3.1_8B_initial_X_test_2labels_scale.csv\")\n",
    "X_test_old['predictions_initial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions_initial\n",
       "no_disagreement    4040\n",
       "disagree            250\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"output/Llama_3.1_8B_initial_X_test_2labels_scale.csv\")\n",
    "X_test['predictions_initial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions_initial\n",
       "no_disagreement    2419\n",
       "disagree           1871\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new = pd.read_csv(\"output/new_1_Llama_3.1_8B_initial_X_test_2labels_scale.csv\")\n",
    "X_test_new['predictions_initial'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why are the predicted labels now so imbalances?! Check reasons/causes!\n",
    "\n",
    "$\\to$ random logits. The model has not learned anything so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test, pred_col):\n",
    "  y_test = df_test.label\n",
    "  y_pred = df_test[pred_col]\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_old' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_performance_metrics(\u001b[43mX_test_old\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_initial\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_old' is not defined"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_test_old, 'predictions_initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  85 1539]\n",
      " [ 165 2501]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       disagree       0.34      0.05      0.09      1624\n",
      "no_disagreement       0.62      0.94      0.75      2666\n",
      "\n",
      "       accuracy                           0.60      4290\n",
      "      macro avg       0.48      0.50      0.42      4290\n",
      "   weighted avg       0.51      0.60      0.50      4290\n",
      "\n",
      "Balanced Accuracy Score: 0.495224714429839\n",
      "Accuracy Score: 0.6027972027972028\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_test, 'predictions_initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 667  957]\n",
      " [1204 1462]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       disagree       0.36      0.41      0.38      1624\n",
      "no_disagreement       0.60      0.55      0.58      2666\n",
      "\n",
      "       accuracy                           0.50      4290\n",
      "      macro avg       0.48      0.48      0.48      4290\n",
      "   weighted avg       0.51      0.50      0.50      4290\n",
      "\n",
      "Balanced Accuracy Score: 0.4795506912442396\n",
      "Accuracy Score: 0.49627039627039626\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_test_new, 'predictions_initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trainer**\n",
    "\n",
    "* model\n",
    "* tokenizer\n",
    "* training arguments\n",
    "* train dataset\n",
    "* eval dataset\n",
    "* Data Collater\n",
    "* Compute Metrics\n",
    "* class_weights: In our case since we are using a custom trainer so we can use a weighted loss we will subclass trainer and define the custom loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LLAMA tokenized dataset which will house our train/val parts during the training process but after applying tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 34274\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comment', 'reply', 'target', 'prompt'],\n",
       "        num_rows: 4285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b31a548de945a09fcbf36fffdd893f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cf103e2b004c8dba1c1707efb6185e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3377b012a299491eb3e8b5e57a069e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "col_to_delete = ['comment', 'reply', 'prompt']\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['prompt'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 34274\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4284\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collator\n",
    "A **data collator** prepares batches of data for training or inference in machine learning, ensuring uniform formatting and adherence to model input requirements. This is especially crucial for variable-sized inputs like text sequences.\n",
    "\n",
    "### Functions of Data Collator\n",
    "\n",
    "1. **Padding:** Uniformly pads sequences to the length of the longest sequence using a special token, allowing simultaneous batch processing.\n",
    "2. **Batching:** Groups individual data points into batches for efficient processing.\n",
    "3. **Handling Special Tokens:** Adds necessary special tokens to sequences.\n",
    "4. **Converting to Tensor:** Transforms data into tensors, the required format for machine learning frameworks.\n",
    "\n",
    "### `DataCollatorWithPadding`\n",
    "\n",
    "The `DataCollatorWithPadding` specifically manages padding, using a tokenizer to ensure that all sequences are padded to the same length for consistent model input.\n",
    "\n",
    "- **Syntax:** `collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)`\n",
    "- **Purpose:** Automatically pads text data to the longest sequence in a batch, crucial for models like BERT or GPT.\n",
    "- **Tokenizer:** Uses the provided `tokenizer` for sequence processing, respecting model-specific vocabulary and formatting rules.\n",
    "\n",
    "This collator is commonly used with libraries like Hugging Face's Transformers, facilitating data preprocessing for various NLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Trainer\n",
    "* We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "***\n",
    "### Training Arguments --> 5 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'Llama_3.1_8B_training_2labels_scale',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 5, # checked up to 5, but overfitting\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882/37245773.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/tmp/ipykernel_882/37245773.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['val'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Run the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/llama/ClassificationLM/Llama_3.1_8B_2labels_scale/wandb/run-20250325_083626-p10fy2pl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/p10fy2pl' target=\"_blank\">Llama_3.1_8B_training_2labels_scale</a></strong> to <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface' target=\"_blank\">https://wandb.ai/elena-solar-university-of-konstanz/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/p10fy2pl' target=\"_blank\">https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/p10fy2pl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21450' max='21450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21450/21450 8:32:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464300</td>\n",
       "      <td>0.443172</td>\n",
       "      <td>0.812316</td>\n",
       "      <td>0.821870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.446552</td>\n",
       "      <td>0.815787</td>\n",
       "      <td>0.826533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.547217</td>\n",
       "      <td>0.808032</td>\n",
       "      <td>0.820937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306700</td>\n",
       "      <td>0.704391</td>\n",
       "      <td>0.810855</td>\n",
       "      <td>0.823735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.952339</td>\n",
       "      <td>0.808707</td>\n",
       "      <td>0.820937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =          5.0\n",
      "  total_flos               = 1021181669GF\n",
      "  train_loss               =       0.3661\n",
      "  train_runtime            =   8:32:26.73\n",
      "  train_samples            =        34315\n",
      "  train_samples_per_second =         5.58\n",
      "  train_steps_per_second   =        0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "# metrics\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = len(X_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(X_train))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "trainer.model.eval()\n",
    "# save\n",
    "trainer.model.save_pretrained(\"Llama_3.1_8B_saved_model_2labels_scale\")\n",
    "\n",
    "trainer.tokenizer.save_pretrained(\"Llama_3.1_8B_saved_model_2labels_scale\")\n",
    "trainer.model.config.save_pretrained(\"Llama_3.1_8B_saved_model_2labels_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Training Arguments --> 2 epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'final_Llama_3.1_8B_training_2labels_scale',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 2, # checked up to 5, but overfitting\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_341/37245773.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/tmp/ipykernel_341/37245773.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['val'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/llama_final/Classification/two_labels/attention_LoRa/wandb/run-20250411_062134-xqg2cvml</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/xqg2cvml' target=\"_blank\">final_Llama_3.1_8B_training_2labels_scale</a></strong> to <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface' target=\"_blank\">https://wandb.ai/elena-solar-university-of-konstanz/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/xqg2cvml' target=\"_blank\">https://wandb.ai/elena-solar-university-of-konstanz/huggingface/runs/xqg2cvml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8570' max='8570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8570/8570 3:21:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.449319</td>\n",
       "      <td>0.791646</td>\n",
       "      <td>0.799486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>0.432709</td>\n",
       "      <td>0.813033</td>\n",
       "      <td>0.825864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         2.0\n",
      "  total_flos               = 401367894GF\n",
      "  train_loss               =      0.4498\n",
      "  train_runtime            =  3:21:55.79\n",
      "  train_samples            =       34274\n",
      "  train_samples_per_second =       5.658\n",
      "  train_steps_per_second   =       0.707\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "# metrics\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = len(X_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(X_train))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "# set to evaulation mode\n",
    "trainer.model.eval() \n",
    "\n",
    "\n",
    "# save LoRa adapters\n",
    "trainer.model.save_pretrained(\"final_Llama_3.1_8B_saved_model_2labels_scale\")\n",
    "\n",
    "tokenizer.save_pretrained(\"final_Llama_3.1_8B_saved_model_2labels_scale\")\n",
    "trainer.model.config.save_pretrained(\"final_Llama_3.1_8B_saved_model_2labels_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =         2.0\n",
      "  total_flos               = 409156285GF\n",
      "  train_loss               =      0.3899\n",
      "  train_runtime            =  3:25:17.47\n",
      "  train_samples            =       34315\n",
      "  train_samples_per_second =       5.572\n",
      "  train_steps_per_second   =       0.697\n"
     ]
    }
   ],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = len(X_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(X_train))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# **Reimport**\n",
    "\n",
    "1. base mode\n",
    "2. then fin etuned adapters\n",
    "3. merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9216225ce7084534bb0f0f606d4807fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B\" \n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4 bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")\n",
    " \n",
    "adapter_path = \"final_Llama_3.1_8B_saved_model_2labels_scale\"\n",
    "\n",
    "# Load the base model first\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = quantization_config\n",
    ")\n",
    "\n",
    "\n",
    "# Load the LoRA adapter on top of it\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"final_Llama_3.1_8B_saved_model_2labels_scale\", add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  \n",
    "model.config.use_cache = False \n",
    "model.config.pretraining_pt = 1\n",
    "\n",
    "# move model to gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 20/134 [00:05<00:33,  3.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 49\u001b[0m\n\u001b[1;32m     43\u001b[0m     df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_ft\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_label_ft\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m l:label_dict[l])\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_test, probs_disagree\n\u001b[0;32m---> 49\u001b[0m X_test, probs_disagree \u001b[38;5;241m=\u001b[39m \u001b[43mmake_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 30\u001b[0m, in \u001b[0;36mmake_predictions\u001b[0;34m(model, df_test, thresh)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;66;03m# Perform inference and store the logits\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m       outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m       all_outputs\u001b[38;5;241m.\u001b[39mappend(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     34\u001b[0m final_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/peft/peft_model.py:1558\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1557\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1558\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:193\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1251\u001b[0m, in \u001b[0;36mLlamaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1251\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1263\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:913\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    902\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    903\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         position_embeddings,\n\u001b[1;32m    911\u001b[0m     )\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 913\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:656\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    655\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 656\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    659\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:242\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 242\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:484\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    480\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    482\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:533\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul4Bit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:462\u001b[0m, in \u001b[0;36mMatMul4Bit.forward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m B_shape[:\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# 1. Dequantize\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# 2. MatmulnN\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(A, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdequantize_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mt(), bias)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# 3. Save state\u001b[39;00m\n\u001b[1;32m    465\u001b[0m ctx\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m quant_state\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dictionary for conversions\n",
    "label_dict = {1: \"disagree\", 0 : \"no_disagreement\"}\n",
    "\n",
    "\n",
    "def make_predictions(model,df_test, thresh):\n",
    "    \n",
    "    model.eval()\n",
    "    # Convert summaries to a list\n",
    "    sentences = df_test.prompt.tolist()\n",
    "    \n",
    "    # Define the batch size\n",
    "    batch_size = 32  # You can adjust this based on your system's memory capacity\n",
    "    \n",
    "    # Initialize an empty list to store the model outputs\n",
    "    all_outputs = []\n",
    "    \n",
    "    # Process the sentences in batches\n",
    "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "      # Get the batch of sentences\n",
    "      batch_sentences = sentences[i:i + batch_size]\n",
    "    \n",
    "      # Tokenize the batch\n",
    "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding = True, truncation=True, max_length=512) #return_tensors=\"pt\", padding=True,\n",
    "    \n",
    "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "    \n",
    "      # Perform inference and store the logits\n",
    "      with torch.no_grad():\n",
    "          outputs = model(**inputs)\n",
    "          all_outputs.append(outputs['logits'])\n",
    "          \n",
    "          \n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    probabilities = F.softmax(final_outputs, dim=1)\n",
    "\n",
    "    probs_disagree = probabilities[:, 1].cpu().numpy()  # index 1 = 'disagree'\n",
    "    predicted_labels = (probs_disagree > thresh).long()  # binary prediction\n",
    "    certainty_scores = torch.max(probabilities, dim=1).values\n",
    "    \n",
    "    df_test['predictions_label_ft'] = predicted_labels.cpu().numpy()\n",
    "    df_test['predictions_score_ft'] = certainty_scores.cpu().numpy()\n",
    "    df_test['predictions_ft'] = df_test['predictions_label_ft'].apply(lambda l:label_dict[l])\n",
    "    \n",
    "    return df_test, probs_disagree\n",
    "  \n",
    "\n",
    "\n",
    "X_test, probs_disagree = make_predictions(model, X_test, thresh = 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"output/Llama_3.1_8B_ft_X_test_2labels_scale.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"output/Llama_3.1_8B_ft_X_test_2labels_scale.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test, pred_col):\n",
    "  y_test = df_test.label\n",
    "  y_pred = df_test[pred_col]\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1335  289]\n",
      " [ 507 2154]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       disagree       0.72      0.82      0.77      1624\n",
      "no_disagreement       0.88      0.81      0.84      2661\n",
      "\n",
      "       accuracy                           0.81      4285\n",
      "      macro avg       0.80      0.82      0.81      4285\n",
      "   weighted avg       0.82      0.81      0.82      4285\n",
      "\n",
      "Balanced Accuracy Score: 0.8157572294944491\n",
      "Accuracy Score: 0.8142357059509918\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(X_test, 'predictions_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Classification Report per Label}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & precision & recall & f1-score & support \\\\\n",
      "\\midrule\n",
      "disagree & 0.72 & 0.82 & 0.77 & 1624.00 \\\\\n",
      "no_disagreement & 0.88 & 0.81 & 0.84 & 2661.00 \\\\\n",
      "accuracy & 0.81 & 0.81 & 0.81 & 0.81 \\\\\n",
      "macro avg & 0.80 & 0.82 & 0.81 & 4285.00 \\\\\n",
      "weighted avg & 0.82 & 0.81 & 0.82 & 4285.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = X_test.label\n",
    "y_pred = X_test['predictions_ft']\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Export to LaTeX table\n",
    "latex_code = df.to_latex(float_format=\"%.2f\", index=True, caption=\"Classification Report per Label\")\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4248, 0.0089, 0.4534,  ..., 0.0356, 0.0112, 0.0305], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "probs_disagree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ROC and Precision-Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_roc_pr_curves(y_true, y_scores, threshold_points=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]):\n",
    "    \n",
    "    # ROC\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Precision-Recall\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # --- ROC Curve ---\n",
    "    ax1.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})', color='darkorange', lw=2)\n",
    "    ax1.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    \n",
    "    # Annotate thresholds on ROC curve\n",
    "    for thresh in threshold_points:\n",
    "        idx = np.argmin(np.abs(roc_thresholds - thresh))\n",
    "        ax1.plot(fpr[idx], tpr[idx], 'o', label=f'Threshold {roc_thresholds[idx]:.2f}')\n",
    "        ax1.annotate(f\"{roc_thresholds[idx]:.2f}\", (fpr[idx], tpr[idx]), textcoords=\"offset points\", xytext=(-10,3), ha='center', fontsize=9)\n",
    "    \n",
    "    ax1.set_title(\"ROC Curve\", fontsize=14)\n",
    "    ax1.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "    ax1.set_ylabel(\"True Positive Rate (Recall)\", fontsize=12)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- PR Curve ---\n",
    "    ax2.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.2f})', color='blue', lw=2)\n",
    "    \n",
    "    # Annotate thresholds on PR curve\n",
    "    for thresh in threshold_points:\n",
    "        idx = np.argmin(np.abs(pr_thresholds - thresh))\n",
    "        ax2.plot(recall[idx], precision[idx], 'o', label=f'Threshold {pr_thresholds[idx]:.2f}')\n",
    "        ax2.annotate(f\"{pr_thresholds[idx]:.2f}\", (recall[idx], precision[idx]), textcoords=\"offset points\", xytext=(10,3), ha='center', fontsize=9)\n",
    "    \n",
    "    ax2.set_title(\"Precision-Recall Curve\", fontsize=14)\n",
    "    ax2.set_xlabel(\"Recall\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Precision\", fontsize=12)\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_scores = probs_disagree.cpu().numpy()  \n",
    "y_true = X_test['label'].apply(lambda x: 1 if x == 'disagree' else 0).values\n",
    "\n",
    "plot_roc_pr_curves(y_true, y_scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6076443,
     "sourceId": 9893468,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68812,
     "sourceId": 108555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
