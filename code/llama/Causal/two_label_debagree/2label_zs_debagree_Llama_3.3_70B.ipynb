{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables and file paths\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "output_path = \"output/Llama_3.3_70B_zs_Debagree_2Labels_sample.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Llama-3.3-70B-Instruct**\n",
    "## **Zero Shot Classification of 2 Labels --> disagree or no disagree**\n",
    "\n",
    "* Ran on sample of 10.000 interactions\n",
    "* Purpose: Compare two vs. three labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting torch<3,>=2.0 (from bitsandbytes)\n",
      "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.24.4)\n",
      "Collecting filelock (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2023.9.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch<3,>=2.0->bitsandbytes)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Using cached bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "Using cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, bitsandbytes\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed bitsandbytes-0.45.5 filelock-3.18.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0 typing-extensions-4.13.1\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.1\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
      "Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n",
      "Collecting peft\n",
      "  Using cached peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.51.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.7.22)\n",
      "Using cached peft-0.15.1-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.1\n",
      "Collecting trl\n",
      "  Using cached trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from trl) (1.6.0)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting rich (from trl)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.51.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.1.1)\n",
      "Collecting requests>=2.32.2 (from datasets>=3.0.0->trl)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=3.0.0->trl)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets>=3.0.0->trl)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.8.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (2.16.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2023.7.22)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Using cached trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, mdurl, dill, multiprocess, markdown-it-py, rich, datasets, trl\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 13.0.0\n",
      "    Uninstalling pyarrow-13.0.0:\n",
      "      Successfully uninstalled pyarrow-13.0.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "Successfully installed datasets-3.5.0 dill-0.3.8 markdown-it-py-3.0.0 mdurl-0.1.2 multiprocess-0.70.16 pyarrow-19.0.1 requests-2.32.3 rich-14.0.0 tqdm-4.67.1 trl-0.16.1 xxhash-3.5.0\n",
      "Collecting pyarrow==18.1.0\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Using cached pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "Successfully installed pyarrow-18.1.0\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U peft\n",
    "!pip install -U trl\n",
    "!pip install pyarrow==18.1.0\n",
    "!pip install evaluate\n",
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "import functools # ??\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import is_bf16_supported\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                        AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                            Trainer,\n",
    "                            DataCollatorWithPadding,\n",
    "                          pipeline, \n",
    "                          logging)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                            f1_score, balanced_accuracy_score)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import ast\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA H100 80GB HBM3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# check GPU's capacity for quantization\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(is_bf16_supported())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Authenticate for Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/llama_final/Causal/two_label_debagree'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face access\n",
    "\n",
    "with open(\"../../../login/hf_key.txt\", 'r') as f: \n",
    "    HF_TOKEN = str(f.read())\n",
    "    \n",
    "login(token = HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>agree</td>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't been honest in decades, so I'm cur...   \n",
       "...         ...                                                ...   \n",
       "42838   neutral  Not trying to spark an argument but a legitima...   \n",
       "42839     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840     agree  Why don't I see ads holding Republicans accoun...   \n",
       "42841     agree  How about ... no? This is strange. Community o...   \n",
       "42842     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42839  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42840  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42841  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42842  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1  \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1  \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1  \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0  \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0  \n",
       "...            ...               ...               ...         ...     ...  \n",
       "42838      gyotff1        Republican  19/05/2021 12:36  1621427788       1  \n",
       "42839      gyp3u39         democrats  19/05/2021 13:56  1621432578       2  \n",
       "42840      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2  \n",
       "42841      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2  \n",
       "42842      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2  \n",
       "\n",
       "[42843 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data = pd.read_csv(\"../../../data/debagree_new_preprocessing_com_rep.csv\")\n",
    "data = data[[\"label\", \"body_parent\", \"body_child\", \"msg_id_parent\", \"msg_id_child\", \"subreddit\", \"datetime\", \"exact_time\"]].sort_values(by = \"exact_time\").reset_index(drop = True)\n",
    "\n",
    "# keep integer labels\n",
    "data['target'] = data['label']\n",
    "\n",
    "# for readability, recode labels\n",
    "int_to_label = {2: \"agree\", 1 : \"neutral\", 0 : \"disagree\"}\n",
    "label_to_int = {\"agree\" : 2, \"neutral\" : 1, \"disagree\" : 0}\n",
    "data.replace({\"label\": int_to_label}, inplace = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample interactions, keeping shares of subreddits and labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_sample_target_size(df, subreddit_col, label_col, total_size):\n",
    "    \"\"\"\n",
    "    Perform a two-level stratified sample:\n",
    "    - First by subreddit (in proportion to their frequency)\n",
    "    - Then by label within each subreddit (preserving label distribution)\n",
    "    \n",
    "    Returns exactly `total_size` rows.\n",
    "    \"\"\"\n",
    "    # subreddit proportions\n",
    "    subreddit_dist = df[subreddit_col].value_counts(normalize=True)\n",
    "\n",
    "    sampled_rows = []\n",
    "\n",
    "    for subreddit, subreddit_prop in subreddit_dist.items():\n",
    "        # nr rows to sample from this subreddit\n",
    "        subreddit_n = int(round(total_size * subreddit_prop))\n",
    "        sub_df = df[df[subreddit_col] == subreddit]\n",
    "\n",
    "        # within subreddit, keep label distribution\n",
    "        label_dist = sub_df[label_col].value_counts(normalize=True)\n",
    "\n",
    "        for label, label_prop in label_dist.items():\n",
    "            label_n = int(round(subreddit_n * label_prop))\n",
    "            label_df = sub_df[sub_df[label_col] == label]\n",
    "            \n",
    "            # Sample, but make sure we don't sample more than we have\n",
    "            actual_n = min(label_n, len(label_df))\n",
    "            if actual_n > 0:\n",
    "                sampled_rows.append(label_df.sample(n=actual_n, random_state=42))\n",
    "\n",
    "    # Combine all, shuffle, and trim to exactly `total_size`\n",
    "    final_df = pd.concat(sampled_rows).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Ensure final size matches (if over, just trim)\n",
    "    return final_df.iloc[:total_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agree</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>09/03/2021 04:29</td>\n",
       "      <td>1615264154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agree</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>03/01/2021 03:02</td>\n",
       "      <td>1609642942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agree</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>10/12/2020 17:23</td>\n",
       "      <td>1607620990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agree</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>18/05/2021 11:30</td>\n",
       "      <td>1621337452</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>06/10/2020 22:56</td>\n",
       "      <td>1602024961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>agree</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>02/02/2020 23:35</td>\n",
       "      <td>1580686536</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>neutral</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>04/11/2020 16:28</td>\n",
       "      <td>1604507309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>agree</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>25/04/2020 03:14</td>\n",
       "      <td>1587784461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>agree</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>08/10/2020 05:34</td>\n",
       "      <td>1602135247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>26/06/2020 21:32</td>\n",
       "      <td>1593207132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                        body_parent  \\\n",
       "0        agree  They shouldn't be winning elections, that's fo...   \n",
       "1        agree  This tells me one thing. COVID was politicized...   \n",
       "2        agree  So, the mini-deals are being discussed because...   \n",
       "3        agree  My sister is a type one diabetic and a biden s...   \n",
       "4     disagree  You guys are so stupid. The difference is that...   \n",
       "...        ...                                                ...   \n",
       "9995     agree  Just like he rigged the Supreme court by not a...   \n",
       "9996   neutral  He needs to grow up fast. Right out of the gat...   \n",
       "9997     agree  I just got banned on  for stating that same fa...   \n",
       "9998     agree  I was liberal until I graduated college, moved...   \n",
       "9999  disagree  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                             body_child msg_id_parent  \\\n",
       "0     I agree with this. They obviously shouldn't be...       gqak9tq   \n",
       "1     Ahh yes planned by the whole world to cover up...       ghrt3ay   \n",
       "2     So believes the EU. And seeing as they hold al...       gfask7y   \n",
       "3     Let's be honest. Trump could have directed to ...       gyj4rst   \n",
       "4     One of them had the flu for a couple days? Whi...       g7xuo23   \n",
       "...                                                 ...           ...   \n",
       "9995  I despise him for doing this. This man has bee...       fgdpkdc   \n",
       "9996       I don't keep up with him but what did he do.       gb4idfe   \n",
       "9997   had this bs as a hotpost today. It irks me th...       fogwj8w   \n",
       "9998  Yeah New York scares me. That and California. ...       g82yc73   \n",
       "9999  More importantly, ECB also blinked and gave in...       fw2qwrh   \n",
       "\n",
       "     msg_id_child   subreddit          datetime  exact_time  target  \n",
       "0         gqalvak   democrats  09/03/2021 04:29  1615264154       2  \n",
       "1         ghw66nh  Republican  03/01/2021 03:02  1609642942       2  \n",
       "2         gfav46i      Brexit  10/12/2020 17:23  1607620990       2  \n",
       "3         gyk1wwh  Republican  18/05/2021 11:30  1621337452       2  \n",
       "4         g7y3wdy  Republican  06/10/2020 22:56  1602024961       0  \n",
       "...           ...         ...               ...         ...     ...  \n",
       "9995      fgdsys2   democrats  02/02/2020 23:35  1580686536       2  \n",
       "9996      gb4ofe7  Republican  04/11/2020 16:28  1604507309       1  \n",
       "9997      foie0e3  Republican  25/04/2020 03:14  1587784461       2  \n",
       "9998      g830mfp  Republican  08/10/2020 05:34  1602135247       2  \n",
       "9999      fw3sqm2      Brexit  26/06/2020 21:32  1593207132       0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = stratified_sample_target_size(data, \"subreddit\", \"label\", 10000)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization for QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4 bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load the Model**\n",
    "\n",
    "* AutoModelForCausalLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19390e4dbb354a138ff72d5b44bcd96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 8192)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=8192, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=8192, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=8192, out_features=28672, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=8192, out_features=28672, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=28672, out_features=8192, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = quantization_config\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizer**\n",
    "\n",
    "### Since LLAMA3 pre-training doesn't have EOS token\n",
    "* Set the pad_token_id to eos_token_id\n",
    "* Set pad token ot eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space = True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Update Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_pt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate Prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     I agree with this. They obviously shouldn't be...     agree       2   \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2   \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2   \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2   \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  I despise him for doing this. This man has bee...     agree       2   \n",
       "9996       I don't keep up with him but what did he do.   neutral       1   \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2   \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2   \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "     msg_id_parent msg_id_child   subreddit  \n",
       "0          gqak9tq      gqalvak   democrats  \n",
       "1          ghrt3ay      ghw66nh  Republican  \n",
       "2          gfask7y      gfav46i      Brexit  \n",
       "3          gyj4rst      gyk1wwh  Republican  \n",
       "4          g7xuo23      g7y3wdy  Republican  \n",
       "...            ...          ...         ...  \n",
       "9995       fgdpkdc      fgdsys2   democrats  \n",
       "9996       gb4idfe      gb4ofe7  Republican  \n",
       "9997       fogwj8w      foie0e3  Republican  \n",
       "9998       g82yc73      g830mfp  Republican  \n",
       "9999       fw2qwrh      fw3sqm2      Brexit  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make text\n",
    "\n",
    "def create_training_data(data):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        system_prompt = \"\"\"You are a classification chatbot. Analyze a Reddit comment and its reply. Determine if the reply explicitly and unambiguously disagrees with the comment. Respond with 'disagree' for clear disagreement or 'no_disagreement' if the reply adds information, qualifies the statement, offers an alternative perspective, or leaves any doubt about disagreement. Your response must strictly be 'disagree' or 'no_disagreement'.\"\"\"\n",
    "        comment = row[\"body_parent\"]\n",
    "        reply = row[\"body_child\"]\n",
    "        label = row[\"label\"]\n",
    "        target = row[\"target\"]\n",
    "        \n",
    "        comment_id = row[\"msg_id_parent\"]\n",
    "        reply_id = row[\"msg_id_child\"]\n",
    "        subreddit = row[\"subreddit\"]\n",
    "        \n",
    "        result.append({'system_prompt' : system_prompt, 'comment' : comment, 'reply': reply, 'label' : label, 'target' : target, 'msg_id_parent' : comment_id, 'msg_id_child' : reply_id, 'subreddit' : subreddit})\n",
    "    \n",
    "    return result\n",
    "\n",
    "# save data\n",
    "df = pd.DataFrame(create_training_data(sample_df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a classification chatbot. Analyze a Reddit comment and its reply. Determine if the reply explicitly and unambiguously disagrees with the comment. Respond with 'disagree' for clear disagreement or 'no_disagreement' if the reply adds information, qualifies the statement, offers an alternative perspective, or leaves any doubt about disagreement. Your response must strictly be 'disagree' or 'no_disagreement'.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\ncomment: 'They shouldn't be winning elections, that's for sure, but I'm not sure how to angle a ban. All that would do is fail when it hit the Supreme Court and give them fuel for their martyr complex' ; reply: 'I agree with this. They obviously shouldn't be holding positions of power, but just outright banning an idea, even a horrible and dangerous one, just won't fly in the supreme court, especially not with the current justices. I think everyone agrees something should be done to get rid of white supremacists, but it's a difficult problem to sort out in a way that will actually stick without further enflaming them and the masses that tolerate them.'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "def make_chat_prompt(row):\n",
    "\n",
    "    temp = [] \n",
    "    temp.append({\"role\": \"system\", \"content\": row['system_prompt']})\n",
    "    temp.append({\"role\": \"user\", \"content\": f\"comment: '{row['comment']}' ; reply: '{row['reply']}'\"})\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(temp, tokenize=False, add_generation_prompt=True )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "df['chat_prompt'] = df.apply(lambda row: make_chat_prompt(row), axis = 1)\n",
    "df['chat_prompt'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## **Apply model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Function to process one prompt column\n",
    "def generate_predictions(df, prompt_column_name, output_column_name):\n",
    "    all_outputs = []\n",
    "\n",
    "    # Get all prompts for the selected strategy\n",
    "    prompts = df[prompt_column_name].tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=f\"Generating for {prompt_column_name}\"):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "\n",
    "        # Tokenize (skip apply_chat_template here — it's already done)\n",
    "        inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=False  # Optional: make deterministic\n",
    "            )\n",
    "\n",
    "        # Decode and collect\n",
    "        decoded = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        all_outputs.extend(decoded)\n",
    "\n",
    "    # Add raw output to the dataframe\n",
    "    df[output_column_name] = all_outputs\n",
    "\n",
    "    # Normalize and clean up (extract just 'agree' or 'disagree' if possible)\n",
    "    df[output_column_name] = df[output_column_name].str.lower().str.strip()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating for chat_prompt:   0%|          | 0/313 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   0%|          | 1/313 [00:06<31:20,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   1%|          | 2/313 [00:11<29:43,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   1%|          | 3/313 [00:16<28:23,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   1%|▏         | 4/313 [00:22<28:28,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   2%|▏         | 5/313 [00:27<28:25,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   2%|▏         | 6/313 [00:33<29:14,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   2%|▏         | 7/313 [00:39<28:52,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   3%|▎         | 8/313 [00:44<28:13,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   3%|▎         | 9/313 [00:50<28:31,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   3%|▎         | 10/313 [00:55<27:57,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   4%|▎         | 11/313 [01:01<27:25,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   4%|▍         | 12/313 [01:06<27:35,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   4%|▍         | 13/313 [01:12<27:36,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   4%|▍         | 14/313 [01:17<27:13,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   5%|▍         | 15/313 [01:23<27:16,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   5%|▌         | 16/313 [01:28<27:27,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   5%|▌         | 17/313 [01:34<27:44,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   6%|▌         | 18/313 [01:40<27:59,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   6%|▌         | 19/313 [01:46<27:39,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   6%|▋         | 20/313 [01:51<27:28,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   7%|▋         | 21/313 [01:57<27:15,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   7%|▋         | 22/313 [02:02<27:00,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   7%|▋         | 23/313 [02:08<26:26,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   8%|▊         | 24/313 [02:13<26:54,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   8%|▊         | 25/313 [02:19<26:32,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   8%|▊         | 26/313 [02:24<26:33,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   9%|▊         | 27/313 [02:30<26:00,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   9%|▉         | 28/313 [02:35<25:50,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:   9%|▉         | 29/313 [02:41<26:01,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  10%|▉         | 30/313 [02:47<26:34,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  10%|▉         | 31/313 [02:52<26:15,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  10%|█         | 32/313 [02:58<26:21,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  11%|█         | 33/313 [03:03<26:14,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  11%|█         | 34/313 [03:09<26:09,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  11%|█         | 35/313 [03:14<25:47,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  12%|█▏        | 36/313 [03:20<26:02,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  12%|█▏        | 37/313 [03:26<25:37,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  12%|█▏        | 38/313 [03:31<25:26,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  12%|█▏        | 39/313 [03:37<25:27,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  13%|█▎        | 40/313 [03:42<25:23,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  13%|█▎        | 41/313 [03:48<25:34,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  13%|█▎        | 42/313 [03:54<25:35,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  14%|█▎        | 43/313 [04:00<25:25,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  14%|█▍        | 44/313 [04:05<25:36,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  14%|█▍        | 45/313 [04:11<25:17,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  15%|█▍        | 46/313 [04:17<25:07,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  15%|█▌        | 47/313 [04:22<24:56,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  15%|█▌        | 48/313 [04:28<24:57,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  16%|█▌        | 49/313 [04:33<24:31,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  16%|█▌        | 50/313 [04:39<24:47,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  16%|█▋        | 51/313 [04:45<24:25,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  17%|█▋        | 52/313 [04:50<24:04,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  17%|█▋        | 53/313 [04:56<24:12,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  17%|█▋        | 54/313 [05:01<23:59,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  18%|█▊        | 55/313 [05:07<23:48,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  18%|█▊        | 56/313 [05:12<23:15,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  18%|█▊        | 57/313 [05:17<22:53,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  19%|█▊        | 58/313 [05:23<23:08,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  19%|█▉        | 59/313 [05:29<23:40,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  19%|█▉        | 60/313 [05:34<23:30,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  19%|█▉        | 61/313 [05:39<23:06,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  20%|█▉        | 62/313 [05:45<23:34,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  20%|██        | 63/313 [05:51<23:05,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  20%|██        | 64/313 [05:56<23:02,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  21%|██        | 65/313 [06:02<22:33,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  21%|██        | 66/313 [06:07<22:28,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  21%|██▏       | 67/313 [06:12<22:10,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  22%|██▏       | 68/313 [06:18<21:58,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  22%|██▏       | 69/313 [06:23<22:10,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  22%|██▏       | 70/313 [06:29<22:04,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  23%|██▎       | 71/313 [06:34<22:09,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  23%|██▎       | 72/313 [06:39<21:45,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  23%|██▎       | 73/313 [06:45<22:12,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  24%|██▎       | 74/313 [06:51<22:03,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  24%|██▍       | 75/313 [06:57<22:15,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  24%|██▍       | 76/313 [07:02<21:56,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  25%|██▍       | 77/313 [07:08<22:40,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  25%|██▍       | 78/313 [07:14<22:13,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  25%|██▌       | 79/313 [07:19<22:08,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  26%|██▌       | 80/313 [07:25<21:48,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  26%|██▌       | 81/313 [07:30<21:16,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  26%|██▌       | 82/313 [07:35<20:57,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  27%|██▋       | 83/313 [07:41<21:03,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  27%|██▋       | 84/313 [07:47<21:34,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  27%|██▋       | 85/313 [07:53<21:14,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  27%|██▋       | 86/313 [07:58<21:16,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  28%|██▊       | 87/313 [08:04<21:11,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  28%|██▊       | 88/313 [08:10<21:11,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  28%|██▊       | 89/313 [08:15<21:03,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  29%|██▉       | 90/313 [08:21<20:46,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  29%|██▉       | 91/313 [08:26<20:16,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  29%|██▉       | 92/313 [08:32<20:39,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  30%|██▉       | 93/313 [08:37<20:22,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  30%|███       | 94/313 [08:43<20:26,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  30%|███       | 95/313 [08:48<20:17,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  31%|███       | 96/313 [08:54<20:04,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  31%|███       | 97/313 [08:59<19:56,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  31%|███▏      | 98/313 [09:05<19:45,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  32%|███▏      | 99/313 [09:11<19:47,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  32%|███▏      | 100/313 [09:16<19:20,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  32%|███▏      | 101/313 [09:22<19:35,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  33%|███▎      | 102/313 [09:27<19:44,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  33%|███▎      | 103/313 [09:33<19:29,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  33%|███▎      | 104/313 [09:38<19:22,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  34%|███▎      | 105/313 [09:44<19:11,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  34%|███▍      | 106/313 [09:50<19:27,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  34%|███▍      | 107/313 [09:55<19:19,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  35%|███▍      | 108/313 [10:01<19:12,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  35%|███▍      | 109/313 [10:06<18:51,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  35%|███▌      | 110/313 [10:12<19:05,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  35%|███▌      | 111/313 [10:18<19:13,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  36%|███▌      | 112/313 [10:24<19:02,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  36%|███▌      | 113/313 [10:29<18:56,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  36%|███▋      | 114/313 [10:35<18:57,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  37%|███▋      | 115/313 [10:41<18:40,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  37%|███▋      | 116/313 [10:46<18:19,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  37%|███▋      | 117/313 [10:52<18:36,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  38%|███▊      | 118/313 [10:58<18:21,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  38%|███▊      | 119/313 [11:04<18:41,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  38%|███▊      | 120/313 [11:09<18:25,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  39%|███▊      | 121/313 [11:15<18:38,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  39%|███▉      | 122/313 [11:21<18:12,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  39%|███▉      | 123/313 [11:27<18:24,  5.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  40%|███▉      | 124/313 [11:32<18:08,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  40%|███▉      | 125/313 [11:38<17:58,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  40%|████      | 126/313 [11:43<17:28,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  41%|████      | 127/313 [11:49<17:12,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  41%|████      | 128/313 [11:54<16:58,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  41%|████      | 129/313 [12:00<17:04,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  42%|████▏     | 130/313 [12:06<17:12,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  42%|████▏     | 131/313 [12:11<16:40,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  42%|████▏     | 132/313 [12:17<16:53,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  42%|████▏     | 133/313 [12:22<16:43,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  43%|████▎     | 134/313 [12:28<16:39,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  43%|████▎     | 135/313 [12:33<16:34,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  43%|████▎     | 136/313 [12:39<16:10,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  44%|████▍     | 137/313 [12:44<16:09,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  44%|████▍     | 138/313 [12:50<16:04,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  44%|████▍     | 139/313 [12:56<16:10,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  45%|████▍     | 140/313 [13:00<15:33,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  45%|████▌     | 141/313 [13:06<15:35,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  45%|████▌     | 142/313 [13:11<15:22,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  46%|████▌     | 143/313 [13:17<15:09,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  46%|████▌     | 144/313 [13:22<15:30,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  46%|████▋     | 145/313 [13:28<15:15,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  47%|████▋     | 146/313 [13:33<15:02,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  47%|████▋     | 147/313 [13:39<15:01,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  47%|████▋     | 148/313 [13:44<15:17,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  48%|████▊     | 149/313 [13:50<14:56,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  48%|████▊     | 150/313 [13:55<14:55,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  48%|████▊     | 151/313 [14:00<14:36,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  49%|████▊     | 152/313 [14:06<14:41,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  49%|████▉     | 153/313 [14:12<15:02,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  49%|████▉     | 154/313 [14:17<14:46,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  50%|████▉     | 155/313 [14:23<14:54,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  50%|████▉     | 156/313 [14:29<14:46,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  50%|█████     | 157/313 [14:35<14:53,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  50%|█████     | 158/313 [14:40<14:39,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  51%|█████     | 159/313 [14:46<14:17,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  51%|█████     | 160/313 [14:51<14:05,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  51%|█████▏    | 161/313 [14:57<14:12,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  52%|█████▏    | 162/313 [15:03<14:10,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  52%|█████▏    | 163/313 [15:08<13:57,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  52%|█████▏    | 164/313 [15:13<13:35,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  53%|█████▎    | 165/313 [15:19<13:19,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  53%|█████▎    | 166/313 [15:24<13:29,  5.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  53%|█████▎    | 167/313 [15:30<13:18,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  54%|█████▎    | 168/313 [15:36<13:38,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  54%|█████▍    | 169/313 [15:41<13:25,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  54%|█████▍    | 170/313 [15:47<13:12,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  55%|█████▍    | 171/313 [15:53<13:20,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  55%|█████▍    | 172/313 [15:58<13:04,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  55%|█████▌    | 173/313 [16:04<13:05,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  56%|█████▌    | 174/313 [16:09<13:06,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  56%|█████▌    | 175/313 [16:15<13:09,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  56%|█████▌    | 176/313 [16:21<12:51,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  57%|█████▋    | 177/313 [16:26<12:33,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  57%|█████▋    | 178/313 [16:32<12:25,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  57%|█████▋    | 179/313 [16:37<12:23,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  58%|█████▊    | 180/313 [16:42<12:08,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  58%|█████▊    | 181/313 [16:48<12:00,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  58%|█████▊    | 182/313 [16:54<12:08,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  58%|█████▊    | 183/313 [17:00<12:17,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  59%|█████▉    | 184/313 [17:05<12:02,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  59%|█████▉    | 185/313 [17:11<12:16,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  59%|█████▉    | 186/313 [17:17<12:10,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  60%|█████▉    | 187/313 [17:23<12:16,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  60%|██████    | 188/313 [17:28<11:56,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  60%|██████    | 189/313 [17:34<11:47,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  61%|██████    | 190/313 [17:39<11:29,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  61%|██████    | 191/313 [17:45<11:24,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  61%|██████▏   | 192/313 [17:51<11:27,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  62%|██████▏   | 193/313 [17:56<11:05,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  62%|██████▏   | 194/313 [18:01<10:51,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  62%|██████▏   | 195/313 [18:07<10:54,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  63%|██████▎   | 196/313 [18:12<10:41,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  63%|██████▎   | 197/313 [18:18<10:33,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  63%|██████▎   | 198/313 [18:23<10:26,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  64%|██████▎   | 199/313 [18:29<10:26,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  64%|██████▍   | 200/313 [18:35<10:27,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  64%|██████▍   | 201/313 [18:41<10:34,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  65%|██████▍   | 202/313 [18:46<10:21,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  65%|██████▍   | 203/313 [18:52<10:15,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  65%|██████▌   | 204/313 [18:57<10:08,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  65%|██████▌   | 205/313 [19:03<10:09,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  66%|██████▌   | 206/313 [19:08<10:00,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  66%|██████▌   | 207/313 [19:14<09:50,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  66%|██████▋   | 208/313 [19:20<09:48,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  67%|██████▋   | 209/313 [19:26<09:53,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  67%|██████▋   | 210/313 [19:31<09:42,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  67%|██████▋   | 211/313 [19:36<09:25,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  68%|██████▊   | 212/313 [19:42<09:21,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  68%|██████▊   | 213/313 [19:48<09:20,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  68%|██████▊   | 214/313 [19:54<09:27,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  69%|██████▊   | 215/313 [20:00<09:23,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  69%|██████▉   | 216/313 [20:05<09:15,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  69%|██████▉   | 217/313 [20:10<08:57,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  70%|██████▉   | 218/313 [20:16<08:55,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  70%|██████▉   | 219/313 [20:22<08:51,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  70%|███████   | 220/313 [20:27<08:44,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  71%|███████   | 221/313 [20:33<08:46,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  71%|███████   | 222/313 [20:39<08:46,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  71%|███████   | 223/313 [20:45<08:39,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  72%|███████▏  | 224/313 [20:50<08:20,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  72%|███████▏  | 225/313 [20:56<08:10,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  72%|███████▏  | 226/313 [21:02<08:09,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  73%|███████▎  | 227/313 [21:07<08:02,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  73%|███████▎  | 228/313 [21:13<07:54,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  73%|███████▎  | 229/313 [21:18<07:47,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  73%|███████▎  | 230/313 [21:23<07:33,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  74%|███████▍  | 231/313 [21:29<07:20,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  74%|███████▍  | 232/313 [21:34<07:17,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  74%|███████▍  | 233/313 [21:39<07:06,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  75%|███████▍  | 234/313 [21:45<07:11,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  75%|███████▌  | 235/313 [21:50<06:58,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  75%|███████▌  | 236/313 [21:55<06:49,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  76%|███████▌  | 237/313 [22:01<06:50,  5.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  76%|███████▌  | 238/313 [22:07<06:51,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  76%|███████▋  | 239/313 [22:13<06:55,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  77%|███████▋  | 240/313 [22:18<06:55,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  77%|███████▋  | 241/313 [22:24<06:51,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  77%|███████▋  | 242/313 [22:30<06:45,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  78%|███████▊  | 243/313 [22:35<06:31,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  78%|███████▊  | 244/313 [22:41<06:29,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  78%|███████▊  | 245/313 [22:46<06:20,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  79%|███████▊  | 246/313 [22:52<06:11,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  79%|███████▉  | 247/313 [22:58<06:15,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  79%|███████▉  | 248/313 [23:03<06:00,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  80%|███████▉  | 249/313 [23:09<05:55,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  80%|███████▉  | 250/313 [23:14<05:48,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  80%|████████  | 251/313 [23:20<05:43,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  81%|████████  | 252/313 [23:25<05:36,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  81%|████████  | 253/313 [23:31<05:42,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  81%|████████  | 254/313 [23:37<05:33,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  81%|████████▏ | 255/313 [23:43<05:29,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  82%|████████▏ | 256/313 [23:48<05:22,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  82%|████████▏ | 257/313 [23:54<05:14,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  82%|████████▏ | 258/313 [23:59<05:07,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  83%|████████▎ | 259/313 [24:05<05:07,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  83%|████████▎ | 260/313 [24:11<04:55,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  83%|████████▎ | 261/313 [24:16<04:51,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  84%|████████▎ | 262/313 [24:22<04:45,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  84%|████████▍ | 263/313 [24:27<04:38,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  84%|████████▍ | 264/313 [24:33<04:31,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  85%|████████▍ | 265/313 [24:38<04:21,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  85%|████████▍ | 266/313 [24:43<04:16,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  85%|████████▌ | 267/313 [24:49<04:14,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  86%|████████▌ | 268/313 [24:55<04:11,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  86%|████████▌ | 269/313 [25:01<04:09,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  86%|████████▋ | 270/313 [25:07<04:09,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  87%|████████▋ | 271/313 [25:12<03:59,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  87%|████████▋ | 272/313 [25:17<03:45,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  87%|████████▋ | 273/313 [25:23<03:39,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  88%|████████▊ | 274/313 [25:28<03:30,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  88%|████████▊ | 275/313 [25:34<03:28,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  88%|████████▊ | 276/313 [25:39<03:25,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  88%|████████▊ | 277/313 [25:45<03:21,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  89%|████████▉ | 278/313 [25:51<03:15,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  89%|████████▉ | 279/313 [25:56<03:09,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  89%|████████▉ | 280/313 [26:02<03:02,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  90%|████████▉ | 281/313 [26:07<03:00,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  90%|█████████ | 282/313 [26:13<02:55,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  90%|█████████ | 283/313 [26:19<02:50,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  91%|█████████ | 284/313 [26:24<02:43,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  91%|█████████ | 285/313 [26:30<02:37,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  91%|█████████▏| 286/313 [26:36<02:30,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  92%|█████████▏| 287/313 [26:41<02:24,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  92%|█████████▏| 288/313 [26:47<02:21,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  92%|█████████▏| 289/313 [26:53<02:15,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  93%|█████████▎| 290/313 [26:58<02:10,  5.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  93%|█████████▎| 291/313 [27:04<02:02,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  93%|█████████▎| 292/313 [27:09<01:55,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  94%|█████████▎| 293/313 [27:14<01:49,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  94%|█████████▍| 294/313 [27:20<01:45,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  94%|█████████▍| 295/313 [27:26<01:39,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  95%|█████████▍| 296/313 [27:31<01:34,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  95%|█████████▍| 297/313 [27:37<01:30,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  95%|█████████▌| 298/313 [27:43<01:25,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  96%|█████████▌| 299/313 [27:48<01:18,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  96%|█████████▌| 300/313 [27:54<01:13,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  96%|█████████▌| 301/313 [28:00<01:07,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  96%|█████████▋| 302/313 [28:05<01:01,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  97%|█████████▋| 303/313 [28:10<00:54,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  97%|█████████▋| 304/313 [28:16<00:49,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  97%|█████████▋| 305/313 [28:21<00:44,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  98%|█████████▊| 306/313 [28:27<00:38,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  98%|█████████▊| 307/313 [28:32<00:33,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  98%|█████████▊| 308/313 [28:38<00:27,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  99%|█████████▊| 309/313 [28:44<00:22,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  99%|█████████▉| 310/313 [28:49<00:16,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt:  99%|█████████▉| 311/313 [28:55<00:11,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt: 100%|█████████▉| 312/313 [29:00<00:05,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Generating for chat_prompt: 100%|██████████| 313/313 [29:04<00:00,  5.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>chat_prompt</th>\n",
       "      <th>predicted_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     I agree with this. They obviously shouldn't be...     agree       2   \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2   \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2   \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2   \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  I despise him for doing this. This man has bee...     agree       2   \n",
       "9996       I don't keep up with him but what did he do.   neutral       1   \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2   \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2   \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "     msg_id_parent msg_id_child   subreddit  \\\n",
       "0          gqak9tq      gqalvak   democrats   \n",
       "1          ghrt3ay      ghw66nh  Republican   \n",
       "2          gfask7y      gfav46i      Brexit   \n",
       "3          gyj4rst      gyk1wwh  Republican   \n",
       "4          g7xuo23      g7y3wdy  Republican   \n",
       "...            ...          ...         ...   \n",
       "9995       fgdpkdc      fgdsys2   democrats   \n",
       "9996       gb4idfe      gb4ofe7  Republican   \n",
       "9997       fogwj8w      foie0e3  Republican   \n",
       "9998       g82yc73      g830mfp  Republican   \n",
       "9999       fw2qwrh      fw3sqm2      Brexit   \n",
       "\n",
       "                                            chat_prompt  \\\n",
       "0     <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1     <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2     <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3     <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4     <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "...                                                 ...   \n",
       "9995  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "9996  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "9997  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "9998  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "9999  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                         predicted_chat  \n",
       "0     system\\n\\ncutting knowledge date: december 202...  \n",
       "1     system\\n\\ncutting knowledge date: december 202...  \n",
       "2     system\\n\\ncutting knowledge date: december 202...  \n",
       "3     system\\n\\ncutting knowledge date: december 202...  \n",
       "4     system\\n\\ncutting knowledge date: december 202...  \n",
       "...                                                 ...  \n",
       "9995  system\\n\\ncutting knowledge date: december 202...  \n",
       "9996  system\\n\\ncutting knowledge date: december 202...  \n",
       "9997  system\\n\\ncutting knowledge date: december 202...  \n",
       "9998  system\\n\\ncutting knowledge date: december 202...  \n",
       "9999  system\\n\\ncutting knowledge date: december 202...  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat\n",
    "df = generate_predictions(df, \"chat_prompt\", \"predicted_chat\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "cutting knowledge date: december 2023\n",
      "today date: 26 jul 2024\n",
      "\n",
      "you are a classification chatbot. analyze a reddit comment and its reply. determine if the reply explicitly and unambiguously disagrees with the comment. respond with 'disagree' for clear disagreement or 'no_disagreement' if the reply adds information, qualifies the statement, offers an alternative perspective, or leaves any doubt about disagreement. your response must strictly be 'disagree' or 'no_disagreement'.user\n",
      "\n",
      "comment: 'they shouldn't be winning elections, that's for sure, but i'm not sure how to angle a ban. all that would do is fail when it hit the supreme court and give them fuel for their martyr complex' ; reply: 'i agree with this. they obviously shouldn't be holding positions of power, but just outright banning an idea, even a horrible and dangerous one, just won't fly in the supreme court, especially not with the current justices. i think everyone agrees something should be done to get rid of white supremacists, but it's a difficult problem to sort out in a way that will actually stick without further enflaming them and the masses that tolerate them.'assistant\n",
      "\n",
      "no_disagreement\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "\n",
    "print(df['predicted_chat'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_chat\n",
       "no_disagreement    7679\n",
       "disagree           2321\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract\n",
    "df['predicted_chat'] = df['predicted_chat'].apply(lambda x: x.split()[-1].strip(\".\"))\n",
    "\n",
    "df['predicted_chat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>chat_prompt</th>\n",
       "      <th>predicted_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     I agree with this. They obviously shouldn't be...     agree       2   \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2   \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2   \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2   \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  I despise him for doing this. This man has bee...     agree       2   \n",
       "9996       I don't keep up with him but what did he do.   neutral       1   \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2   \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2   \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "     msg_id_parent msg_id_child   subreddit  \\\n",
       "0          gqak9tq      gqalvak   democrats   \n",
       "1          ghrt3ay      ghw66nh  Republican   \n",
       "2          gfask7y      gfav46i      Brexit   \n",
       "3          gyj4rst      gyk1wwh  Republican   \n",
       "4          g7xuo23      g7y3wdy  Republican   \n",
       "...            ...          ...         ...   \n",
       "9995       fgdpkdc      fgdsys2   democrats   \n",
       "9996       gb4idfe      gb4ofe7  Republican   \n",
       "9997       fogwj8w      foie0e3  Republican   \n",
       "9998       g82yc73      g830mfp  Republican   \n",
       "9999       fw2qwrh      fw3sqm2      Brexit   \n",
       "\n",
       "                                            chat_prompt   predicted_chat  \n",
       "0     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "1     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "2     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "3     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "4     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "...                                                 ...              ...  \n",
       "9995  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9996  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9997  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9998  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9999  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode to two labels\n",
    "df['label_2'] = df['label'].map(lambda x: 'no_disagreement' if x in ['neutral', 'agree'] else 'disagree')\n",
    "\n",
    "df.to_csv(output_path, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_share_and_performance(df, true_col, pred_col, valid_responses):\n",
    "\n",
    "    share = len(df[df[pred_col].isin(valid_reponses)]) / len(df)\n",
    "    print(\"Valid Share of Responses: \", share)\n",
    "\n",
    "    valid_df = df[df[pred_col].isin(valid_reponses)]\n",
    "\n",
    "    # performance\n",
    "    y_test = valid_df[true_col]\n",
    "    y_pred = valid_df[pred_col]\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "    return valid_df\n",
    "\n",
    "\n",
    "valid_reponses = ['disagree', 'no_disagreement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Share of Responses:  1.0\n",
      "Confusion Matrix:\n",
      "[[1624 2332]\n",
      " [ 697 5347]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       disagree       0.70      0.41      0.52      3956\n",
      "no_disagreement       0.70      0.88      0.78      6044\n",
      "\n",
      "       accuracy                           0.70     10000\n",
      "      macro avg       0.70      0.65      0.65     10000\n",
      "   weighted avg       0.70      0.70      0.68     10000\n",
      "\n",
      "Balanced Accuracy Score: 0.6475973464562872\n",
      "Accuracy Score: 0.6971\n"
     ]
    }
   ],
   "source": [
    "valid_chat = get_valid_share_and_performance(df, 'label_2', 'predicted_chat', valid_reponses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Error Investigation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>chat_prompt</th>\n",
       "      <th>predicted_chat</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>When Biden wins we should all act like trump p...</td>\n",
       "      <td>I don't know if I would be capable of being th...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>gb5yw8o</td>\n",
       "      <td>gb5zc90</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Brilliant. The democrats patronizing black peo...</td>\n",
       "      <td>Can you cite the source of law-makers stating ...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>gx9wjwa</td>\n",
       "      <td>gxavosm</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I wish there was a way to push up the election...</td>\n",
       "      <td>If you think Trump is bad now, just wait for t...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fn7iyqu</td>\n",
       "      <td>fn7on7t</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I saw 2 masks throughout that whole video. I h...</td>\n",
       "      <td>I had the same thought but then I realized tha...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>gcen7s4</td>\n",
       "      <td>gcfj64r</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Fancy. I wonder who ever said nobody would eve...</td>\n",
       "      <td>FDI was widely predicted to decrease, not incr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>gvbbdr2</td>\n",
       "      <td>gvbbixg</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Don't extend, withdraw! there is nothing to st...</td>\n",
       "      <td>We couldn't withdraw and reactivate just to ex...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>eeol46o</td>\n",
       "      <td>eeosaka</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Wait, what if trump wins pa,bc,AK, ga, and nv....</td>\n",
       "      <td>President gets decided by the house if they bo...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>gb5yg96</td>\n",
       "      <td>gb64nea</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Still more have your cake and eat it. This is ...</td>\n",
       "      <td>What items are you classing here as having you...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>dln7029</td>\n",
       "      <td>dln7gjs</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "3024  You are a classification chatbot. Analyze a Re...   \n",
       "3025  You are a classification chatbot. Analyze a Re...   \n",
       "3026  You are a classification chatbot. Analyze a Re...   \n",
       "3027  You are a classification chatbot. Analyze a Re...   \n",
       "3028  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     You guys are so stupid. The difference is that...   \n",
       "1     When Biden wins we should all act like trump p...   \n",
       "2     Brilliant. The democrats patronizing black peo...   \n",
       "3     I wish there was a way to push up the election...   \n",
       "4     I saw 2 masks throughout that whole video. I h...   \n",
       "...                                                 ...   \n",
       "3024  Fancy. I wonder who ever said nobody would eve...   \n",
       "3025  Don't extend, withdraw! there is nothing to st...   \n",
       "3026  Wait, what if trump wins pa,bc,AK, ga, and nv....   \n",
       "3027  Still more have your cake and eat it. This is ...   \n",
       "3028  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "1     I don't know if I would be capable of being th...  disagree       0   \n",
       "2     Can you cite the source of law-makers stating ...  disagree       0   \n",
       "3     If you think Trump is bad now, just wait for t...  disagree       0   \n",
       "4     I had the same thought but then I realized tha...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "3024  FDI was widely predicted to decrease, not incr...   neutral       1   \n",
       "3025  We couldn't withdraw and reactivate just to ex...  disagree       0   \n",
       "3026  President gets decided by the house if they bo...  disagree       0   \n",
       "3027  What items are you classing here as having you...  disagree       0   \n",
       "3028  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "     msg_id_parent msg_id_child         subreddit  \\\n",
       "0          g7xuo23      g7y3wdy        Republican   \n",
       "1          gb5yw8o      gb5zc90         democrats   \n",
       "2          gx9wjwa      gxavosm        Republican   \n",
       "3          fn7iyqu      fn7on7t         democrats   \n",
       "4          gcen7s4      gcfj64r  BlackLivesMatter   \n",
       "...            ...          ...               ...   \n",
       "3024       gvbbdr2      gvbbixg            Brexit   \n",
       "3025       eeol46o      eeosaka            Brexit   \n",
       "3026       gb5yg96      gb64nea        Republican   \n",
       "3027       dln7029      dln7gjs            Brexit   \n",
       "3028       fw2qwrh      fw3sqm2            Brexit   \n",
       "\n",
       "                                            chat_prompt   predicted_chat  \\\n",
       "0     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "1     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "2     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "3     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "4     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "...                                                 ...              ...   \n",
       "3024  <|begin_of_text|><|start_header_id|>system<|en...         disagree   \n",
       "3025  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "3026  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "3027  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "3028  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement   \n",
       "\n",
       "              label_2  \n",
       "0            disagree  \n",
       "1            disagree  \n",
       "2            disagree  \n",
       "3            disagree  \n",
       "4            disagree  \n",
       "...               ...  \n",
       "3024  no_disagreement  \n",
       "3025         disagree  \n",
       "3026         disagree  \n",
       "3027         disagree  \n",
       "3028         disagree  \n",
       "\n",
       "[3029 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_errors(df, pred_col, true_col):\n",
    "\n",
    "    errors = df[df[pred_col] != df[true_col]].reset_index(drop = True)\n",
    "\n",
    "    return errors\n",
    "\n",
    "errors_chat = get_errors(valid_chat, 'predicted_chat', 'label_2')\n",
    "errors_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_cm(df, pred_col):\n",
    "    print(df['label_2'].value_counts())\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(df['label_2'], df[pred_col])\n",
    "    labels = sorted(set(df['label_2']).union(set(df[pred_col])))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"Confusion Matrix: {pred_col}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_2\n",
      "disagree           2332\n",
      "no_disagreement     697\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_cm(errors_chat, 'predicted_chat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "* 2332 / (2332 + 697) = 0.76989 percent of the errors are predicted no_disagreement, when in fact it is disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3029\n",
      "0.7698910531528558\n"
     ]
    }
   ],
   "source": [
    "print((2332 + 697))\n",
    "print(2332 / (2332 + 697))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_2\n",
      "no_disagreement    6044\n",
      "disagree           3956\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_cm(df, 'predicted_chat')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6076443,
     "sourceId": 9893468,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68812,
     "sourceId": 108555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
