{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables and file paths\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "output_path_sample = \"output/Llama_3.3_70B_zs_Debagree_3labels_sample.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Llama-3.3-70B-Instruct**\n",
    "## **Zero Shot Classification of 3 Labels (agree/disagree/neutral)**\n",
    "\n",
    "* Ran on sample of 10.000 interactions\n",
    "* Purpose: Compare two vs. three labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.24.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.51.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.51.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from trl) (3.5.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.51.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.0.0->trl) (3.8.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->trl) (2.16.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.13.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2023.7.22)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Requirement already satisfied: pyarrow==18.1.0 in /opt/conda/lib/python3.11/site-packages (18.1.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.24.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U transformers\n",
    "!pip install -U accelerate\n",
    "!pip install -U peft\n",
    "!pip install -U trl\n",
    "!pip install pyarrow==18.1.0\n",
    "!pip install evaluate\n",
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import evaluate\n",
    "import functools # ??\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, PeftConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                        AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                            Trainer,\n",
    "                            DataCollatorWithPadding,\n",
    "                          pipeline, \n",
    "                          logging)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix,\n",
    "                            f1_score, balanced_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Authenticate for Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/llama_final/Causal/three_label_debagree'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face access\n",
    "from huggingface_hub import login\n",
    "with open(\"../../../login/hf_key.txt\", 'r') as f: \n",
    "    HF_TOKEN = str(f.read())\n",
    "    \n",
    "login(token = HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>I'm in NE USA we've had 3 in two years...all e...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndj2gv</td>\n",
       "      <td>climate</td>\n",
       "      <td>03/01/2015 23:18</td>\n",
       "      <td>1420327135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I live in rural Saskatchewan, Canada. We have ...</td>\n",
       "      <td>One hundred year flood just means a one in one...</td>\n",
       "      <td>cnddov1</td>\n",
       "      <td>cndkpy7</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 00:10</td>\n",
       "      <td>1420330231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Convince her of what? That it's happening or t...</td>\n",
       "      <td>That anthropocentric climate change is actuall...</td>\n",
       "      <td>cndnlrd</td>\n",
       "      <td>cndnsxt</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 01:45</td>\n",
       "      <td>1420335952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disagree</td>\n",
       "      <td>I think this prediction is about as valid as s...</td>\n",
       "      <td>It's January. Literally no one said it would b...</td>\n",
       "      <td>cndl5x4</td>\n",
       "      <td>cndybsy</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 08:01</td>\n",
       "      <td>1420358465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Mann hasn't been honest in decades, so I'm cur...</td>\n",
       "      <td>There have been a dozen re-constructions of Ma...</td>\n",
       "      <td>cne462t</td>\n",
       "      <td>cne89ej</td>\n",
       "      <td>climate</td>\n",
       "      <td>04/01/2015 17:45</td>\n",
       "      <td>1420393544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42838</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Not trying to spark an argument but a legitima...</td>\n",
       "      <td>Keeping in mind that the Palestinians killed m...</td>\n",
       "      <td>gyo197v</td>\n",
       "      <td>gyotff1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>19/05/2021 12:36</td>\n",
       "      <td>1621427788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42839</th>\n",
       "      <td>agree</td>\n",
       "      <td>Y'all saw Guilianis hail Mary right? Get his s...</td>\n",
       "      <td>Same I want these assholes in jail, full stop....</td>\n",
       "      <td>gynfsu4</td>\n",
       "      <td>gyp3u39</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 13:56</td>\n",
       "      <td>1621432578</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42840</th>\n",
       "      <td>agree</td>\n",
       "      <td>Why don't I see ads holding Republicans accoun...</td>\n",
       "      <td>Yeah, I agree with the goal of this post but n...</td>\n",
       "      <td>gyn6nzm</td>\n",
       "      <td>gyp5vzw</td>\n",
       "      <td>democrats</td>\n",
       "      <td>19/05/2021 14:11</td>\n",
       "      <td>1621433471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42841</th>\n",
       "      <td>agree</td>\n",
       "      <td>How about ... no? This is strange. Community o...</td>\n",
       "      <td>I know, it feels strange too. We wouldn't hold...</td>\n",
       "      <td>gyp71o7</td>\n",
       "      <td>gyp7en6</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:21</td>\n",
       "      <td>1621434116</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>agree</td>\n",
       "      <td>Can you recruit some white allies so you aren'...</td>\n",
       "      <td>Ooooo, now I like the taking the day request. ...</td>\n",
       "      <td>gyp7b89</td>\n",
       "      <td>gyp7vjv</td>\n",
       "      <td>BlackLivesMatter</td>\n",
       "      <td>19/05/2021 14:25</td>\n",
       "      <td>1621434314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42843 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                        body_parent  \\\n",
       "0       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "1       neutral  I live in rural Saskatchewan, Canada. We have ...   \n",
       "2       neutral  Convince her of what? That it's happening or t...   \n",
       "3      disagree  I think this prediction is about as valid as s...   \n",
       "4      disagree  Mann hasn't been honest in decades, so I'm cur...   \n",
       "...         ...                                                ...   \n",
       "42838   neutral  Not trying to spark an argument but a legitima...   \n",
       "42839     agree  Y'all saw Guilianis hail Mary right? Get his s...   \n",
       "42840     agree  Why don't I see ads holding Republicans accoun...   \n",
       "42841     agree  How about ... no? This is strange. Community o...   \n",
       "42842     agree  Can you recruit some white allies so you aren'...   \n",
       "\n",
       "                                              body_child msg_id_parent  \\\n",
       "0      I'm in NE USA we've had 3 in two years...all e...       cnddov1   \n",
       "1      One hundred year flood just means a one in one...       cnddov1   \n",
       "2      That anthropocentric climate change is actuall...       cndnlrd   \n",
       "3      It's January. Literally no one said it would b...       cndl5x4   \n",
       "4      There have been a dozen re-constructions of Ma...       cne462t   \n",
       "...                                                  ...           ...   \n",
       "42838  Keeping in mind that the Palestinians killed m...       gyo197v   \n",
       "42839  Same I want these assholes in jail, full stop....       gynfsu4   \n",
       "42840  Yeah, I agree with the goal of this post but n...       gyn6nzm   \n",
       "42841  I know, it feels strange too. We wouldn't hold...       gyp71o7   \n",
       "42842  Ooooo, now I like the taking the day request. ...       gyp7b89   \n",
       "\n",
       "      msg_id_child         subreddit          datetime  exact_time  target  \n",
       "0          cndj2gv           climate  03/01/2015 23:18  1420327135       1  \n",
       "1          cndkpy7           climate  04/01/2015 00:10  1420330231       1  \n",
       "2          cndnsxt           climate  04/01/2015 01:45  1420335952       1  \n",
       "3          cndybsy           climate  04/01/2015 08:01  1420358465       0  \n",
       "4          cne89ej           climate  04/01/2015 17:45  1420393544       0  \n",
       "...            ...               ...               ...         ...     ...  \n",
       "42838      gyotff1        Republican  19/05/2021 12:36  1621427788       1  \n",
       "42839      gyp3u39         democrats  19/05/2021 13:56  1621432578       2  \n",
       "42840      gyp5vzw         democrats  19/05/2021 14:11  1621433471       2  \n",
       "42841      gyp7en6  BlackLivesMatter  19/05/2021 14:21  1621434116       2  \n",
       "42842      gyp7vjv  BlackLivesMatter  19/05/2021 14:25  1621434314       2  \n",
       "\n",
       "[42843 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "\n",
    "data = pd.read_csv(\"../../../data/debagree_new_preprocessing_com_rep.csv\")\n",
    "data = data[[\"label\", \"body_parent\", \"body_child\", \"msg_id_parent\", \"msg_id_child\", \"subreddit\", \"datetime\", \"exact_time\"]].sort_values(by = \"exact_time\").reset_index(drop = True)\n",
    "\n",
    "# keep integer labels\n",
    "data['target'] = data['label']\n",
    "\n",
    "# for readability, recode labels\n",
    "int_to_label = {2: \"agree\", 1 : \"neutral\", 0 : \"disagree\"}\n",
    "label_to_int = {\"agree\" : 2, \"neutral\" : 1, \"disagree\" : 0}\n",
    "data.replace({\"label\": int_to_label}, inplace = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample interactions, keeping shares of subreddits and labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_sample_target_size(df, subreddit_col, label_col, total_size):\n",
    "    \"\"\"\n",
    "    Perform a two-level stratified sample:\n",
    "    - First by subreddit (in proportion to their frequency)\n",
    "    - Then by label within each subreddit (preserving label distribution)\n",
    "    \n",
    "    Returns exactly `total_size` rows.\n",
    "    \"\"\"\n",
    "    # subreddit proportions\n",
    "    subreddit_dist = df[subreddit_col].value_counts(normalize=True)\n",
    "\n",
    "    sampled_rows = []\n",
    "\n",
    "    for subreddit, subreddit_prop in subreddit_dist.items():\n",
    "        # nr rows to sample from this subreddit\n",
    "        subreddit_n = int(round(total_size * subreddit_prop))\n",
    "        sub_df = df[df[subreddit_col] == subreddit]\n",
    "\n",
    "        # within subreddit, keep label distribution\n",
    "        label_dist = sub_df[label_col].value_counts(normalize=True)\n",
    "\n",
    "        for label, label_prop in label_dist.items():\n",
    "            label_n = int(round(subreddit_n * label_prop))\n",
    "            label_df = sub_df[sub_df[label_col] == label]\n",
    "            \n",
    "            # Sample, but make sure we don't sample more than we have\n",
    "            actual_n = min(label_n, len(label_df))\n",
    "            if actual_n > 0:\n",
    "                sampled_rows.append(label_df.sample(n=actual_n, random_state=42))\n",
    "\n",
    "    # Combine all, shuffle, and trim to exactly `total_size`\n",
    "    final_df = pd.concat(sampled_rows).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Ensure final size matches (if over, just trim)\n",
    "    return final_df.iloc[:total_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agree</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>09/03/2021 04:29</td>\n",
       "      <td>1615264154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agree</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>03/01/2021 03:02</td>\n",
       "      <td>1609642942</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agree</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>10/12/2020 17:23</td>\n",
       "      <td>1607620990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agree</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>18/05/2021 11:30</td>\n",
       "      <td>1621337452</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>06/10/2020 22:56</td>\n",
       "      <td>1602024961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>agree</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>02/02/2020 23:35</td>\n",
       "      <td>1580686536</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>neutral</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>04/11/2020 16:28</td>\n",
       "      <td>1604507309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>agree</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>25/04/2020 03:14</td>\n",
       "      <td>1587784461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>agree</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>08/10/2020 05:34</td>\n",
       "      <td>1602135247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>26/06/2020 21:32</td>\n",
       "      <td>1593207132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                        body_parent  \\\n",
       "0        agree  They shouldn't be winning elections, that's fo...   \n",
       "1        agree  This tells me one thing. COVID was politicized...   \n",
       "2        agree  So, the mini-deals are being discussed because...   \n",
       "3        agree  My sister is a type one diabetic and a biden s...   \n",
       "4     disagree  You guys are so stupid. The difference is that...   \n",
       "...        ...                                                ...   \n",
       "9995     agree  Just like he rigged the Supreme court by not a...   \n",
       "9996   neutral  He needs to grow up fast. Right out of the gat...   \n",
       "9997     agree  I just got banned on  for stating that same fa...   \n",
       "9998     agree  I was liberal until I graduated college, moved...   \n",
       "9999  disagree  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                             body_child msg_id_parent  \\\n",
       "0     I agree with this. They obviously shouldn't be...       gqak9tq   \n",
       "1     Ahh yes planned by the whole world to cover up...       ghrt3ay   \n",
       "2     So believes the EU. And seeing as they hold al...       gfask7y   \n",
       "3     Let's be honest. Trump could have directed to ...       gyj4rst   \n",
       "4     One of them had the flu for a couple days? Whi...       g7xuo23   \n",
       "...                                                 ...           ...   \n",
       "9995  I despise him for doing this. This man has bee...       fgdpkdc   \n",
       "9996       I don't keep up with him but what did he do.       gb4idfe   \n",
       "9997   had this bs as a hotpost today. It irks me th...       fogwj8w   \n",
       "9998  Yeah New York scares me. That and California. ...       g82yc73   \n",
       "9999  More importantly, ECB also blinked and gave in...       fw2qwrh   \n",
       "\n",
       "     msg_id_child   subreddit          datetime  exact_time  target  \n",
       "0         gqalvak   democrats  09/03/2021 04:29  1615264154       2  \n",
       "1         ghw66nh  Republican  03/01/2021 03:02  1609642942       2  \n",
       "2         gfav46i      Brexit  10/12/2020 17:23  1607620990       2  \n",
       "3         gyk1wwh  Republican  18/05/2021 11:30  1621337452       2  \n",
       "4         g7y3wdy  Republican  06/10/2020 22:56  1602024961       0  \n",
       "...           ...         ...               ...         ...     ...  \n",
       "9995      fgdsys2   democrats  02/02/2020 23:35  1580686536       2  \n",
       "9996      gb4ofe7  Republican  04/11/2020 16:28  1604507309       1  \n",
       "9997      foie0e3  Republican  25/04/2020 03:14  1587784461       2  \n",
       "9998      g830mfp  Republican  08/10/2020 05:34  1602135247       2  \n",
       "9999      fw3sqm2      Brexit  26/06/2020 21:32  1593207132       0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = stratified_sample_target_size(data, \"subreddit\", \"label\", 10000)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the Model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization for QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, # enable 4 bit quantization\n",
    "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
    "    bnb_4bit_use_double_quant = True, # quantize quantized weights\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load the Model**\n",
    "\n",
    "* AutoModelForCausalLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12841d1f31644a04a8d730f33de56101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.10 GiB of which 322.31 MiB is free. Process 309748 has 46.03 GiB memory in use. Process 342401 has 32.74 GiB memory in use. Of the allocated memory 31.62 GiB is allocated by PyTorch, and 549.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:4399\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4390\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4392\u001b[0m     (\n\u001b[1;32m   4393\u001b[0m         model,\n\u001b[1;32m   4394\u001b[0m         missing_keys,\n\u001b[1;32m   4395\u001b[0m         unexpected_keys,\n\u001b[1;32m   4396\u001b[0m         mismatched_keys,\n\u001b[1;32m   4397\u001b[0m         offload_index,\n\u001b[1;32m   4398\u001b[0m         error_msgs,\n\u001b[0;32m-> 4399\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4408\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4417\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4418\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:4833\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4831\u001b[0m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[1;32m   4832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[0;32m-> 4833\u001b[0m     disk_offload_index, cpu_offload_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4847\u001b[0m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4851\u001b[0m \u001b[38;5;66;03m# force memory release if loading multiple shards, to avoid having 2 state dicts in memory in next loop\u001b[39;00m\n\u001b[1;32m   4852\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:789\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    787\u001b[0m param \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 789\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[1;32m    791\u001b[0m     param \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 0 has a total capacity of 79.10 GiB of which 322.31 MiB is free. Process 309748 has 46.03 GiB memory in use. Process 342401 has 32.74 GiB memory in use. Of the allocated memory 31.62 GiB is allocated by PyTorch, and 549.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = quantization_config\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenizer**\n",
    "\n",
    "### Since LLAMA3 pre-training doesn't have EOS token\n",
    "* Set the pad_token_id to eos_token_id\n",
    "* Set pad token ot eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space = True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Update Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_pt = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate Prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \n",
       "0     I agree with this. They obviously shouldn't be...     agree       2  \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2  \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2  \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2  \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0  \n",
       "...                                                 ...       ...     ...  \n",
       "9995  I despise him for doing this. This man has bee...     agree       2  \n",
       "9996       I don't keep up with him but what did he do.   neutral       1  \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2  \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2  \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make text\n",
    "\n",
    "\n",
    "def create_training_data(data):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        system_prompt = \"\"\"You are a classification chatbot. Analyze a Reddit comment and its reply. Determine whether the reply explicitly and unambiguously agrees, disagrees, or remains neutral toward the comment. Respond with \"agree\" for clear agreement, \"disagree\" for clear disagreement, or \"neutral\" if the reply adds information, qualifies the statement, offers an alternative perspective, is vague, off-topic, or leaves any doubt about agreement or disagreement. Your response must strictly be one of: \"agree\", \"disagree\", or \"neutral\".\"\"\"\n",
    "        comment = row[\"body_parent\"]\n",
    "        reply = row[\"body_child\"]\n",
    "        label = row[\"label\"]\n",
    "        target = row[\"target\"]\n",
    "        \n",
    "        comment_id = row[\"msg_id_parent\"]\n",
    "        reply_id = row[\"msg_id_child\"]\n",
    "        subreddit = row[\"subreddit\"]\n",
    "        \n",
    "        result.append({'system_prompt' : system_prompt, 'comment' : comment, 'reply': reply, 'label' : label, 'target' : target, 'msg_id_parent' : comment_id, 'msg_id_child' : reply_id, 'subreddit' : subreddit})\n",
    "    \n",
    "    return result\n",
    "\n",
    "# save data\n",
    "df = pd.DataFrame(create_training_data(sample_df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a clas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     I agree with this. They obviously shouldn't be...     agree       2   \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2   \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2   \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2   \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  I despise him for doing this. This man has bee...     agree       2   \n",
       "9996       I don't keep up with him but what did he do.   neutral       1   \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2   \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2   \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "                                               sentence  \n",
       "0     [{'role': 'system', 'content': 'You are a clas...  \n",
       "1     [{'role': 'system', 'content': 'You are a clas...  \n",
       "2     [{'role': 'system', 'content': 'You are a clas...  \n",
       "3     [{'role': 'system', 'content': 'You are a clas...  \n",
       "4     [{'role': 'system', 'content': 'You are a clas...  \n",
       "...                                                 ...  \n",
       "9995  [{'role': 'system', 'content': 'You are a clas...  \n",
       "9996  [{'role': 'system', 'content': 'You are a clas...  \n",
       "9997  [{'role': 'system', 'content': 'You are a clas...  \n",
       "9998  [{'role': 'system', 'content': 'You are a clas...  \n",
       "9999  [{'role': 'system', 'content': 'You are a clas...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "def make_chat_prompt(row):\n",
    "\n",
    "    temp = [] \n",
    "    temp.append({\"role\": \"system\", \"content\": row['system_prompt']})\n",
    "    temp.append({\"role\": \"user\", \"content\": f\"comment: '{row['comment']}' ; reply: '{row['reply']}'\"})\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(temp, tokenize=False, add_generation_prompt=True )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "df['chat_prompt'] = df.apply(lambda row: make_chat_prompt(row), axis = 1)\n",
    "df['chat_prompt'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## **Apply model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 1/313 [00:37<3:14:05, 37.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 2/313 [01:12<3:08:08, 36.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 3/313 [01:45<2:58:52, 34.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|â–         | 4/313 [02:21<3:00:48, 35.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|â–         | 5/313 [02:56<3:01:05, 35.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|â–         | 6/313 [03:36<3:08:32, 36.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|â–         | 7/313 [04:12<3:05:53, 36.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|â–Ž         | 8/313 [04:46<3:01:16, 35.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|â–Ž         | 9/313 [05:24<3:04:35, 36.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|â–Ž         | 10/313 [05:58<3:00:11, 35.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|â–Ž         | 11/313 [06:31<2:55:11, 34.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|â–         | 12/313 [07:08<2:57:32, 35.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|â–         | 13/313 [07:44<2:58:04, 35.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|â–         | 14/313 [08:18<2:55:29, 35.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|â–         | 15/313 [08:54<2:55:32, 35.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|â–Œ         | 16/313 [09:31<2:57:28, 35.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|â–Œ         | 17/313 [10:09<2:59:58, 36.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|â–Œ         | 18/313 [10:47<3:02:18, 37.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|â–Œ         | 19/313 [11:23<2:59:11, 36.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|â–‹         | 23/313 [13:43<2:49:41, 35.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|â–Š         | 24/313 [14:22<2:54:00, 36.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|â–Š         | 25/313 [14:56<2:50:23, 35.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|â–Š         | 26/313 [15:32<2:51:17, 35.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|â–Š         | 27/313 [16:05<2:46:29, 34.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|â–‰         | 28/313 [16:39<2:44:57, 34.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|â–‰         | 29/313 [17:16<2:47:16, 35.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|â–‰         | 30/313 [17:55<2:52:19, 36.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|â–‰         | 31/313 [18:31<2:49:47, 36.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|â–ˆ         | 32/313 [19:08<2:50:31, 36.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|â–ˆ         | 33/313 [19:44<2:49:12, 36.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|â–ˆ         | 34/313 [20:20<2:49:06, 36.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|â–ˆ         | 35/313 [20:54<2:45:39, 35.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|â–ˆâ–        | 36/313 [21:32<2:48:11, 36.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|â–ˆâ–        | 37/313 [22:06<2:44:15, 35.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|â–ˆâ–        | 38/313 [22:42<2:42:55, 35.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|â–ˆâ–        | 39/313 [23:18<2:43:59, 35.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|â–ˆâ–Ž        | 40/313 [23:54<2:43:34, 35.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|â–ˆâ–Ž        | 41/313 [24:32<2:44:50, 36.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|â–ˆâ–Ž        | 42/313 [25:09<2:45:30, 36.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|â–ˆâ–Ž        | 43/313 [25:46<2:44:46, 36.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|â–ˆâ–        | 44/313 [26:24<2:46:37, 37.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|â–ˆâ–        | 45/313 [27:00<2:43:56, 36.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|â–ˆâ–        | 46/313 [27:36<2:42:16, 36.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|â–ˆâ–Œ        | 47/313 [28:11<2:40:52, 36.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|â–ˆâ–Œ        | 48/313 [28:49<2:41:31, 36.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|â–ˆâ–Œ        | 49/313 [29:23<2:37:56, 35.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|â–ˆâ–Œ        | 50/313 [30:01<2:40:24, 36.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|â–ˆâ–‹        | 51/313 [30:36<2:37:08, 35.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|â–ˆâ–‹        | 52/313 [31:10<2:34:21, 35.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|â–ˆâ–‹        | 53/313 [31:47<2:35:57, 35.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|â–ˆâ–‹        | 54/313 [32:23<2:34:18, 35.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|â–ˆâ–Š        | 55/313 [32:58<2:32:51, 35.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|â–ˆâ–Š        | 56/313 [33:30<2:28:36, 34.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|â–ˆâ–Š        | 57/313 [34:03<2:25:34, 34.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|â–ˆâ–Š        | 58/313 [34:40<2:28:20, 34.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|â–ˆâ–‰        | 59/313 [35:19<2:33:17, 36.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|â–ˆâ–‰        | 60/313 [35:55<2:32:02, 36.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|â–ˆâ–‰        | 61/313 [36:29<2:28:32, 35.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|â–ˆâ–‰        | 62/313 [37:08<2:32:55, 36.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|â–ˆâ–ˆ        | 63/313 [37:42<2:29:04, 35.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|â–ˆâ–ˆ        | 64/313 [38:17<2:28:20, 35.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|â–ˆâ–ˆ        | 65/313 [38:51<2:24:23, 34.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|â–ˆâ–ˆ        | 66/313 [39:26<2:24:00, 34.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|â–ˆâ–ˆâ–       | 67/313 [39:59<2:21:49, 34.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|â–ˆâ–ˆâ–       | 68/313 [40:33<2:20:07, 34.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|â–ˆâ–ˆâ–       | 69/313 [41:10<2:22:38, 35.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|â–ˆâ–ˆâ–       | 70/313 [41:44<2:21:21, 34.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 71/313 [42:21<2:22:47, 35.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 72/313 [42:54<2:19:25, 34.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 73/313 [43:33<2:23:39, 35.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|â–ˆâ–ˆâ–Ž       | 74/313 [44:08<2:22:27, 35.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|â–ˆâ–ˆâ–       | 75/313 [44:46<2:24:29, 36.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|â–ˆâ–ˆâ–       | 76/313 [45:20<2:21:18, 35.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|â–ˆâ–ˆâ–       | 77/313 [46:02<2:28:00, 37.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|â–ˆâ–ˆâ–       | 78/313 [46:37<2:24:27, 36.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 79/313 [47:14<2:23:46, 36.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 80/313 [47:49<2:21:12, 36.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 81/313 [48:23<2:16:49, 35.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 82/313 [48:56<2:14:21, 34.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|â–ˆâ–ˆâ–‹       | 83/313 [49:33<2:15:43, 35.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|â–ˆâ–ˆâ–‹       | 84/313 [50:13<2:20:05, 36.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|â–ˆâ–ˆâ–‹       | 85/313 [50:47<2:17:03, 36.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|â–ˆâ–ˆâ–‹       | 86/313 [51:24<2:17:39, 36.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|â–ˆâ–ˆâ–Š       | 87/313 [52:01<2:17:15, 36.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|â–ˆâ–ˆâ–Š       | 88/313 [52:38<2:17:32, 36.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|â–ˆâ–ˆâ–Š       | 89/313 [53:15<2:17:01, 36.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|â–ˆâ–ˆâ–‰       | 90/313 [53:50<2:14:40, 36.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|â–ˆâ–ˆâ–‰       | 91/313 [54:23<2:10:17, 35.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|â–ˆâ–ˆâ–‰       | 92/313 [55:02<2:13:38, 36.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|â–ˆâ–ˆâ–‰       | 93/313 [55:36<2:10:49, 35.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 94/313 [56:13<2:11:42, 36.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 95/313 [56:49<2:10:41, 35.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 96/313 [57:24<2:09:05, 35.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 97/313 [57:59<2:08:07, 35.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 98/313 [58:34<2:07:02, 35.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 99/313 [59:11<2:07:54, 35.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 100/313 [59:44<2:03:53, 34.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 101/313 [1:00:22<2:06:25, 35.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 102/313 [1:00:59<2:07:57, 36.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 103/313 [1:01:34<2:05:24, 35.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 104/313 [1:02:09<2:04:36, 35.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 105/313 [1:02:45<2:03:23, 35.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 106/313 [1:03:23<2:06:06, 36.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 107/313 [1:04:00<2:05:29, 36.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 108/313 [1:04:36<2:04:13, 36.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 109/313 [1:05:10<2:01:11, 35.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 110/313 [1:05:48<2:03:29, 36.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 111/313 [1:06:27<2:04:56, 37.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 112/313 [1:07:04<2:03:58, 37.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 113/313 [1:07:41<2:03:25, 37.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 114/313 [1:08:19<2:03:38, 37.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 115/313 [1:08:54<2:01:08, 36.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 116/313 [1:09:28<1:58:09, 35.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 120/313 [1:12:00<1:59:46, 37.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 121/313 [1:12:40<2:01:40, 38.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 122/313 [1:13:15<1:58:15, 37.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 123/313 [1:13:55<2:00:00, 37.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 124/313 [1:14:31<1:58:21, 37.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 125/313 [1:15:09<1:57:17, 37.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 126/313 [1:15:42<1:53:24, 36.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 127/313 [1:16:17<1:50:45, 35.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 128/313 [1:16:51<1:48:32, 35.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 129/313 [1:17:28<1:49:41, 35.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 130/313 [1:18:06<1:51:18, 36.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 131/313 [1:18:38<1:47:09, 35.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/313 [1:19:17<1:49:08, 36.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/313 [1:19:52<1:47:49, 35.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 134/313 [1:20:29<1:47:47, 36.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 135/313 [1:21:04<1:46:56, 36.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 136/313 [1:21:38<1:43:46, 35.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 137/313 [1:22:13<1:43:31, 35.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 138/313 [1:22:49<1:43:12, 35.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 139/313 [1:23:26<1:44:18, 35.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/313 [1:23:57<1:39:32, 34.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 141/313 [1:24:33<1:39:59, 34.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 142/313 [1:25:07<1:38:25, 34.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 143/313 [1:25:40<1:36:29, 34.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 144/313 [1:26:18<1:39:53, 35.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 145/313 [1:26:52<1:37:46, 34.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 146/313 [1:27:26<1:36:11, 34.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 147/313 [1:28:01<1:36:15, 34.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 148/313 [1:28:40<1:38:45, 35.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 149/313 [1:29:12<1:35:39, 35.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 150/313 [1:29:48<1:35:44, 35.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 151/313 [1:30:21<1:33:12, 34.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 152/313 [1:30:58<1:34:26, 35.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 153/313 [1:31:37<1:37:21, 36.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 154/313 [1:32:12<1:35:07, 35.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 155/313 [1:32:50<1:36:34, 36.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 156/313 [1:33:27<1:35:50, 36.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 157/313 [1:34:06<1:36:50, 37.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 158/313 [1:34:41<1:34:58, 36.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 159/313 [1:35:15<1:32:13, 35.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 160/313 [1:35:50<1:30:33, 35.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 161/313 [1:36:28<1:31:57, 36.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 162/313 [1:37:05<1:31:55, 36.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/313 [1:37:40<1:29:48, 35.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/313 [1:38:12<1:26:42, 34.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 165/313 [1:38:45<1:24:35, 34.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 166/313 [1:39:22<1:26:12, 35.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 167/313 [1:39:56<1:24:45, 34.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 168/313 [1:40:36<1:27:50, 36.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 169/313 [1:41:11<1:26:31, 36.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 170/313 [1:41:46<1:24:40, 35.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 171/313 [1:42:25<1:26:23, 36.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/313 [1:42:59<1:24:02, 35.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 173/313 [1:43:36<1:24:28, 36.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 174/313 [1:44:14<1:25:04, 36.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 175/313 [1:44:52<1:25:39, 37.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 176/313 [1:45:27<1:23:08, 36.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 177/313 [1:46:01<1:20:51, 35.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 178/313 [1:46:36<1:20:01, 35.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 179/313 [1:47:12<1:20:05, 35.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 180/313 [1:47:46<1:18:14, 35.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 181/313 [1:48:21<1:17:00, 35.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 182/313 [1:48:59<1:18:31, 35.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 183/313 [1:49:38<1:19:42, 36.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 184/313 [1:50:12<1:17:34, 36.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 185/313 [1:50:53<1:20:09, 37.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 186/313 [1:51:31<1:19:22, 37.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 187/313 [1:52:11<1:20:24, 38.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 188/313 [1:52:46<1:17:50, 37.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 189/313 [1:53:23<1:16:54, 37.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 190/313 [1:53:57<1:14:18, 36.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 191/313 [1:54:33<1:14:00, 36.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 192/313 [1:55:12<1:14:39, 37.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 193/313 [1:55:45<1:11:24, 35.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 194/313 [1:56:18<1:09:38, 35.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 195/313 [1:56:56<1:10:19, 35.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 196/313 [1:57:30<1:08:42, 35.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 197/313 [1:58:04<1:07:35, 34.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 198/313 [1:58:38<1:06:38, 34.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 199/313 [1:59:15<1:07:11, 35.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 200/313 [1:59:52<1:07:25, 35.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 201/313 [2:00:31<1:08:48, 36.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 202/313 [2:01:06<1:06:54, 36.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 203/313 [2:01:42<1:06:09, 36.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 204/313 [2:02:17<1:05:26, 36.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 205/313 [2:02:55<1:05:52, 36.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 206/313 [2:03:31<1:04:47, 36.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 207/313 [2:04:06<1:03:34, 35.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 208/313 [2:04:43<1:03:31, 36.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 209/313 [2:05:23<1:04:38, 37.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 210/313 [2:05:59<1:03:09, 36.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 211/313 [2:06:32<1:00:41, 35.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 212/313 [2:07:08<1:00:11, 35.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 213/313 [2:07:45<1:00:14, 36.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 214/313 [2:08:24<1:01:27, 37.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 215/313 [2:09:03<1:01:17, 37.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 216/313 [2:09:39<1:00:18, 37.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 217/313 [2:10:13<57:40, 36.05s/it]  Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 218/313 [2:10:50<57:37, 36.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 219/313 [2:11:27<57:20, 36.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 220/313 [2:12:03<56:42, 36.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 221/313 [2:12:43<57:21, 37.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 222/313 [2:13:22<57:43, 38.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 223/313 [2:13:59<56:38, 37.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 224/313 [2:14:32<53:56, 36.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 225/313 [2:15:08<52:54, 36.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 226/313 [2:15:45<52:49, 36.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 227/313 [2:16:21<51:57, 36.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 228/313 [2:16:56<50:58, 35.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 229/313 [2:17:32<50:07, 35.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 230/313 [2:18:05<48:25, 35.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 231/313 [2:18:37<46:31, 34.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 232/313 [2:19:12<46:24, 34.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 233/313 [2:19:44<45:03, 33.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 234/313 [2:20:22<46:06, 35.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 235/313 [2:20:54<44:27, 34.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 236/313 [2:21:27<43:26, 33.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 237/313 [2:22:04<43:54, 34.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 238/313 [2:22:41<44:08, 35.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 239/313 [2:23:20<45:00, 36.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 240/313 [2:23:58<45:00, 36.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 241/313 [2:24:36<44:47, 37.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 242/313 [2:25:13<44:03, 37.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 243/313 [2:25:47<42:17, 36.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 244/313 [2:26:25<42:03, 36.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 245/313 [2:27:00<40:58, 36.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 246/313 [2:27:34<39:49, 35.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 247/313 [2:28:14<40:33, 36.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 248/313 [2:28:47<38:44, 35.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 249/313 [2:29:23<38:05, 35.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 250/313 [2:29:58<37:19, 35.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 251/313 [2:30:33<36:41, 35.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 252/313 [2:31:08<35:47, 35.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 253/313 [2:31:48<36:36, 36.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 254/313 [2:32:23<35:33, 36.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 255/313 [2:33:00<35:18, 36.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 256/313 [2:33:36<34:22, 36.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 257/313 [2:34:11<33:29, 35.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 258/313 [2:34:46<32:42, 35.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 259/313 [2:35:25<32:56, 36.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 260/313 [2:35:59<31:39, 35.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 261/313 [2:36:35<31:05, 35.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 262/313 [2:37:10<30:22, 35.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 263/313 [2:37:46<29:41, 35.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 264/313 [2:38:20<28:50, 35.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 265/313 [2:38:53<27:39, 34.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 266/313 [2:39:28<27:14, 34.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 267/313 [2:40:06<27:15, 35.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 268/313 [2:40:43<26:57, 35.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 269/313 [2:41:21<26:59, 36.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 270/313 [2:42:01<27:04, 37.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 271/313 [2:42:37<25:56, 37.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 272/313 [2:43:08<24:04, 35.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 273/313 [2:43:43<23:31, 35.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 274/313 [2:44:15<22:21, 34.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 275/313 [2:44:52<22:15, 35.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 276/313 [2:45:29<22:01, 35.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 277/313 [2:46:06<21:37, 36.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 278/313 [2:46:42<20:57, 35.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 279/313 [2:47:17<20:16, 35.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 280/313 [2:47:52<19:27, 35.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 281/313 [2:48:30<19:24, 36.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 282/313 [2:49:08<18:54, 36.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 283/313 [2:49:46<18:32, 37.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 284/313 [2:50:21<17:39, 36.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 285/313 [2:50:58<17:03, 36.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 286/313 [2:51:32<16:10, 35.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 287/313 [2:52:07<15:29, 35.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 288/313 [2:52:47<15:22, 36.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 289/313 [2:53:24<14:43, 36.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 290/313 [2:54:01<14:13, 37.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 291/313 [2:54:35<13:14, 36.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 292/313 [2:55:08<12:18, 35.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 293/313 [2:55:43<11:40, 35.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 294/313 [2:56:21<11:21, 35.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 295/313 [2:56:55<10:36, 35.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 296/313 [2:57:31<10:03, 35.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 297/313 [2:58:09<09:42, 36.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 298/313 [2:58:48<09:16, 37.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 299/313 [2:59:21<08:21, 35.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 300/313 [2:59:58<07:51, 36.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 301/313 [3:00:34<07:13, 36.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 302/313 [3:01:10<06:38, 36.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 303/313 [3:01:43<05:52, 35.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 304/313 [3:02:20<05:21, 35.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 305/313 [3:02:56<04:45, 35.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 306/313 [3:03:29<04:04, 34.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 307/313 [3:04:06<03:32, 35.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 308/313 [3:04:42<02:58, 35.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 309/313 [3:05:19<02:24, 36.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 310/313 [3:05:55<01:48, 36.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 311/313 [3:06:29<01:11, 35.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 312/313 [3:07:04<00:35, 35.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [3:07:25<00:00, 35.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_parent</th>\n",
       "      <th>body_child</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>datetime</th>\n",
       "      <th>exact_time</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agree</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>09/03/2021 04:29</td>\n",
       "      <td>1615264154</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agree</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>03/01/2021 03:02</td>\n",
       "      <td>1609642942</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agree</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>10/12/2020 17:23</td>\n",
       "      <td>1607620990</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agree</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>18/05/2021 11:30</td>\n",
       "      <td>1621337452</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>06/10/2020 22:56</td>\n",
       "      <td>1602024961</td>\n",
       "      <td>0</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>agree</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>02/02/2020 23:35</td>\n",
       "      <td>1580686536</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>neutral</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>04/11/2020 16:28</td>\n",
       "      <td>1604507309</td>\n",
       "      <td>1</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>agree</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>25/04/2020 03:14</td>\n",
       "      <td>1587784461</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>agree</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>08/10/2020 05:34</td>\n",
       "      <td>1602135247</td>\n",
       "      <td>2</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>disagree</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>26/06/2020 21:32</td>\n",
       "      <td>1593207132</td>\n",
       "      <td>0</td>\n",
       "      <td>system\\n\\ncutting knowledge date: december 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                        body_parent  \\\n",
       "0        agree  They shouldn't be winning elections, that's fo...   \n",
       "1        agree  This tells me one thing. COVID was politicized...   \n",
       "2        agree  So, the mini-deals are being discussed because...   \n",
       "3        agree  My sister is a type one diabetic and a biden s...   \n",
       "4     disagree  You guys are so stupid. The difference is that...   \n",
       "...        ...                                                ...   \n",
       "9995     agree  Just like he rigged the Supreme court by not a...   \n",
       "9996   neutral  He needs to grow up fast. Right out of the gat...   \n",
       "9997     agree  I just got banned on  for stating that same fa...   \n",
       "9998     agree  I was liberal until I graduated college, moved...   \n",
       "9999  disagree  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                             body_child msg_id_parent  \\\n",
       "0     I agree with this. They obviously shouldn't be...       gqak9tq   \n",
       "1     Ahh yes planned by the whole world to cover up...       ghrt3ay   \n",
       "2     So believes the EU. And seeing as they hold al...       gfask7y   \n",
       "3     Let's be honest. Trump could have directed to ...       gyj4rst   \n",
       "4     One of them had the flu for a couple days? Whi...       g7xuo23   \n",
       "...                                                 ...           ...   \n",
       "9995  I despise him for doing this. This man has bee...       fgdpkdc   \n",
       "9996       I don't keep up with him but what did he do.       gb4idfe   \n",
       "9997   had this bs as a hotpost today. It irks me th...       fogwj8w   \n",
       "9998  Yeah New York scares me. That and California. ...       g82yc73   \n",
       "9999  More importantly, ECB also blinked and gave in...       fw2qwrh   \n",
       "\n",
       "     msg_id_child   subreddit          datetime  exact_time  target  \\\n",
       "0         gqalvak   democrats  09/03/2021 04:29  1615264154       2   \n",
       "1         ghw66nh  Republican  03/01/2021 03:02  1609642942       2   \n",
       "2         gfav46i      Brexit  10/12/2020 17:23  1607620990       2   \n",
       "3         gyk1wwh  Republican  18/05/2021 11:30  1621337452       2   \n",
       "4         g7y3wdy  Republican  06/10/2020 22:56  1602024961       0   \n",
       "...           ...         ...               ...         ...     ...   \n",
       "9995      fgdsys2   democrats  02/02/2020 23:35  1580686536       2   \n",
       "9996      gb4ofe7  Republican  04/11/2020 16:28  1604507309       1   \n",
       "9997      foie0e3  Republican  25/04/2020 03:14  1587784461       2   \n",
       "9998      g830mfp  Republican  08/10/2020 05:34  1602135247       2   \n",
       "9999      fw3sqm2      Brexit  26/06/2020 21:32  1593207132       0   \n",
       "\n",
       "                                       predicted_labels  \n",
       "0     system\\n\\ncutting knowledge date: december 202...  \n",
       "1     system\\n\\ncutting knowledge date: december 202...  \n",
       "2     system\\n\\ncutting knowledge date: december 202...  \n",
       "3     system\\n\\ncutting knowledge date: december 202...  \n",
       "4     system\\n\\ncutting knowledge date: december 202...  \n",
       "...                                                 ...  \n",
       "9995  system\\n\\ncutting knowledge date: december 202...  \n",
       "9996  system\\n\\ncutting knowledge date: december 202...  \n",
       "9997  system\\n\\ncutting knowledge date: december 202...  \n",
       "9998  system\\n\\ncutting knowledge date: december 202...  \n",
       "9999  system\\n\\ncutting knowledge date: december 202...  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Function to process one prompt column\n",
    "def generate_predictions(df, prompt_column_name, output_column_name):\n",
    "    all_outputs = []\n",
    "\n",
    "    # Get all prompts for the selected strategy\n",
    "    prompts = df[prompt_column_name].tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=f\"Generating for {prompt_column_name}\"):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "\n",
    "        # Tokenize (skip apply_chat_template here â€” it's already done)\n",
    "        inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=False  # Optional: make deterministic\n",
    "            )\n",
    "\n",
    "        # Decode and collect\n",
    "        decoded = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        all_outputs.extend(decoded)\n",
    "\n",
    "    # Add raw output to the dataframe\n",
    "    df[output_column_name] = all_outputs\n",
    "\n",
    "    # Normalize and clean up (extract just 'agree' or 'disagree' if possible)\n",
    "    df[output_column_name] = df[output_column_name].str.lower().str.strip()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat\n",
    "df = generate_predictions(df, \"chat_prompt\", \"predicted_chat\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "cutting knowledge date: december 2023\n",
      "today date: 26 jul 2024\n",
      "\n",
      "you are a classification chatbot. analyze a reddit comment and its reply. determine if the reply explicitly and unambiguously disagrees with the comment. respond with 'disagree' for clear disagreement or 'no_disagreement' if the reply adds information, qualifies the statement, offers an alternative perspective, or leaves any doubt about disagreement. your response must strictly be 'disagree' or 'no_disagreement'.user\n",
      "\n",
      "comment: 'they shouldn't be winning elections, that's for sure, but i'm not sure how to angle a ban. all that would do is fail when it hit the supreme court and give them fuel for their martyr complex' ; reply: 'i agree with this. they obviously shouldn't be holding positions of power, but just outright banning an idea, even a horrible and dangerous one, just won't fly in the supreme court, especially not with the current justices. i think everyone agrees something should be done to get rid of white supremacists, but it's a difficult problem to sort out in a way that will actually stick without further enflaming them and the masses that tolerate them.'assistant\n",
      "\n",
      "no_disagreement\n"
     ]
    }
   ],
   "source": [
    "# Show the results\n",
    "\n",
    "print(df['predicted_chat'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_chat\n",
       "no_disagreement    7679\n",
       "disagree           2321\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract\n",
    "df['predicted_chat'] = df['predicted_chat'].apply(lambda x: x.split()[-1].strip(\".\"))\n",
    "\n",
    "df['predicted_chat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>chat_prompt</th>\n",
       "      <th>predicted_chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>They shouldn't be winning elections, that's fo...</td>\n",
       "      <td>I agree with this. They obviously shouldn't be...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>This tells me one thing. COVID was politicized...</td>\n",
       "      <td>Ahh yes planned by the whole world to cover up...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>So, the mini-deals are being discussed because...</td>\n",
       "      <td>So believes the EU. And seeing as they hold al...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>My sister is a type one diabetic and a biden s...</td>\n",
       "      <td>Let's be honest. Trump could have directed to ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>You guys are so stupid. The difference is that...</td>\n",
       "      <td>One of them had the flu for a couple days? Whi...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Just like he rigged the Supreme court by not a...</td>\n",
       "      <td>I despise him for doing this. This man has bee...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>He needs to grow up fast. Right out of the gat...</td>\n",
       "      <td>I don't keep up with him but what did he do.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I just got banned on  for stating that same fa...</td>\n",
       "      <td>had this bs as a hotpost today. It irks me th...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>I was liberal until I graduated college, moved...</td>\n",
       "      <td>Yeah New York scares me. That and California. ...</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>You are a classification chatbot. Analyze a Re...</td>\n",
       "      <td>Merkel said, it did not fundamentally challeng...</td>\n",
       "      <td>More importantly, ECB also blinked and gave in...</td>\n",
       "      <td>disagree</td>\n",
       "      <td>0</td>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>no_disagreement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          system_prompt  \\\n",
       "0     You are a classification chatbot. Analyze a Re...   \n",
       "1     You are a classification chatbot. Analyze a Re...   \n",
       "2     You are a classification chatbot. Analyze a Re...   \n",
       "3     You are a classification chatbot. Analyze a Re...   \n",
       "4     You are a classification chatbot. Analyze a Re...   \n",
       "...                                                 ...   \n",
       "9995  You are a classification chatbot. Analyze a Re...   \n",
       "9996  You are a classification chatbot. Analyze a Re...   \n",
       "9997  You are a classification chatbot. Analyze a Re...   \n",
       "9998  You are a classification chatbot. Analyze a Re...   \n",
       "9999  You are a classification chatbot. Analyze a Re...   \n",
       "\n",
       "                                                comment  \\\n",
       "0     They shouldn't be winning elections, that's fo...   \n",
       "1     This tells me one thing. COVID was politicized...   \n",
       "2     So, the mini-deals are being discussed because...   \n",
       "3     My sister is a type one diabetic and a biden s...   \n",
       "4     You guys are so stupid. The difference is that...   \n",
       "...                                                 ...   \n",
       "9995  Just like he rigged the Supreme court by not a...   \n",
       "9996  He needs to grow up fast. Right out of the gat...   \n",
       "9997  I just got banned on  for stating that same fa...   \n",
       "9998  I was liberal until I graduated college, moved...   \n",
       "9999  Merkel said, it did not fundamentally challeng...   \n",
       "\n",
       "                                                  reply     label  target  \\\n",
       "0     I agree with this. They obviously shouldn't be...     agree       2   \n",
       "1     Ahh yes planned by the whole world to cover up...     agree       2   \n",
       "2     So believes the EU. And seeing as they hold al...     agree       2   \n",
       "3     Let's be honest. Trump could have directed to ...     agree       2   \n",
       "4     One of them had the flu for a couple days? Whi...  disagree       0   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  I despise him for doing this. This man has bee...     agree       2   \n",
       "9996       I don't keep up with him but what did he do.   neutral       1   \n",
       "9997   had this bs as a hotpost today. It irks me th...     agree       2   \n",
       "9998  Yeah New York scares me. That and California. ...     agree       2   \n",
       "9999  More importantly, ECB also blinked and gave in...  disagree       0   \n",
       "\n",
       "     msg_id_parent msg_id_child   subreddit  \\\n",
       "0          gqak9tq      gqalvak   democrats   \n",
       "1          ghrt3ay      ghw66nh  Republican   \n",
       "2          gfask7y      gfav46i      Brexit   \n",
       "3          gyj4rst      gyk1wwh  Republican   \n",
       "4          g7xuo23      g7y3wdy  Republican   \n",
       "...            ...          ...         ...   \n",
       "9995       fgdpkdc      fgdsys2   democrats   \n",
       "9996       gb4idfe      gb4ofe7  Republican   \n",
       "9997       fogwj8w      foie0e3  Republican   \n",
       "9998       g82yc73      g830mfp  Republican   \n",
       "9999       fw2qwrh      fw3sqm2      Brexit   \n",
       "\n",
       "                                            chat_prompt   predicted_chat  \n",
       "0     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "1     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "2     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "3     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "4     <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "...                                                 ...              ...  \n",
       "9995  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9996  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9997  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9998  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "9999  <|begin_of_text|><|start_header_id|>system<|en...  no_disagreement  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode to two labels\n",
    "#df['label_2'] = df['label'].map(lambda x: 'no_disagreement' if x in ['neutral', 'agree'] else 'disagree')\n",
    "\n",
    "#df.to_csv(\"output/Llama_3.3_70B_zs_Debagree_3labels_sample.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df[['msg_id_parent', 'msg_id_child', 'subreddit', 'label', 'predicted_labels']].to_csv(output_path_sample, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reimport**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_id_parent</th>\n",
       "      <th>msg_id_child</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gqak9tq</td>\n",
       "      <td>gqalvak</td>\n",
       "      <td>democrats</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghrt3ay</td>\n",
       "      <td>ghw66nh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>agree</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gfask7y</td>\n",
       "      <td>gfav46i</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gyj4rst</td>\n",
       "      <td>gyk1wwh</td>\n",
       "      <td>Republican</td>\n",
       "      <td>agree</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g7xuo23</td>\n",
       "      <td>g7y3wdy</td>\n",
       "      <td>Republican</td>\n",
       "      <td>disagree</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fgdpkdc</td>\n",
       "      <td>fgdsys2</td>\n",
       "      <td>democrats</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>gb4idfe</td>\n",
       "      <td>gb4ofe7</td>\n",
       "      <td>Republican</td>\n",
       "      <td>neutral</td>\n",
       "      <td>does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>fogwj8w</td>\n",
       "      <td>foie0e3</td>\n",
       "      <td>Republican</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>g82yc73</td>\n",
       "      <td>g830mfp</td>\n",
       "      <td>Republican</td>\n",
       "      <td>agree</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>fw2qwrh</td>\n",
       "      <td>fw3sqm2</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>disagree</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     msg_id_parent msg_id_child   subreddit     label predicted_labels\n",
       "0          gqak9tq      gqalvak   democrats     agree            agree\n",
       "1          ghrt3ay      ghw66nh  Republican     agree          neutral\n",
       "2          gfask7y      gfav46i      Brexit     agree            agree\n",
       "3          gyj4rst      gyk1wwh  Republican     agree          neutral\n",
       "4          g7xuo23      g7y3wdy  Republican  disagree         disagree\n",
       "...            ...          ...         ...       ...              ...\n",
       "9995       fgdpkdc      fgdsys2   democrats     agree            agree\n",
       "9996       gb4idfe      gb4ofe7  Republican   neutral             does\n",
       "9997       fogwj8w      foie0e3  Republican     agree            agree\n",
       "9998       g82yc73      g830mfp  Republican     agree            agree\n",
       "9999       fw2qwrh      fw3sqm2      Brexit  disagree          neutral\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(output_path_sample)\n",
    "sample_df['predicted_labels'] = sample_df['predicted_labels'].apply(lambda x: x.split()[-1])\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2067\n"
     ]
    }
   ],
   "source": [
    "valid = sample_df[sample_df['predicted_labels'].isin([\"agree\", \"disagree\", \"neutral\"])].reset_index(drop = True)\n",
    "valid\n",
    "\n",
    "print(len(sample_df) - len(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Performance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "  y_test = df_test.label\n",
    "  y_pred = df_test.predicted_labels\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1498  553  775]\n",
      " [ 206 2231  900]\n",
      " [ 255  463 1052]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.76      0.53      0.63      2826\n",
      "    disagree       0.69      0.67      0.68      3337\n",
      "     neutral       0.39      0.59      0.47      1770\n",
      "\n",
      "    accuracy                           0.60      7933\n",
      "   macro avg       0.61      0.60      0.59      7933\n",
      "weighted avg       0.65      0.60      0.61      7933\n",
      "\n",
      "Balanced Accuracy Score: 0.5976642366660675\n",
      "Accuracy Score: 0.6026723811924871\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "disagree    3337\n",
      "agree       2826\n",
      "neutral     1770\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "print(valid['label'].value_counts())\n",
    "\n",
    "\n",
    "cm = confusion_matrix(valid['label'], valid['predicted_labels'])\n",
    "labels = sorted(set(valid['label']).union(set(valid['predicted_labels'])))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6076443,
     "sourceId": 9893468,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68812,
     "sourceId": 108555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
