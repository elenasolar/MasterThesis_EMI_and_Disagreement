{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Embedding**\n",
    "\n",
    "Modified embeddings\n",
    "* training texts filtered based on id (not on unique text content)\n",
    "* `min_count` of words for fine tuning and self build model = 10\n",
    "* `window size` for fine tuning and self build model = 5 (explicitly set in self, for finetune apparently default)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==2.2.2 in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (1.11.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers==2.2.2) (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers==2.2.2)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.5.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->sentence-transformers==2.2.2) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.25.1\n",
      "    Uninstalling huggingface-hub-0.25.1:\n",
      "      Successfully uninstalled huggingface-hub-0.25.1\n",
      "Successfully installed huggingface-hub-0.30.2\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers==2.2.2\n",
    "!pip install huggingface_hub #==0.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "from sentence_transformers import models\n",
    "from sentence_transformers.models import WordEmbeddings\n",
    "from sentence_transformers.models.tokenizer import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from token_normalize import TokenNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **File Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_input_w_dim = \"embedding_files/fine_tuned_glove_word2vec_wordlim_10.txt\"\n",
    "self_build_w_dim = \"embedding_files/self_build_word2vec_wordlim_10_window_5.txt\"\n",
    "\n",
    "finetuned_input = \"embedding_files/finetuned_input_word2vec_wordlim_10_window_5.txt\"\n",
    "self_build_input = \"embedding_files/self_input_word2vec_wordlim_10_window_5.txt\"\n",
    "\n",
    "normalized_finetuned_input = 'embedding_files/normalized_finetuned_word2vec_wordlim_10_window_5.txt'\n",
    "normalized_self_build_input = 'embedding_files/normalized_self_input_word2vec_wordlim_10_window_5.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Remove Dimensions from Finetuned and Self Build Embeddings**\n",
    "\n",
    "(if not already done in normalization analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuned embeddings\n",
    "\n",
    "# read txt embeddings\n",
    "with open(finetuned_input_w_dim, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# write relevant lines only\n",
    "with open(finetuned_input, 'w') as new_file:\n",
    "    new_file.writelines(lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump -0.6135888 -0.05122478 0.32378477 -0.018552344 -0.04039653 -0.7179959 -1.4525905 0.535624 -1.5831982 -0.32613507 0.6316913 2.1569276 0.34307536 -0.062699385 -0.4873404 0.37337807 0.6948798 -0.8668169 -0.00010414087 0.5997524 -0.62814766 -0.16490321 -1.1172909 2.528996 1.3801602 0.8241034 -0.26796582 -0.671873 0.2545098 0.97736526 1.014585 -0.7936119 -0.105332196 -0.19707057 0.22297364 -0.6990499 -1.6896893 1.7435157 -1.9377967 0.25481412 -0.03202884 3.8575087 -0.060180493 -1.0402737 -0.6887274 -1.640598 0.45344245 -0.16767389 0.84069604 1.5578289 0.9771874 -0.89675 0.9967128 0.90804654 -0.007272807 -0.029031191 0.8605955 2.4673493 1.4746195 -0.4503221 1.8652802 0.41773197 1.3121616 -0.192177 0.77656454 0.04783074 -0.08766447 0.8279369 0.5085095 -1.0751499 1.2548716 -0.5749214 2.3748658 -0.30434716 1.6162771 0.49036238 -0.30241713 1.2241513 0.19421458 1.574174 -0.15816964 -1.6831776 -1.7084638 -0.83086646 -0.89024335 1.0556635 0.24655919 -0.8254698 -1.5905627 -0.37951446 -0.43745154 1.1734179 0.26036182 -1.3867198 -0.12500446 1.4731853 -1.8228654 -0.36809555 -0.87591946 -1.2878158 -0.82783246 3.135903 1.691222 -1.8947674 -0.5382246 0.21376687 -1.8167937 0.17813468 -1.4450679 -0.9884946 -0.9286046 0.047830407 -0.52549225 0.39090627 -1.1080611 -0.8967462 0.6976532 -0.2078584 -0.40214184 -0.08078444 -0.3746634 -2.103412 -2.0843508 -0.26483968 -1.2920061 0.77586603 -0.00029498478 0.85528016 -3.2107916 0.03624265 0.9213221 1.3243127 -0.38427767 -0.09099498 2.625681 2.2280607 -1.6543243 0.49393925 0.5027152 0.083597615 0.34876007 -0.47767302 0.29168624 -1.3037736 -0.37376133 -1.0004325 -0.7079989 2.991733 0.44666 -1.00616 0.9445794 1.2919774 0.59928817 0.45870584 -3.5294511 -0.25538597 -0.99384516 0.86477804 0.039479602 0.022077465 0.7031395 -0.35875916 -0.45328724 1.2467333 -0.9759871 0.13971147 1.900144 0.94001234 -1.1581023 -0.6693524 0.11110198 -0.007096018 -0.41958308 -0.31092376 -1.3530458 0.4262323 1.3293239 -1.0365043 1.3985384 1.2127748 -0.040959775 -1.4321983 0.2984376 -0.0921853 -0.14141254 0.13362351 0.63802177 1.3677683 -1.1911465 -0.12747815 0.36395 -1.1214248 -0.07614919 -1.1823863 -1.143759 -0.45690492 -0.26934385 1.1634713 -0.7194633 -1.5287272 -0.8238854 -1.5582662 0.179163 -0.36378923 -0.048322946 0.56235164 0.97711354 0.29196107 -3.069358 0.2682526 0.37660182 3.3922195 0.05435045 0.4566514 1.2880132 -0.82938975 -0.21223213 -1.4503915 1.638377 -1.2063298 0.0684427 -0.9396916 0.084015176 1.3729618 0.092859544 -0.96764565 -1.8364233 1.2893392 0.44159997 0.34217 -0.63625246 -0.09330774 0.5656144 -1.2216806 0.13877971 0.76220286 0.7664899 -0.075549394 -0.867609 0.32120928 -1.4183241 1.4285066 -0.15322109 3.9566932 1.7736742 0.32986328 -1.0791606 -2.5574327 -0.104831025 0.76129127 -1.2339922 0.59692824 -1.2031677 -1.4169229 -0.31543088 0.295089 -1.9737328 -0.79587364 -2.2382102 0.8878048 0.7562199 0.3072119 -0.18116027 1.7134311 -1.3728237 0.85987735 0.32102126 0.50846016 0.037814565 -0.20069882 0.8759051 -0.79887 -0.97293913 -0.630224 0.5352114 1.5457069 -1.6194172 -0.06515034 0.850623 -0.3657758 1.7799172 -0.29486328 0.17504352 0.6855299 0.33748776 -0.7641739 0.9943629 -0.2027307 0.6225027 1.7853813 0.3339164 -0.6031079 -1.9449376 -0.890642 0.76774293 1.3602284 -1.8848867 -0.49226803 0.74159694 -0.2872027\n",
      "\n",
      "people -2.9278486 -0.34890845 -0.20060521 -1.1640363 -1.6036453 -0.56516546 -2.1096587 -0.9938473 -1.0888791 1.1198227 2.78209 1.2806108 -0.013768463 -1.5284446 -1.569838 -0.5618843 -1.0353051 -1.1299896 0.41744092 -0.7350455 -0.4868492 -0.11441768 0.3417595 0.9220519 -0.99245167 -0.6814472 -1.6323451 -2.4135015 -0.38583893 0.81358105 0.0088638645 -1.3097394 -0.46241584 -0.22671816 -0.5002779 0.6738452 -1.0071563 0.7314208 -1.0407504 -0.0725876 0.39036182 1.5804279 0.9194865 -0.15727638 0.90526515 0.4306091 1.0929631 -0.26890197 1.3257407 2.5070832 0.79478127 0.21813136 -0.7398529 -1.4459839 0.44091064 0.30382362 1.2986443 1.5871017 0.56963944 -1.0528698 0.54896915 -0.43748295 0.6961206 0.6107654 -1.4103308 0.7321719 1.3937947 -2.31766 1.2339737 -0.17406212 -0.5385046 0.023667352 1.3822578 -0.4545544 1.7242997 0.36991197 0.18575507 2.029894 -0.0722814 1.7986813 2.2155385 -1.2102003 -0.20911725 -0.9053253 -0.34319684 1.1897136 2.9658136 -1.4348904 -0.28683433 2.149454 -0.36427048 1.1962225 -0.8012509 -0.6181501 0.21732692 0.36916333 -2.9445763 0.50508237 -1.0107152 0.06397812 -0.02934936 0.46507037 -0.15316978 -3.1505804 -0.55109435 2.276897 -1.6846949 -0.056804683 0.10989657 -0.41455024 -0.44536617 0.0755679 1.5027931 0.413524 0.24922314 -1.6494945 -0.39052606 -0.34441993 0.48463833 0.31352952 0.4430924 -2.0585196 -0.6179396 -1.2256051 -1.8534243 2.7880116 0.80388683 -0.65063447 -2.0943723 -1.3554598 -0.61465394 1.0998787 1.2477992 0.6971361 0.60486937 1.0433296 -0.5599995 0.13844341 -0.42003247 -1.6214988 -0.7806534 -0.43320033 0.72683597 -0.53687596 0.5097488 -1.4573947 -1.3938824 0.37313664 0.2426642 -1.4621036 1.1237468 -0.8153007 0.12465379 0.646752 -0.6981572 2.3531587 2.1103144 -0.49315658 0.10170243 1.1186491 -1.465389 0.29811612 -1.6109543 -0.2720197 -1.1640172 2.1302829 -1.1888278 -2.7980967 -0.88633496 0.41593984 -0.9902319 0.24713282 -1.313141 0.6172356 -0.524785 0.4488587 0.41443747 0.019918669 0.48951304 1.1883446 0.73986566 0.78440803 -1.4429873 -1.8126628 -0.48068324 -2.004656 0.8164376 0.5307077 -0.87418604 -0.1430543 0.9555296 -0.761593 -0.5310196 -0.5386365 0.6706347 -0.3665003 -1.2232621 0.40387678 -0.3654708 -1.2879744 -2.5758836 -0.40086672 2.607349 -0.5627674 0.17167424 0.100262746 -0.36568135 -1.2138195 -1.9842436 -1.0266514 -0.82831264 1.6477557 -0.90775484 2.243787 0.8660524 -0.87917435 -0.8059471 1.2460222 0.30247813 3.1966157 -1.1444091 -0.8368583 -0.27043054 1.2785634 0.98804 1.3603452 -1.7387563 0.7999518 -0.45768476 -2.0186386 -0.208102 1.1771616 0.7803032 -0.7411751 0.102756806 -0.27290013 0.2569911 -1.4264312 0.3843435 0.23226924 -3.5162368 -0.042411085 1.9904209 0.5441258 0.4029737 -0.87086326 -0.68096393 -1.7525588 0.42294088 1.3703811 0.4326639 0.6797853 -0.7065707 1.8273393 1.164804 0.72230434 -0.70465744 -0.4370751 2.1528156 -0.49231008 0.47887444 0.61260855 -1.0528944 0.272694 -0.6909 1.071665 -0.75677294 0.646079 0.8366492 2.0461943 0.2743821 -0.6429872 -1.9196897 0.022158513 -1.7974505 -0.20558044 1.7922561 0.7243105 -0.2823039 0.6763846 0.3387325 1.6171573 -0.81335855 1.8318138 1.0074812 0.29166767 0.6113479 0.09509304 -0.008655292 1.2416707 -0.094973594 0.13938373 -1.2245573 -1.1880561 0.7491436 -2.7969751 -2.42587 -0.1951296 0.2478124 0.04071833\n",
      "\n",
      "would -0.9355807 -1.9517702 0.08936865 -0.85748315 -0.10027437 -1.498141 -1.9395744 0.48267066 -1.6338161 -0.41330406 1.0830104 0.39701387 -0.082953334 -2.1225219 0.84599495 -0.45637017 -0.7129511 -1.1112767 0.18394655 0.97529346 0.19606283 -0.08667265 -0.57687634 1.6174982 1.3492872 0.15095389 1.5838566 -0.64795387 -1.0347056 0.7095984 0.1080399 0.8857339 1.5150449 0.25897744 0.124277696 -2.01043 -0.25299639 1.2771773 -0.11080811 0.91177523 -0.7726881 1.2342278 -1.2047864 -0.8595597 0.4077603 -2.0192099 0.42324167 -0.9809408 -0.5564957 1.8097382 0.83134615 0.25916424 0.6516293 1.3729128 -0.05034818 0.48966762 -0.15835598 1.2150337 0.030256249 -1.2351282 -0.9623501 -0.65076655 1.4666219 -1.0755453 -1.2930901 0.805728 0.3557782 0.5918853 -0.50791365 -1.1258348 0.029690055 -0.27394515 0.39396533 -0.44881678 0.33689344 0.57010776 -1.3760693 0.9399597 -0.32623687 2.244231 0.25040346 -2.2213645 0.9042912 -0.60712016 -0.13631478 1.6380379 0.82975954 -0.79271543 -0.9388534 0.24547084 0.101056166 -1.5824043 0.18618384 -0.4358145 0.3163559 0.15217605 -0.34322652 0.031852055 -2.0302901 1.5839263 0.6622773 0.83934814 0.76150227 -1.5308547 -0.90718406 -0.26742196 -0.5455139 0.19085665 0.6877169 -2.8306668 0.6567068 -0.6837988 0.26338592 0.5477292 0.087803 -1.1529437 -0.101192184 0.09309437 -1.2020864 -0.46001077 1.0543296 0.8865345 -0.50536215 -1.6892269 -1.0435221 0.35193893 -0.45063823 1.4101458 -3.5306132 -0.81769985 0.31800586 -0.29703423 0.434616 -1.1969463 0.6009224 1.0455488 -2.119603 -1.3986305 1.7674824 0.41904268 -0.22119054 -1.1203198 -0.8358016 -0.3704631 0.42027214 1.065065 0.5337106 0.12232138 0.39916182 -0.8720324 1.2271488 1.0228523 1.3596077 0.16036801 -1.5523058 1.7074667 0.071769334 0.15112485 -1.7405828 -1.1145356 -0.112110324 1.0264319 -0.940125 1.261604 -2.4359317 -0.44197404 1.1362896 -0.12458714 0.009975534 0.16070284 0.32867715 -1.0260638 -0.34022322 1.2002478 0.4530399 0.61239135 -1.1048052 -0.21770582 0.9330096 0.5166778 -1.7150711 -0.84183455 -0.24360566 0.9124287 -0.66166437 -1.9288648 1.4677697 0.64722115 -1.2843127 -0.022587866 0.4946524 -1.1199049 1.3555418 0.858187 0.49116626 -1.5951394 -0.9973406 -0.04508232 1.2238916 -1.1467421 -1.0700454 -0.08057589 0.5246813 -0.92823476 0.44827443 1.1460457 -2.1712713 -0.87198234 -2.2185738 -1.9644665 0.75940514 2.3332953 -0.6240909 0.87685275 0.75867623 -0.7126507 -0.40734997 0.90095943 0.27914596 1.2388201 -0.9004569 -0.08384921 -2.0842898 0.72289413 -0.223198 0.024048068 -0.20615943 0.3887024 1.0024887 -1.5725886 0.3615998 0.56458014 -0.028165247 0.048403963 0.07368137 1.5058502 -0.33648545 -0.4987666 1.6868438 -0.28483653 -2.6102204 -1.0453317 -1.7212234 1.7874866 0.14415328 -0.89926076 -0.026482914 -0.49644732 -0.8085781 1.945414 -0.8000947 -1.3559717 -0.781093 -1.1329262 -1.7904894 -0.2710638 0.58762705 0.26527333 0.49341705 1.4108077 1.6982841 1.1550168 0.39827475 -0.6275697 -1.4145907 1.6588213 -0.72217625 1.0794656 -0.8802437 -1.9806758 2.9793427 -1.181802 -1.3724461 -1.5964621 -2.0370393 2.3357055 -0.67567307 -0.43209636 0.46894294 1.5930496 -0.07990245 1.9626557 0.122727625 1.8344066 -0.5950637 -0.16732024 0.5054649 2.123727 -0.23838316 0.7510998 -0.61761177 0.38576207 -1.2560788 -1.2387829 1.885734 -1.766684 0.27633867 -0.7618971 -1.7189261 0.27247316\n",
      "\n",
      "like -2.5837858 -1.2194278 -1.4121162 -0.84652996 -1.348678 -0.29704538 -0.57816666 -0.3386677 -1.3366864 -1.871227 1.2394102 -0.6029915 0.37946793 -1.2474113 -1.2120886 0.5893924 -0.49558342 0.22337918 -2.6552677 0.07243686 1.0121131 -0.047094926 -1.6289262 0.9574507 0.78615206 -1.5738223 0.7959166 -1.9742204 -0.17699334 0.63158953 -1.2593751 0.49728128 0.46129656 1.512057 -0.6804651 -0.938889 -0.6730031 -0.47905445 -2.0498395 0.55698234 -1.0365578 2.305002 -1.5069326 0.4590517 -0.45531216 -0.9962646 -0.6650741 -0.87664115 1.4354148 -0.5930366 1.0610778 2.0735888 0.09793798 0.23230836 -1.0393516 1.0405895 -0.99243706 -0.7062808 3.1064956 -1.4450421 -1.4320182 0.22123641 -0.96547824 1.0669582 -0.9896857 -0.8082995 -0.5468514 0.6510977 -0.23167378 -1.428517 0.18216605 -1.6592768 -0.84780574 -0.4382148 0.505911 -2.0111077 -0.5729049 0.5888383 1.1264129 1.0342208 -0.048677824 -1.0740594 -0.34552336 -0.97409046 -1.7285733 0.16309993 -0.9837192 -1.6545908 -1.1470897 -1.8252561 -0.035411518 1.1080941 0.33952302 -0.93052953 0.2146755 0.3241939 -2.8534274 0.06827874 0.119231924 0.700351 -0.8345816 -0.6767863 -0.17888823 0.33464167 0.20857991 0.52421325 -1.3442183 0.49403346 -0.8153341 0.015889985 -0.35552076 0.7292096 0.5809244 -1.5551546 2.0585408 2.3151882 2.3782713 -1.9777495 1.3395015 -0.42875916 0.12655063 -1.8028774 0.8524615 1.1597754 -1.0577275 0.21274538 0.9947912 -0.64668846 -2.5609047 0.5098839 -0.15589774 1.4766698 0.8248087 -0.50302947 0.7176472 -0.1672495 0.61263686 -0.9481835 -0.51570195 0.7463716 1.6610929 -1.7914442 0.35453367 -0.3056598 -0.97663003 -0.08238648 -0.49191064 -0.020510608 -0.17244598 0.77190876 1.5034344 0.47083223 1.5858161 -1.1898707 -1.2879956 -0.48500133 -0.12777117 0.65642834 0.3742359 0.61769587 0.067076564 -0.37627742 -1.2800167 1.1296039 0.751295 1.2668818 0.36583123 -0.72374725 -0.5334862 0.23141599 -1.8537552 0.16512619 -1.3876264 -0.7272065 0.022557398 -0.2963761 0.40443566 0.8397734 -0.4821105 1.2810208 -0.33527547 -0.11306321 -0.08583905 0.63396055 0.3327219 -0.44225505 -0.6912638 -0.57504904 1.3383511 -1.26313 0.4633334 -1.7950324 1.4186465 -0.5428998 0.7318557 -0.0492146 -0.86635685 1.6217625 -1.278864 -1.2507452 -1.5421218 1.2594131 0.32060382 0.043555785 -0.58414346 0.75614804 0.2800969 -2.0122614 0.98111194 -0.6658675 0.7454813 1.6263583 -1.2270713 1.5512406 0.6191017 -2.3631043 0.2944279 -0.023514504 0.0044881203 0.101964995 -0.76437014 0.08569351 -0.68027633 1.2220885 -0.2252034 0.2007807 -0.49610436 0.9866716 1.6415026 -0.58984333 -0.13793206 -1.7317978 -0.09628956 1.3942708 0.22562297 1.3623326 1.1072676 0.71548027 0.4996206 -0.25449857 -1.8476368 0.93110985 -0.035649482 1.2294697 1.8995539 -0.2776806 0.64584345 0.47759005 -0.11908171 -0.62722415 -0.3180503 0.12038677 -0.7353905 -1.9690368 0.84903556 -1.5943043 -0.41216126 -0.66115034 0.044436418 1.817272 -1.343266 -1.1393061 -0.5556999 -1.3761997 -1.1700006 1.7616026 -0.62739116 0.29144913 -1.1282982 2.3476005 -1.0088769 0.7507084 1.4494929 0.97361124 2.5661535e-05 -1.0588769 -1.0045726 1.6055255 -0.9138851 0.3550553 1.966788 -0.4588268 0.52598256 -0.07293358 -0.23418652 0.6357661 0.5132605 0.9245483 0.354202 -0.33740526 1.6389889 0.64703244 -0.8836308 -1.294418 2.0028186 -0.6736421 -1.243334 0.5608094 1.2781851 -1.0436939\n",
      "\n",
      "think -2.2163606 -2.2262657 -0.51690334 -0.8321225 -0.08056661 -1.7447977 -1.7325321 -1.5874175 -0.94771016 -0.8155212 0.9426528 1.0584041 -1.9629211 -0.1553941 0.21364152 -1.114896 -0.09695369 0.76138425 -0.806964 -0.82331544 0.8005002 -0.07801629 -0.69422185 0.59936166 -0.29130727 -0.40314373 -1.0706815 -0.115576975 -0.012305057 -1.0612161 -0.90028006 -0.08143131 0.56563187 0.61885476 0.18675944 -0.4996975 -1.0365145 1.2040361 -2.2792547 0.65819925 -1.6490794 1.5256758 -1.0459563 -1.0722773 0.38640937 -0.3889571 0.41008472 -0.9137539 0.25486672 0.68737316 0.74251753 -0.029879797 0.5249662 0.039575566 -0.4255252 -0.0077457153 1.776345 1.3006281 1.1215224 -1.7183381 1.048984 0.4775942 1.0889621 -0.8622031 -0.39670804 0.40623468 -0.87561977 -0.95733607 0.3197391 -0.7035866 0.20629133 0.74735326 0.77927446 0.6438943 0.46485677 -0.9254404 1.2595367 1.7523137 0.5079432 1.3522707 0.4681143 -1.0163844 -1.1274269 -0.89886945 -1.1274533 0.36365744 0.3582315 0.10402563 -0.9480656 -0.7628524 0.64584774 0.659562 0.1520332 0.027764622 -0.83639157 1.8633312 -0.7385665 -0.45053908 -1.1321856 0.7433085 -0.70242065 -0.07935561 -0.53780067 -0.80881196 -0.3190508 0.1553037 -1.1791838 -0.14185734 0.9611712 -0.79975826 0.009143617 -0.8775011 1.7252152 0.31997553 0.015120432 -1.2485877 0.19659127 -0.9307995 0.56424975 -0.53816575 1.4287728 -0.72835493 0.8821052 -0.040420357 -0.7989467 -0.52719504 -0.7147695 0.24770886 -1.4755535 0.7093381 0.2189679 1.8912928 0.15250196 -0.18907908 0.8111505 -0.2847236 0.07821569 -1.5769874 0.88102764 0.50067645 0.8352917 -1.7637764 0.46997398 0.2097171 0.08261625 0.52216053 -0.4382917 0.5936052 -0.27329913 -0.33659357 1.1726673 0.23396951 0.5724037 -0.5383849 -2.12767 1.3175683 0.37967968 0.2499794 0.76945525 0.5829784 2.228356 0.49814832 -1.4094884 0.51134676 -1.2255343 0.9186948 -0.049257793 -0.181044 0.54673904 0.13148464 -0.62201995 0.22101218 -0.7230446 0.007788645 -0.5512011 1.2411041 0.65783644 -0.37745556 -0.40657645 -0.12469329 0.7652332 0.85501736 -0.44635183 1.0306462 -0.021639805 1.2229493 0.62072027 -0.30179584 -0.62129164 -0.46130374 0.36650336 -1.9945318 0.9721969 -1.4021224 -0.21551363 -0.7948631 -0.9948511 -0.27727324 2.155308 -0.9909523 -1.806347 -0.8357677 0.5708373 -1.6253067 0.4999581 0.15250322 -0.9369003 0.0052727447 -0.8040441 -0.08639225 -0.10700832 2.3336616 -0.8491356 -0.2815091 0.3671158 -1.6964036 0.90857273 0.2750434 1.0592786 -0.009204719 -0.4725406 0.10533041 0.33274767 0.6293864 0.90274626 1.1659242 -0.5147739 -0.668745 0.5832044 -0.6593066 -1.1912608 0.08921769 2.826507 -0.8305667 0.6606674 2.0211754 -0.23206227 0.562782 -0.18436468 -0.75552547 -1.8215815 0.74318403 -0.49756417 1.2319117 1.026415 1.0617256 -0.38022718 0.08195918 -1.173466 0.59336495 -0.27046552 1.5783062 -1.6218435 -1.0321168 -0.57748437 -0.7893881 -0.97050816 -0.6403765 -0.2901004 0.73035246 0.32563028 0.519803 -0.8022153 1.0950117 -1.1953334 0.92214054 0.3202732 -0.06755681 0.37214556 0.08408953 -0.37083876 0.54392546 -0.6376347 -0.5327024 0.66428745 1.5770043 -0.52271575 0.7163895 -1.0625994 -0.4239115 0.16907462 0.11059186 0.2628624 0.2550819 0.35033703 -0.39021635 0.7225657 0.34975475 1.0468172 0.1655194 -0.006537506 0.6604399 -0.06657499 -0.017861098 2.1341653 -0.9069843 -1.721931 -0.6304852 1.8210276 0.47373128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check ft model\n",
    "\n",
    "with open(finetuned_input, 'r') as f:\n",
    "    for _ in range(5):  # Print first 5 lines\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self build model\n",
    "\n",
    "# read txt embeddings\n",
    "with open(self_build_w_dim, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "# write relevant lines only\n",
    "with open(self_build_input, 'w') as new_file:\n",
    "    new_file.writelines(lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump 0.59948117 -0.28408778 0.6504988 0.43734848 -0.6227624 -0.6972409 0.9597554 -0.008057123 -0.8670799 -0.72377723 -0.82790774 -0.42517745 -0.9437413 0.57381374 -0.373582 0.21953763 -0.51725835 1.2853409 -0.08310709 -1.4900138 0.6531159 0.069898136 -0.22441697 -0.63979894 0.100700974 0.84639233 0.48628098 0.3515258 0.24299438 0.5723756 -0.27149495 0.45208332 -0.16213135 0.13250393 0.24455719 0.5482613 0.8628233 -0.12933758 0.25566643 0.3456846 -0.7715811 -0.08185323 -0.34849134 -0.16647597 0.27219388 -0.34899205 -0.36642495 -0.14317276 0.2615827 0.5620519 -0.14176743 -0.95004207 -0.7693819 -0.79598457 1.3206114 -0.5447436 0.55283064 -0.5398319 -0.40984643 0.44866917 0.5866288 0.2146417 -0.74650306 -0.5409015 -0.11758082 1.1736859 0.564685 0.3442389 -0.28383437 0.035038754 0.13543443 0.11346874 0.0856265 -0.18126954 0.4666765 0.41795218 0.20135987 0.8923833 0.41415718 -0.10463093 -0.5322809 0.097537965 -0.23520711 0.77364516 0.12296794 0.30868208 0.25286117 -0.1536013 1.1614325 -0.3670092 0.15036497 0.33016852 -0.31274363 -0.5554359 1.1838553 -0.35617676 -0.40496677 0.23771624 -0.29706982 -0.116597645 -0.0338647 0.71316546 0.8722473 1.0634887 0.3029462 -0.16437495 0.6379655 0.24815199 -0.084523685 0.0816062 -0.270148 0.018860247 -0.6790689 -0.30762208 -0.86789536 0.02301635 -0.30568382 -0.77577245 -0.2786871 0.68407655 -0.25133273 0.39260846 0.42663547 0.37251428 0.8658176 -0.17910022 -0.767676 0.9074393 -0.10898957 -0.38368353 -0.16625865 -1.8485639 0.36255765 -0.11294586 0.38103288 0.13443355 1.1260036 0.8818298 0.41548994 0.8279229 0.41629243 0.42844182 -0.008607542 -0.7813422 -0.9723343 -0.024745649 -0.6557289 0.34724322 0.09484957 0.12685251 -0.40079573 -0.3799612 -0.84142697 0.507068 -0.21135786 0.048336916 -0.010347749 0.2447925 -0.069280714 0.09312264 -0.0061240927 0.3280445 1.1128455 0.4238267 -0.024787407 -0.03492719 -0.20420332 -0.17187215 -0.37585396 -0.23003106 -0.2880362 -1.3676366 0.6810538 0.17271602 0.6662185 0.5870297 0.59451073 0.109058335 -0.46659717 0.2568542 -0.41750038 -0.42230266 -0.2849195 0.50312376 0.042530686 0.0935605 -0.121245734 -0.35745728 -0.122256435 0.028701644 0.025187664 -0.08282477 -0.123824514 0.10197557 -0.23211718 -0.3832599 -0.17998226 -0.06384517 0.11102589 0.17447627 0.07157207 0.18206991 -0.10408312 0.115109466 0.1554776 0.6582658 0.24847111 0.30053765 0.5002464 0.5640261 -0.97780883 -0.21816447 0.8634285 0.050476052 -0.23772809 0.24246506 0.47200236 0.024590883 0.03601924 1.1719545 0.054010436 -0.23803549 0.13254286 -1.105994 -0.71598965 -0.12028269 -0.13209504 -0.4647566 0.057035517 -0.42193463 -0.19056794 0.48552606 0.09398277 0.88104266 0.95056796 -0.7640852 -0.2544439 0.80741763 -0.2638917 1.2114522 -1.0716134 0.6181393 0.35717845 0.053221762 -0.22972624 0.32877645 0.20743434 0.39200708 -0.4266884 -0.8808408 0.5183927 0.5637063 0.25118315 -0.13377933 -0.48103517 -0.38567933 -0.6330664 -0.676725 0.95636487 0.12508573 -0.8013292 -1.0499816 -1.0235138 0.22256303 -0.008582699 -0.3172555 0.24329485 0.6245035 0.1930128 0.31024644 -0.61458474 0.05209728 -0.57814854 0.45627758 -0.2021024 0.5388423 0.2024046 0.43922108 0.43242702 -0.57369924 -1.2505236 0.28747225 -0.43726286 0.0959919 -0.29507205 0.9624076 0.080237255 -0.29574168 -0.49360514 -0.40934873 0.36045578 -0.27778286 0.75180787 -0.10184049 -0.49350384 0.0029694666 -0.879606 -0.45232335 -0.23879965 0.27004856\n",
      "\n",
      "people -0.54101557 -0.08576071 -0.0013694663 -0.5671615 0.124356985 0.098720916 0.14386427 0.30396676 0.9360579 -0.33590132 -0.23574229 0.011602329 0.15285459 -0.32863832 -0.46175894 0.26726505 -0.21920215 -0.9993409 0.9093999 0.6155978 0.31668314 0.56743264 -1.050333 0.46769845 -0.2187817 -0.7843627 0.6534044 -0.10623087 0.20097303 0.72493464 0.4987213 0.7468719 -0.9954787 0.30490878 0.49184003 -0.27225882 0.5579436 -0.5556437 -0.34916458 -0.2342849 -0.17395155 -0.39277512 0.47726718 0.039922956 -0.14248626 -0.033180088 -0.4611458 0.15269138 0.65186524 0.1374657 0.7766014 -0.29006657 0.1347219 -0.31703857 0.42671332 0.28646833 0.4544401 0.6613939 0.54691577 -0.15706246 -0.9425482 0.055295724 0.21561188 -1.569568 -0.5847307 0.7851901 -1.0399222 -0.7543508 0.1763393 -0.3683256 0.4629325 0.4372293 -0.38605306 -0.8711689 0.7488215 0.38575703 0.3160515 0.18900299 -0.58324003 0.76341945 -0.98899245 0.08510501 0.116335504 -0.27765873 0.17224096 -0.6643337 0.53996354 -0.2214804 -0.003178653 0.10191633 -0.7134413 0.60188156 -0.08570814 0.25054097 0.80899894 0.69219106 0.27073327 0.66123706 0.3295669 -0.5837338 0.46176833 -0.36666816 0.49898934 -0.7026174 -0.048832163 0.30703107 -0.5508631 0.1395907 -0.08065114 0.95372087 0.5071083 -1.2406516 0.0067481906 -0.14596757 -0.043215837 -0.7524441 0.123675674 -0.18101764 0.4595237 0.82790136 -0.98004913 -0.5322146 1.437776 -0.47401083 -0.060616422 -0.03910085 -0.45654622 0.0924905 -0.3039343 0.70992553 0.9330561 -0.5865713 0.66578364 -0.46562502 -0.48890623 0.15559669 0.029833438 0.6255053 0.60178286 -0.11316552 -0.4393871 -0.42841375 -1.3108501 0.6113419 0.22292759 -0.1868934 0.36877805 -0.2557965 0.3698076 0.42915815 -0.8894486 0.2598257 -0.23281746 0.04266733 0.13873547 0.23910125 0.11281988 0.19848828 -0.4830824 0.21888193 -0.46284416 -0.3260996 0.65995157 1.0912347 -0.18743472 0.22326408 -1.0459045 -1.3927871 0.6324532 -0.07751393 -0.3921963 0.2986021 0.06471686 1.5063123 0.63457924 -0.26957843 -0.17776327 0.9828078 1.2347428 0.20169705 -0.7491165 -0.07657312 0.02109731 0.9990801 -1.1372122 0.23512729 -0.864557 0.38831517 -1.285147 -0.64294255 0.05707387 0.00897716 0.6528407 0.22524256 0.54643625 0.56247884 0.51445305 1.1538712 -0.7174353 0.67059827 0.2391625 0.6173284 -0.20542943 -0.56322724 0.30539072 -0.09537759 0.25352573 0.0064686406 0.51584744 -0.7010035 -0.5245975 0.27073032 -0.19534643 -0.66870666 -0.31555754 0.61494094 -0.27256647 -0.6432599 -0.15186945 -0.33540714 -0.04476548 -0.07695691 0.4824451 1.2014172 0.33759174 -1.009301 0.3404198 -0.42902246 0.6569279 0.17312607 -0.40657476 -0.49944362 0.939231 -0.46133456 0.026745735 0.81064796 0.29088154 0.6973 0.57736295 -0.3378313 0.8256459 -1.3179885 0.49416548 -1.2277483 0.19840917 -0.10542216 0.93240196 0.20826447 0.14320816 -0.17571601 -0.08360196 0.17873585 0.54519755 0.80083054 -0.5091932 -0.31267422 0.27026775 0.076766185 -0.21721923 0.026164986 1.0910378 -0.61211336 0.25817862 0.09283283 -0.8335928 -0.033227235 0.6227293 -0.0071564666 -0.48955497 0.25214818 0.14137846 1.2776033 0.32145786 0.2506403 0.5948959 -0.6136861 -0.76278794 0.29344928 0.41883555 -0.034406286 0.88705313 -0.19475672 1.0471991 -0.38412195 1.2924455 0.38516498 0.04978368 0.43399075 0.82906556 0.5876647 0.032497615 0.12368974 0.3077359 1.0361547 0.84552944 -0.068580516 -0.13625188 -1.1548932 -0.3448264 0.54041743\n",
      "\n",
      "would -0.6829207 -0.351287 0.6466604 0.10897703 0.19041803 0.53772223 -0.252542 0.29082793 0.005176877 -0.2819379 -0.010194877 0.32707712 0.12734 -0.28394476 -0.89277035 0.44371465 0.038405318 -0.628121 -0.15348995 0.14223485 0.18542983 0.6020511 0.237889 1.169763 0.5102262 -0.30138212 0.37182608 -0.36433592 -0.4436194 0.33690286 -0.15127538 0.7685454 -0.05245588 -0.76166993 0.32774338 0.13363022 0.37457794 0.16168621 0.25284994 -0.47385865 -0.46597418 -0.46169293 -0.2675945 0.45146134 -0.3256197 -0.3262116 -0.43382314 -0.53849894 0.30203614 -1.40698 -0.23471436 -0.9453113 0.2565251 -0.31671467 -0.019941902 -0.7447585 0.062098164 0.38950416 -1.062525 0.18389373 0.6928549 0.29621983 -0.005546013 -0.47996527 0.35672912 1.3131281 -1.0096076 -0.022457639 -0.17782235 0.038900077 0.40098405 0.115539946 0.18497731 0.2187082 -0.37141246 -0.0256029 0.40600333 0.21462657 -0.9587293 -0.48404452 -0.041340724 0.94207895 0.36742842 -0.813826 1.3351493 -0.31655633 0.5318315 -0.1450548 -0.5900761 0.0296537 1.1007868 0.049420226 0.20591341 0.08354299 1.0329734 -0.58688736 0.48358536 -0.76805055 0.7663666 -0.59101754 0.18843879 -0.6335408 -0.0110996775 0.73532224 -0.21975532 -0.2544164 -0.7995837 0.24201676 0.031064834 -0.38381243 -0.043136686 -0.57669806 0.075992666 -0.40708324 0.19342436 0.3068951 -0.3923085 0.34198436 0.882511 0.23165691 0.7179518 0.74810225 0.29479223 0.2903539 -0.5668884 -0.39749172 0.17489319 -0.8140285 -0.17025603 0.6037652 -0.8887317 0.03497613 -0.60265934 -0.6804414 -0.69503963 -0.48510766 0.42967853 0.10924253 0.1364561 0.44239363 0.14404921 0.45815828 0.89676994 -0.26088724 -0.2590307 0.7598647 -0.5550084 -0.35656235 0.37024453 -0.2391513 -0.9638087 -0.41448823 0.3323567 0.20178601 -0.19990464 -0.24808471 -0.35638523 0.003098468 0.11378136 0.5951739 -0.22503601 -0.100607336 -0.50629145 -0.033983625 -0.10424797 -0.16122624 -0.6032807 0.07801519 0.5291302 0.28630915 0.21632487 -0.37206477 0.8243811 -0.8884725 -0.3472867 0.25815856 -0.07223499 -0.1406613 -0.17195104 -0.087667905 -0.82996255 0.8490724 0.6191497 0.39201522 -1.1555847 -0.41305852 0.61484855 0.39572647 0.19924563 -0.02752278 1.623095 -0.0990163 0.068852544 0.15995473 0.23644549 -0.8034583 0.32410705 0.60278493 0.43062064 -0.34964502 0.28374624 -0.19161183 -0.2486023 -0.5802125 0.50536823 0.7419648 -0.4043208 -1.1355605 -0.14436492 -0.17306645 0.022871712 0.51437116 -0.28296238 -0.042683713 -0.25241432 0.016149502 -0.81798244 0.38929427 0.16255867 -0.045934476 -0.92492574 0.37505224 0.50058717 -0.9306048 0.008767451 0.54897106 -0.732983 0.13335371 -0.078942485 -1.3889401 -0.44806606 0.19308789 1.4880227 -0.0011386946 -0.022926114 1.0411832 -0.43910187 0.15432295 0.6406948 -0.06246348 -0.031542104 -0.9830332 0.34765747 -0.2449565 -0.16011663 -0.44898352 -0.25781924 -0.7488646 0.59447205 -0.95057285 0.41021758 0.068393625 -0.8512311 0.6408433 -0.06429503 0.086142845 1.0896821 -0.12533976 -0.39735445 1.3087977 0.4280819 0.053548273 0.62319374 0.1828512 -0.03021097 0.09270834 -0.4571389 -0.028131472 -0.19104874 0.22560821 -1.3195767 0.09337073 0.62544197 0.14130369 0.12512513 -0.7891119 0.48294947 -0.653115 0.8413951 0.58497 0.07446384 -0.013750365 -0.0016408992 0.16421258 -0.55511487 0.68977994 0.19173165 0.39461568 0.29091093 0.16714227 0.722583 -0.7670805 -0.20370929 0.40762073 -1.092851 -0.054478317 -0.33038542 -0.31518823 1.3007247 -0.5534134\n",
      "\n",
      "like -0.68435836 -0.16935709 -0.91587275 0.641172 0.99856937 0.9519442 1.3296666 -0.14530136 -0.46269333 -0.3830496 0.718594 0.88865304 -0.37196577 0.0028288437 0.5999348 -0.05948598 -0.15222792 -0.12801169 -0.91301394 -0.8048681 -0.26205003 -0.019267008 0.6121627 -0.45052165 0.5179752 0.20788808 -0.52441764 1.3563393 -0.76196337 0.0034367272 0.20015834 -0.9528262 0.39065585 -0.2653727 0.07531037 -0.13187341 -0.5148346 0.79286045 0.12773587 -0.21038619 0.087024644 -0.2363355 -0.22714901 -0.14079876 0.7086755 0.6497309 0.42031696 0.30312276 0.18320864 0.9677378 -0.01743052 0.59214526 0.023760414 -0.08086723 0.48525357 -0.37733665 -0.2659818 -0.14636007 -0.012760125 -0.60988677 -0.21911503 0.22170426 0.5846804 -0.08126981 0.020290766 -0.11424517 0.32375595 -0.3244447 0.5670256 -0.1034509 0.52502537 -0.09004498 0.16419505 -0.1762184 0.12317414 -1.1472403 0.18016388 -0.9683312 0.13692544 0.22264187 -0.15398933 0.24367161 -0.70032746 -0.2666481 -0.7521626 0.23130004 -0.1894712 -0.49915257 0.35981545 -0.053369585 -0.013544444 0.77744186 -0.30268303 0.38304353 0.004151601 0.35190448 -0.83727247 -0.6312177 0.13613263 -0.08050877 0.57945377 0.25680754 -0.40215096 -0.76184785 -0.30060506 -0.38715756 -0.6605697 -0.5409794 0.22526339 -0.8362032 -0.58581436 -0.13265325 1.121917 -0.2742667 0.18678392 -1.014456 1.0384241 0.4301313 0.45080668 0.18207717 0.13426842 0.21726617 -0.33616418 0.31685683 -0.44484437 -0.34089848 -0.13396885 -0.4770275 0.39999226 0.048607852 -0.13335423 0.73106045 0.07999139 -0.08145469 -0.54776907 0.0111096855 -0.30157498 -0.56459457 -0.16923034 -0.63618016 -0.32244053 -0.19077043 0.60477024 0.30315652 0.005576123 0.56042296 -1.0071112 0.69389486 -0.29129252 0.9190355 -0.19411683 0.94651246 0.18241772 0.8519326 -0.17450263 0.36499846 0.21957743 -0.7904388 0.9095814 0.6131836 -0.5947148 -0.35282588 -0.74379396 -0.7181888 -1.251526 -0.7762486 -1.5015066 0.13403694 0.28851882 -0.8845644 0.3376402 -0.067715034 -0.57174474 0.2983211 -0.42168412 0.8075094 -0.15971985 -0.112130426 0.3584336 0.055861183 0.24963936 -1.0385249 0.49940234 -1.1350082 -0.32343203 -0.9980073 -0.16182643 -0.24991533 0.24611583 0.24704689 0.4656688 0.23004964 -1.1598583 0.430132 -0.5870086 -0.21014008 0.04697597 0.2971655 -0.53991264 -1.0123945 0.20773414 0.2627112 0.5459411 1.1299204 0.10746519 -0.36137837 0.3522695 0.9940115 -1.0201571 0.27086604 -0.5393251 -0.06342673 0.391377 -0.22884312 0.784884 -0.5119357 0.11380291 -0.3645375 -0.46438858 -0.052572355 1.1747262 0.4131015 0.4885514 0.050751265 0.25339672 -0.07034242 -0.18318626 -0.3992118 0.5418943 0.27635214 0.22886859 -0.25007385 -0.49550495 -0.25641042 0.503384 0.067363344 0.47378165 0.110557474 -1.2047073 -0.5283006 -0.14151399 0.24148628 -0.9346176 -0.855633 0.7300025 -0.16529281 0.24557391 -0.14344344 0.84362465 0.23056383 -0.050640866 -0.22234975 0.62913024 0.17690954 -0.351112 -0.11034388 -1.2067215 0.7783063 -1.3574295 0.26384425 -0.52526206 -0.65042573 1.449041 0.5213096 -1.1445589 0.9310658 0.016614404 0.5421875 -0.6549914 0.107817344 -0.2559554 0.105979234 -0.7734886 0.4663196 -0.5910331 0.84187186 -0.46722674 -0.4866153 -1.1767737 -0.7600031 -0.50517756 0.8151637 -0.10808463 -0.5431642 0.42829862 0.43314967 -0.2520568 -0.7331595 0.74685323 -0.5710585 0.115397125 -0.20158689 -0.3815949 -0.74316937 1.3794639 0.017795796 0.19944389 0.47948477 0.99914646 0.56396556\n",
      "\n",
      "think 0.03506034 -0.3208472 -0.4642956 0.34714842 0.96360373 0.49576 -0.55179656 0.10667431 0.1775519 -0.37953714 -0.58632016 0.21745953 -0.5612098 -0.50459254 -0.53036535 0.059805494 -0.23996174 0.815278 0.12509283 -0.4023611 0.061088078 -0.6070038 0.6475045 0.22957467 -0.51820064 -0.39709052 -0.6930976 0.32961494 -0.081508435 -0.32283443 0.3876636 -0.4712215 -0.5003418 -0.2816071 0.24667911 -0.46110198 -0.14543676 0.79087585 -0.13996874 -0.044218857 0.028147832 -0.6619726 -0.178795 0.11190858 0.022095414 -0.071271 0.21044984 -0.8706544 -0.35006353 0.0250024 -0.05663509 -0.7590623 -0.20594597 0.06075799 0.16910933 0.32526693 -0.16184156 -0.29162621 0.1890165 -0.91745013 -0.48391363 -0.45099163 0.17920266 -0.31643608 -0.63914806 -0.9743458 0.11651767 -0.22782683 -0.37656415 0.036558155 0.1364618 0.6286752 0.026740829 -0.022300249 -0.11605938 -0.13838494 0.41377744 0.28904778 -0.32971987 -0.06705721 0.4609756 0.8749825 -0.898026 0.24769107 -0.16332166 0.0040955953 -0.15829244 -0.101578094 -0.15774474 0.4213544 0.33867258 0.16892643 -0.003101176 -0.30749997 -0.18343702 0.21347548 0.3651864 -0.025495593 0.46387017 -0.473263 -0.20157157 0.5906744 -0.63667023 0.32044086 -0.1723483 0.43546656 -0.11705934 0.18807998 0.23375654 0.31410134 -0.16779906 0.5816914 0.15510748 -0.024393678 -0.14915009 -0.3190349 0.2853724 -0.13049589 0.7687159 0.035177406 -0.3449085 -0.8548451 0.30367425 0.5682715 -0.0028228955 -0.2713519 0.34212252 0.29938698 0.60339284 0.7222591 -0.20514917 0.091901086 -0.040512368 0.18409617 0.3475976 0.19025224 -0.4526709 -0.24695258 0.9621237 -0.06311273 0.7888182 -0.12294865 -0.5997759 -0.12807769 0.029365536 -0.4320852 0.43685865 0.42531055 0.10019508 0.17264022 0.6266298 -0.4570776 -0.20012079 0.6898551 -0.07670672 -0.123384826 0.94220495 -0.30035898 0.30661714 0.023416193 -0.067368984 -0.050295174 0.5993236 -1.0827371 -0.4720947 0.11436283 0.07309271 0.069332495 -0.34148094 -0.79764897 0.21333754 -0.60667795 -0.24993679 0.26424578 -0.6390407 -0.09995488 0.6161084 0.8219317 -0.16771282 0.29199493 0.78163505 -0.5946472 -0.29524672 -0.14709094 0.38471827 -0.087452985 0.10004922 0.114317775 -0.41512603 -0.471701 0.34893668 -0.24797057 1.0306511 -0.22495843 0.060083084 -0.017418927 -0.29694092 0.25064608 -0.62705165 -0.14733991 0.20909035 0.026387732 0.81297827 -0.44208175 -0.3399548 -0.057841156 0.25502092 0.04774719 -0.01885706 0.2278435 0.28327817 -0.09206211 -0.6658298 0.4407827 0.61231565 -0.23338789 0.6332306 -0.025850693 0.02799026 -0.07851533 0.22495045 -0.6803368 -0.64505327 -0.3348697 -0.3984659 0.7847505 -0.32239723 0.25743636 0.0049990593 -0.6590231 -0.34204027 0.20983295 0.14595264 0.0020822652 0.13192059 0.3937888 -0.55076456 0.19625401 0.41990876 1.2176558 0.07075129 -0.07174839 0.056602377 -0.25112996 0.16613525 0.4293863 0.1154251 0.12176441 -0.07612671 -0.06313864 0.80287683 -0.5101395 0.013622098 -0.3639773 -0.6265215 -0.41041455 0.670654 -0.018898208 -0.43278503 -0.18755601 0.41408348 0.2305865 0.36452904 0.13774025 0.04306727 -0.48621708 -0.83619064 -0.027248228 -0.5233931 0.16634312 -0.66873527 -0.19496596 -0.69636285 0.049938504 -0.28173345 -0.3521286 0.12542742 -0.45216608 0.024972651 -0.6601141 -0.06818068 -0.29623434 -0.7555128 -0.37244192 0.13843401 -0.12408374 0.4265788 -0.335643 0.77579707 -0.65761286 -0.07721174 0.28496662 0.69193506 0.8868756 1.0765942 -0.43361157 0.35724312 -0.11565331 0.36493853 -0.3858758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check self model\n",
    "\n",
    "with open(self_build_input, 'r') as f:\n",
    "    for _ in range(5):  # Print first 5 lines\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Make Two Types of Sentence Model**\n",
    "\n",
    "* one normalizing word embeddings prior to averaging\n",
    "* one not normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize word embeddings\n",
    "\n",
    "\n",
    "def normalize_embeddings(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f_in, open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        for line in f_in:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue  # Skip malformed lines\n",
    "            word = parts[0]\n",
    "            try:\n",
    "                vec = np.array([float(x) for x in parts[1:]])\n",
    "                norm = np.linalg.norm(vec)\n",
    "                if norm == 0:\n",
    "                    norm = 1  # Avoid division by zero\n",
    "                vec_norm = vec / norm\n",
    "                vec_str = ' '.join(f'{x:.6f}' for x in vec_norm)\n",
    "                f_out.write(f\"{word} {vec_str}\\n\")\n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to parsing error: {line.strip()}\")\n",
    "\n",
    "# Example usage\n",
    "normalize_embeddings(finetuned_input, normalized_finetuned_input)\n",
    "normalize_embeddings(self_build_input, normalized_self_build_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump: norm = 1.000000 -> OK ✅\n",
      "people: norm = 1.000000 -> OK ✅\n",
      "would: norm = 1.000000 -> OK ✅\n",
      "like: norm = 1.000000 -> OK ✅\n",
      "think: norm = 1.000000 -> OK ✅\n",
      "trump: norm = 1.000000 -> OK ✅\n",
      "people: norm = 0.999999 -> OK ✅\n",
      "would: norm = 1.000000 -> OK ✅\n",
      "like: norm = 0.999999 -> OK ✅\n",
      "think: norm = 1.000000 -> OK ✅\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "def check_first_n_vectors(file_path, n=5, tolerance=1e-5):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= n:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                print(f\"Line {i+1} is malformed.\")\n",
    "                continue\n",
    "            word = parts[0]\n",
    "            try:\n",
    "                vec = np.array([float(x) for x in parts[1:]])\n",
    "                norm = np.linalg.norm(vec)\n",
    "                is_normalized = abs(norm - 1.0) < tolerance\n",
    "                print(f\"{word}: norm = {norm:.6f} -> {'OK ✅' if is_normalized else 'NOT normalized ❌'}\")\n",
    "            except ValueError:\n",
    "                print(f\"Line {i+1} has a parsing error.\")\n",
    "\n",
    "# Example usage\n",
    "check_first_n_vectors(normalized_finetuned_input)\n",
    "check_first_n_vectors(normalized_self_build_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_normalize_before_pooling(embeddings_file, output_path, stopwords):\n",
    "    embedding_model = WordEmbeddings.from_text_file(\n",
    "        embeddings_file,\n",
    "        tokenizer=WhitespaceTokenizer(stop_words=stopwords)\n",
    "    )\n",
    "\n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_dimension=embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True\n",
    "    )\n",
    "    \n",
    "    model = SentenceTransformer(modules=[\n",
    "        embedding_model, \n",
    "        pooling_model\n",
    "    ])\n",
    "    \n",
    "    model.save(output_path)\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load Word Embeddings: 70449Embeddings [00:02, 23530.02Embeddings/s]\n",
      "Load Word Embeddings: 70449Embeddings [00:03, 23406.89Embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "#model_test_pre = model_normalize_before_pooling(self_build_input, output_self_build_pre_pool, stop_words)\n",
    "#model_test_after = model_normalize_after_pooling(self_build_input, output_self_build_pre_pool, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9999999\n",
      "0.69474727\n"
     ]
    }
   ],
   "source": [
    "#apple = model_test_pre.encode(\"apple\")\n",
    "#great = model_test_pre.encode(\"great\")\n",
    "#sentence = model_test_pre.encode(\"apple great\")\n",
    "\n",
    "#from numpy import linalg as LA\n",
    "#print(LA.norm(great))\n",
    "#print(LA.norm(apple))\n",
    "#print(LA.norm(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9999999\n",
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "#apple = model_test_after.encode(\"apple\")\n",
    "#great = model_test_after.encode(\"great\")\n",
    "#sentence = model_test_after.encode(\"apple great\")\n",
    "\n",
    "#from numpy import linalg as LA\n",
    "#print(LA.norm(great))\n",
    "#print(LA.norm(apple))\n",
    "#print(LA.norm(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Pooling Normalization\n",
    "\n",
    "\n",
    "def model_normalize_after_pooling(embeddings_file, output_path, stopwords):\n",
    "    embedding_model = WordEmbeddings.from_text_file(\n",
    "        embeddings_file,\n",
    "        tokenizer=WhitespaceTokenizer(stop_words=stopwords)\n",
    "    )\n",
    "    \n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_dimension=embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True\n",
    "    )\n",
    "\n",
    "    normalize_model = models.Normalize()\n",
    "\n",
    "    model = SentenceTransformer(modules=[\n",
    "        embedding_model,\n",
    "        pooling_model,\n",
    "        normalize_model\n",
    "    ])\n",
    "\n",
    "    model.save(output_path)\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "\n",
    "# pre pool normalizing model\n",
    "output_fine_tuned_model_pre_pool = \"pre_pool_finetuned_sentence_model_wordlim_10_window_5\"\n",
    "output_self_build_pre_pool = \"pre_pool_selfbuild_sentence_model_wordlim_10_window_5\"\n",
    "\n",
    "\n",
    "# post pool model\n",
    "output_fine_tuned_model_after_pool = \"after_pool_finetuned_sentence_model_wordlim_10_window_5\"\n",
    "output_self_build_after_pool = \"after_pool_self_build_sentence_model_wordlim_10_window_5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load Word Embeddings: 1921604Embeddings [01:19, 24145.92Embeddings/s]\n",
      "Load Word Embeddings: 70449Embeddings [00:02, 25379.71Embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "# pre pool\n",
    "\n",
    "\n",
    "model_normalize_before_pooling(normalized_finetuned_input, output_fine_tuned_model_pre_pool, stop_words)\n",
    "model_normalize_before_pooling(normalized_self_build_input, output_self_build_pre_pool, stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load Word Embeddings: 1921604Embeddings [01:19, 24154.55Embeddings/s]\n",
      "Load Word Embeddings: 70449Embeddings [00:02, 23972.82Embeddings/s]\n"
     ]
    }
   ],
   "source": [
    "# after pooling\n",
    "\n",
    "model_normalize_after_pooling(finetuned_input, output_fine_tuned_model_after_pool, stop_words)\n",
    "model_normalize_after_pooling(self_build_input, output_self_build_after_pool, stop_words)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6105472,
     "sourceId": 9932245,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 222993998,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
